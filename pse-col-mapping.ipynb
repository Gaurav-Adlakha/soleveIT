{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed73835",
   "metadata": {
    "input_tokens": 6,
    "time_run": "8:49:57a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de46b33",
   "metadata": {
    "input_tokens": 28,
    "output_tokens": 180,
    "time_run": "8:50:44a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Students',\n",
       " 'Re-enrollment',\n",
       " 'Immunization',\n",
       " 'Historical_Grades',\n",
       " 'Test Scores',\n",
       " 'Staff_Teacher',\n",
       " 'Courses',\n",
       " 'Section',\n",
       " 'Section Enrollment',\n",
       " 'Rooms']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path='esp_data_mod.xlsx'\n",
    "\n",
    "xls = pd.ExcelFile(file_path)\n",
    "xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3de88d",
   "metadata": {
    "input_tokens": 2971,
    "time_run": "8:52:41a"
   },
   "outputs": [],
   "source": [
    "def generate_data_mapping_insert(mapping_df, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    # Create the INSERT statement header\n",
    "    insert_header = f\"\"\"INSERT INTO {target_schema}.DATA_MAPPING \n",
    "    (TABLENAME, TARGET_COLUMN, SOURCE_TABLE, SOURCE_COLUMN, MAPPING_TYPE, TRANSFORMATION, CONFIDENCE, SOURCE_SIS_TYPE)\n",
    "    VALUES \"\"\"\n",
    "    \n",
    "    \n",
    "    # Create each row value\n",
    "    value_rows = []\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        # Clean and escape problematic values\n",
    "        tablename = row['TABLENAME'].replace(\"'\", \"''\") if isinstance(row['TABLENAME'], str) else row['TABLENAME']\n",
    "        target_column = row['TARGET_COLUMN'].replace(\"'\", \"''\") if isinstance(row['TARGET_COLUMN'], str) else row['TARGET_COLUMN']\n",
    "        # Remove special characters and newlines from target column\n",
    "        target_column = target_column.replace('\\n', ' ').replace('(', '_').replace(')', '_') if isinstance(target_column, str) else target_column\n",
    "        \n",
    "        source_table = row['SOURCE_TABLE'].replace(\"'\", \"''\") if isinstance(row['SOURCE_TABLE'], str) else row['SOURCE_TABLE']\n",
    "        # Remove special characters from source table\n",
    "        source_table = source_table.replace('\\n', ' ') if isinstance(source_table, str) else source_table\n",
    "        \n",
    "        source_column = row['SOURCE_COLUMN'].replace(\"'\", \"''\") if isinstance(row['SOURCE_COLUMN'], str) else row['SOURCE_COLUMN']\n",
    "        # Clean source column - remove problematic patterns\n",
    "        if isinstance(source_column, str):\n",
    "            source_column = source_column.replace('\\n', ' ')\n",
    "            # Remove complex expressions that cause SQL errors\n",
    "            if '=' in source_column or '>' in source_column or '<' in source_column:\n",
    "                source_column = source_column.split(',')[0] if ',' in source_column else source_column.split()[0]\n",
    "        \n",
    "        mapping_type = row['MAPPING_TYPE'].replace(\"'\", \"''\") if isinstance(row['MAPPING_TYPE'], str) else row['MAPPING_TYPE']\n",
    "        transformation = row['TRANSFORMATION'].replace(\"'\", \"''\") if isinstance(row['TRANSFORMATION'], str) else row['TRANSFORMATION']\n",
    "        \n",
    "        value_row = f\"('{tablename}', '{target_column}', '{source_table}', '{source_column}', \"\n",
    "        value_row += f\"'{mapping_type}', '{transformation}', {row['CONFIDENCE']}, '{row['SOURCE_SIS_TYPE']}')\"\n",
    "        value_rows.append(value_row)\n",
    "    \n",
    "    # Join all values with commas and add semicolon at the end\n",
    "    values_part = \",\\n\".join(value_rows) + \";\"\n",
    "    \n",
    "    # Combine header and values\n",
    "    return insert_header + \"\\n\" + values_part\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def build_mapping_table(sheet_name='Student'):\n",
    "    df = pd.read_excel('esp_data_mod.xlsx', sheet_name=sheet_name)\n",
    "    mapping_df = pd.DataFrame(columns=['TABLENAME', 'TARGET_COLUMN', 'SOURCE_TABLE', 'SOURCE_COLUMN', \n",
    "                                      'MAPPING_TYPE', 'TRANSFORMATION', 'CONFIDENCE', 'SOURCE_SIS_TYPE'])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        eschool = row['Eschool']\n",
    "        if pd.isna(eschool): continue\n",
    "        \n",
    "        # Convert to string if it's not already\n",
    "        eschool = str(eschool)\n",
    "            \n",
    "        # Extract the source table from Eschool field (before the dot)\n",
    "        source_parts = eschool.split('.')\n",
    "        source_table = source_parts[0] if len(source_parts) > 0 else eschool\n",
    "        \n",
    "        # Extract the source column from Eschool field (after the dot)\n",
    "        source_column = source_parts[1] if len(source_parts) > 1 else \"\"\n",
    "        \n",
    "        # Check for conditional mapping in TRANSFORMATION column\n",
    "        transformation_text = str(row['TRANSFORMATION']) if not pd.isna(row['TRANSFORMATION']) else \"\"\n",
    "        \n",
    "        # Determine mapping type and transformation\n",
    "        if \"if\" in transformation_text.lower() or \"when\" in transformation_text.lower() or \"=\" in transformation_text:\n",
    "            mapping_type = 'CONDITIONAL'\n",
    "            transformation = transformation_text\n",
    "            confidence = random.uniform(0.8, 1.0)\n",
    "        else:\n",
    "            mapping_type = 'DIRECT'\n",
    "            transformation = transformation_text\n",
    "            confidence = 1.0\n",
    "        \n",
    "        mapping_df.loc[i] = [\n",
    "            sheet_name,                  # TABLENAME\n",
    "            row['PowerSchoolFields'],    # TARGET_COLUMN\n",
    "            source_table,                # SOURCE_TABLE\n",
    "            source_column.strip(),       # SOURCE_COLUMN (trimming any whitespace)\n",
    "            mapping_type,                # MAPPING_TYPE - now dynamic\n",
    "            transformation,              # TRANSFORMATION - now includes logic when conditional\n",
    "            confidence,                  # CONFIDENCE - now varies based on mapping type\n",
    "            'ESP'                        # SOURCE_SIS_TYPE\n",
    "        ]\n",
    "    \n",
    "    return mapping_df\n",
    "\n",
    "\n",
    "def process_all_sheets(excel_file='esp_data_mod.xlsx', sheets=None, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    if sheets is None:\n",
    "        # Get all sheet names if not provided\n",
    "        sheets = pd.ExcelFile(excel_file).sheet_names\n",
    "    \n",
    "    all_sql = []\n",
    "    all_mappings = []\n",
    "    \n",
    "    for sheet in sheets:\n",
    "        print(f\"Processing sheet: {sheet}\")\n",
    "        try:\n",
    "            # Build mapping table for this sheet\n",
    "            mapping_df = build_mapping_table(sheet_name=sheet)\n",
    "            \n",
    "            # Generate SQL insert statement\n",
    "            sql = generate_data_mapping_insert(mapping_df, target_schema=target_schema)\n",
    "            \n",
    "            all_mappings.append(mapping_df)\n",
    "            all_sql.append(sql)\n",
    "            \n",
    "            print(f\"Successfully processed {len(mapping_df)} mappings from {sheet}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sheet {sheet}: {str(e)}\")\n",
    "    \n",
    "    # Combine all mappings into one dataframe\n",
    "    combined_mappings = pd.concat(all_mappings, ignore_index=True) if all_mappings else pd.DataFrame()\n",
    "    \n",
    "    # Join all SQL statements with newlines\n",
    "    combined_sql = \"\\n\\n\".join(all_sql)\n",
    "    \n",
    "    return combined_mappings, combined_sql\n",
    "\n",
    "\n",
    "def generate_data_mapping_insert_single(mapping_df, sheet_name, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    filtered_df = mapping_df[mapping_df['TABLENAME'] == sheet_name]\n",
    "    \n",
    "    # Create the INSERT statement header\n",
    "    insert_header = f\"\"\"INSERT INTO {target_schema}.DATA_MAPPING \n",
    "    (TABLENAME, TARGET_COLUMN, SOURCE_TABLE, SOURCE_COLUMN, MAPPING_TYPE, TRANSFORMATION, CONFIDENCE, SOURCE_SIS_TYPE)\n",
    "    VALUES \"\"\"\n",
    "    \n",
    "    # Create each row value\n",
    "    value_rows = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        # Clean and escape problematic values\n",
    "        tablename = row['TABLENAME'].replace(\"'\", \"''\") if isinstance(row['TABLENAME'], str) else row['TABLENAME']\n",
    "        target_column = row['TARGET_COLUMN'].replace(\"'\", \"''\") if isinstance(row['TARGET_COLUMN'], str) else row['TARGET_COLUMN']\n",
    "        target_column = target_column.replace('\\n', ' ').replace('(', '_').replace(')', '_') if isinstance(target_column, str) else target_column\n",
    "        \n",
    "        source_table = row['SOURCE_TABLE'].replace(\"'\", \"''\") if isinstance(row['SOURCE_TABLE'], str) else row['SOURCE_TABLE']\n",
    "        source_table = source_table.replace('\\n', ' ') if isinstance(source_table, str) else source_table\n",
    "        \n",
    "        source_column = row['SOURCE_COLUMN'].replace(\"'\", \"''\") if isinstance(row['SOURCE_COLUMN'], str) else row['SOURCE_COLUMN']\n",
    "        if isinstance(source_column, str):\n",
    "            source_column = source_column.replace('\\n', ' ')\n",
    "            if '=' in source_column or '>' in source_column or '<' in source_column:\n",
    "                source_column = source_column.split(',')[0] if ',' in source_column else source_column.split()[0]\n",
    "        \n",
    "        mapping_type = row['MAPPING_TYPE'].replace(\"'\", \"''\") if isinstance(row['MAPPING_TYPE'], str) else row['MAPPING_TYPE']\n",
    "        transformation = row['TRANSFORMATION'].replace(\"'\", \"''\") if isinstance(row['TRANSFORMATION'], str) else row['TRANSFORMATION']\n",
    "        \n",
    "        value_row = f\"('{tablename}', '{target_column}', '{source_table}', '{source_column}', \"\n",
    "        value_row += f\"'{mapping_type}', '{transformation}', {row['CONFIDENCE']}, '{row['SOURCE_SIS_TYPE']}')\"\n",
    "        value_rows.append(value_row)\n",
    "    \n",
    "    # Join all values with commas and add semicolon at the end\n",
    "    values_part = \",\\n\".join(value_rows) + \";\"\n",
    "    \n",
    "    # Combine header and values\n",
    "    return insert_header + \"\\n\" + values_part\n",
    "\n",
    "def execute_mappings_by_table(combined_mappings, tables=None):\n",
    "    if tables is None:\n",
    "        tables = combined_mappings['TABLENAME'].unique()\n",
    "    results = []\n",
    "    for table in tables:\n",
    "        print(f\"Processing table: {table}\")\n",
    "        try:\n",
    "            # Generate SQL for just this table\n",
    "            sql = generate_data_mapping_insert_single(combined_mappings, table)\n",
    "            execute_sql(sql)\n",
    "            print(f\"SQL generated: {sql[:100]}...\")\n",
    "            \n",
    "            results.append({\"table\": table, \"status\": \"success\"})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table {table}: {str(e)}\")\n",
    "            results.append({\"table\": table, \"status\": \"error\", \"message\": str(e)})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe1af3",
   "metadata": {
    "input_tokens": 43,
    "output_tokens": 1911,
    "solveit_ai": true
   },
   "source": [
    "help me make above code fasai style complinet and keep only the part we need to run execute_mappings_by_table rest all we an skip\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let me refactor the code to follow the fast.ai style, focusing only on what's needed for `execute_mappings_by_table`. I'll keep the essential functions and make them more concise:\n",
    "\n",
    "```python\n",
    "import pandas as pd, random\n",
    "\n",
    "def build_mapping_table(sheet_name='Student'):\n",
    "    \"Build mapping dataframe from Excel sheet\"\n",
    "    df = pd.read_excel('esp_data_mod.xlsx', sheet_name=sheet_name)\n",
    "    mapping_df = pd.DataFrame(columns=['TABLENAME', 'TARGET_COLUMN', 'SOURCE_TABLE', 'SOURCE_COLUMN', \n",
    "                                      'MAPPING_TYPE', 'TRANSFORMATION', 'CONFIDENCE', 'SOURCE_SIS_TYPE'])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        eschool = row['Eschool']\n",
    "        if pd.isna(eschool): continue\n",
    "        \n",
    "        eschool = str(eschool)\n",
    "        source_parts = eschool.split('.')\n",
    "        source_table = source_parts[0] if len(source_parts) > 0 else eschool\n",
    "        source_column = source_parts[1] if len(source_parts) > 1 else \"\"\n",
    "        \n",
    "        transformation_text = str(row['TRANSFORMATION']) if not pd.isna(row['TRANSFORMATION']) else \"\"\n",
    "        \n",
    "        if \"if\" in transformation_text.lower() or \"when\" in transformation_text.lower() or \"=\" in transformation_text:\n",
    "            mapping_type, transformation, confidence = 'CONDITIONAL', transformation_text, random.uniform(0.8, 1.0)\n",
    "        else:\n",
    "            mapping_type, transformation, confidence = 'DIRECT', transformation_text, 1.0\n",
    "        \n",
    "        mapping_df.loc[i] = [sheet_name, row['PowerSchoolFields'], source_table, \n",
    "                            source_column.strip(), mapping_type, transformation, confidence, 'ESP']\n",
    "    \n",
    "    return mapping_df\n",
    "```\n",
    "\n",
    "```python\n",
    "def generate_data_mapping_insert_single(mapping_df, sheet_name, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Generate SQL insert statement for a single table\"\n",
    "    filtered_df = mapping_df[mapping_df['TABLENAME'] == sheet_name]\n",
    "    \n",
    "    insert_header = f\"\"\"INSERT INTO {target_schema}.DATA_MAPPING \n",
    "    (TABLENAME, TARGET_COLUMN, SOURCE_TABLE, SOURCE_COLUMN, MAPPING_TYPE, TRANSFORMATION, CONFIDENCE, SOURCE_SIS_TYPE)\n",
    "    VALUES \"\"\"\n",
    "    \n",
    "    value_rows = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        tablename = row['TABLENAME'].replace(\"'\", \"''\") if isinstance(row['TABLENAME'], str) else row['TABLENAME']\n",
    "        target_column = row['TARGET_COLUMN'].replace(\"'\", \"''\") if isinstance(row['TARGET_COLUMN'], str) else row['TARGET_COLUMN']\n",
    "        target_column = target_column.replace('\\n', ' ').replace('(', '_').replace(')', '_') if isinstance(target_column, str) else target_column\n",
    "        \n",
    "        source_table = row['SOURCE_TABLE'].replace(\"'\", \"''\") if isinstance(row['SOURCE_TABLE'], str) else row['SOURCE_TABLE']\n",
    "        source_table = source_table.replace('\\n', ' ') if isinstance(source_table, str) else source_table\n",
    "        \n",
    "        source_column = row['SOURCE_COLUMN'].replace(\"'\", \"''\") if isinstance(row['SOURCE_COLUMN'], str) else row['SOURCE_COLUMN']\n",
    "        if isinstance(source_column, str):\n",
    "            source_column = source_column.replace('\\n', ' ')\n",
    "            if '=' in source_column or '>' in source_column or '<' in source_column:\n",
    "                source_column = source_column.split(',')[0] if ',' in source_column else source_column.split()[0]\n",
    "        \n",
    "        mapping_type = row['MAPPING_TYPE'].replace(\"'\", \"''\") if isinstance(row['MAPPING_TYPE'], str) else row['MAPPING_TYPE']\n",
    "        transformation = row['TRANSFORMATION'].replace(\"'\", \"''\") if isinstance(row['TRANSFORMATION'], str) else row['TRANSFORMATION']\n",
    "        \n",
    "        value_row = f\"('{tablename}', '{target_column}', '{source_table}', '{source_column}', '{mapping_type}', '{transformation}', {row['CONFIDENCE']}, '{row['SOURCE_SIS_TYPE']}')\"\n",
    "        value_rows.append(value_row)\n",
    "    \n",
    "    return insert_header + \"\\n\" + \",\\n\".join(value_rows) + \";\"\n",
    "```\n",
    "\n",
    "```python\n",
    "def process_all_sheets(excel_file='esp_data_mod.xlsx', sheets=None, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Process all sheets and generate mapping dataframe and SQL\"\n",
    "    if sheets is None: sheets = pd.ExcelFile(excel_file).sheet_names\n",
    "    \n",
    "    all_mappings = []\n",
    "    \n",
    "    for sheet in sheets:\n",
    "        print(f\"Processing sheet: {sheet}\")\n",
    "        try:\n",
    "            mapping_df = build_mapping_table(sheet_name=sheet)\n",
    "            all_mappings.append(mapping_df)\n",
    "            print(f\"Successfully processed {len(mapping_df)} mappings from {sheet}\")\n",
    "        except Exception as e: print(f\"Error processing sheet {sheet}: {str(e)}\")\n",
    "    \n",
    "    return pd.concat(all_mappings, ignore_index=True) if all_mappings else pd.DataFrame()\n",
    "```\n",
    "\n",
    "```python\n",
    "def execute_mappings_by_table(combined_mappings, tables=None):\n",
    "    \"Execute SQL mappings table by table\"\n",
    "    if tables is None: tables = combined_mappings['TABLENAME'].unique()\n",
    "    results = []\n",
    "    \n",
    "    for table in tables:\n",
    "        print(f\"Processing table: {table}\")\n",
    "        try:\n",
    "            sql = generate_data_mapping_insert_single(combined_mappings, table)\n",
    "            # Need to define execute_sql function or replace with actual implementation\n",
    "            execute_sql(sql)\n",
    "            print(f\"SQL generated: {sql[:100]}...\")\n",
    "            results.append(dict(table=table, status=\"success\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table {table}: {str(e)}\")\n",
    "            results.append(dict(table=table, status=\"error\", message=str(e)))\n",
    "    \n",
    "    return results\n",
    "```\n",
    "\n",
    "Now we need to define the missing `execute_sql` function:\n",
    "\n",
    "```python\n",
    "def execute_sql(sql):\n",
    "    \"Execute the SQL statement - placeholder function\"\n",
    "    # Replace with actual SQL execution logic\n",
    "    print(f\"Executing SQL: {sql[:50]}...\")\n",
    "    # For example: connection.execute(sql)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460ae94",
   "metadata": {
    "input_tokens": 1801,
    "time_run": "8:56:20a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, random\n",
    "\n",
    "def build_mapping_table(sheet_name='Student'):\n",
    "    \"Build mapping dataframe from Excel sheet\"\n",
    "    df = pd.read_excel('esp_data_mod.xlsx', sheet_name=sheet_name)\n",
    "    mapping_df = pd.DataFrame(columns=['TABLENAME', 'TARGET_COLUMN', 'SOURCE_TABLE', 'SOURCE_COLUMN', \n",
    "                                      'MAPPING_TYPE', 'TRANSFORMATION', 'CONFIDENCE', 'SOURCE_SIS_TYPE'])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        eschool = row['Eschool']\n",
    "        if pd.isna(eschool): continue\n",
    "        \n",
    "        eschool = str(eschool)\n",
    "        source_parts = eschool.split('.')\n",
    "        source_table = source_parts[0] if len(source_parts) > 0 else eschool\n",
    "        source_column = source_parts[1] if len(source_parts) > 1 else \"\"\n",
    "        \n",
    "        transformation_text = str(row['TRANSFORMATION']) if not pd.isna(row['TRANSFORMATION']) else \"\"\n",
    "        \n",
    "        if \"if\" in transformation_text.lower() or \"when\" in transformation_text.lower() or \"=\" in transformation_text:\n",
    "            mapping_type, transformation, confidence = 'CONDITIONAL', transformation_text, random.uniform(0.8, 1.0)\n",
    "        else:\n",
    "            mapping_type, transformation, confidence = 'DIRECT', transformation_text, 1.0\n",
    "        \n",
    "        mapping_df.loc[i] = [sheet_name, row['PowerSchoolFields'], source_table, \n",
    "                            source_column.strip(), mapping_type, transformation, confidence, 'ESP']\n",
    "    \n",
    "    return mapping_df\n",
    "\n",
    "def generate_data_mapping_insert_single(mapping_df, sheet_name, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Generate SQL insert statement for a single table\"\n",
    "    filtered_df = mapping_df[mapping_df['TABLENAME'] == sheet_name]\n",
    "    \n",
    "    insert_header = f\"\"\"INSERT INTO {target_schema}.DATA_MAPPING \n",
    "    (TABLENAME, TARGET_COLUMN, SOURCE_TABLE, SOURCE_COLUMN, MAPPING_TYPE, TRANSFORMATION, CONFIDENCE, SOURCE_SIS_TYPE)\n",
    "    VALUES \"\"\"\n",
    "    \n",
    "    value_rows = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        tablename = row['TABLENAME'].replace(\"'\", \"''\") if isinstance(row['TABLENAME'], str) else row['TABLENAME']\n",
    "        target_column = row['TARGET_COLUMN'].replace(\"'\", \"''\") if isinstance(row['TARGET_COLUMN'], str) else row['TARGET_COLUMN']\n",
    "        target_column = target_column.replace('\\n', ' ').replace('(', '_').replace(')', '_') if isinstance(target_column, str) else target_column\n",
    "        \n",
    "        source_table = row['SOURCE_TABLE'].replace(\"'\", \"''\") if isinstance(row['SOURCE_TABLE'], str) else row['SOURCE_TABLE']\n",
    "        source_table = source_table.replace('\\n', ' ') if isinstance(source_table, str) else source_table\n",
    "        \n",
    "        source_column = row['SOURCE_COLUMN'].replace(\"'\", \"''\") if isinstance(row['SOURCE_COLUMN'], str) else row['SOURCE_COLUMN']\n",
    "        if isinstance(source_column, str):\n",
    "            source_column = source_column.replace('\\n', ' ')\n",
    "            if '=' in source_column or '>' in source_column or '<' in source_column:\n",
    "                source_column = source_column.split(',')[0] if ',' in source_column else source_column.split()[0]\n",
    "        \n",
    "        mapping_type = row['MAPPING_TYPE'].replace(\"'\", \"''\") if isinstance(row['MAPPING_TYPE'], str) else row['MAPPING_TYPE']\n",
    "        transformation = row['TRANSFORMATION'].replace(\"'\", \"''\") if isinstance(row['TRANSFORMATION'], str) else row['TRANSFORMATION']\n",
    "        \n",
    "        value_row = f\"('{tablename}', '{target_column}', '{source_table}', '{source_column}', '{mapping_type}', '{transformation}', {row['CONFIDENCE']}, '{row['SOURCE_SIS_TYPE']}')\"\n",
    "        value_rows.append(value_row)\n",
    "    \n",
    "    return insert_header + \"\\n\" + \",\\n\".join(value_rows) + \";\"\n",
    "\n",
    "def process_all_sheets(excel_file='esp_data_mod.xlsx', sheets=None, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Process all sheets and generate mapping dataframe and SQL\"\n",
    "    if sheets is None: sheets = pd.ExcelFile(excel_file).sheet_names\n",
    "    \n",
    "    all_mappings = []\n",
    "    \n",
    "    for sheet in sheets:\n",
    "        print(f\"Processing sheet: {sheet}\")\n",
    "        try:\n",
    "            mapping_df = build_mapping_table(sheet_name=sheet)\n",
    "            all_mappings.append(mapping_df)\n",
    "            print(f\"Successfully processed {len(mapping_df)} mappings from {sheet}\")\n",
    "        except Exception as e: print(f\"Error processing sheet {sheet}: {str(e)}\")\n",
    "    \n",
    "    return pd.concat(all_mappings, ignore_index=True) if all_mappings else pd.DataFrame()\n",
    "\n",
    "def execute_mappings_by_table(combined_mappings, tables=None):\n",
    "    \"Execute SQL mappings table by table\"\n",
    "    if tables is None: tables = combined_mappings['TABLENAME'].unique()\n",
    "    results = []\n",
    "    \n",
    "    for table in tables:\n",
    "        print(f\"Processing table: {table}\")\n",
    "        try:\n",
    "            sql = generate_data_mapping_insert_single(combined_mappings, table)\n",
    "            # Need to define execute_sql function or replace with actual implementation\n",
    "            # execute_sql(sql)\n",
    "            print(f\"SQL generated: {sql[:100]}...\")\n",
    "            results.append(dict(table=table, status=\"success\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table {table}: {str(e)}\")\n",
    "            results.append(dict(table=table, status=\"error\", message=str(e)))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def execute_sql(sql):\n",
    "    \"Execute the SQL statement - placeholder function\"\n",
    "    # Replace with actual SQL execution logic\n",
    "    print(f\"Executing SQL: {sql[:50]}...\")\n",
    "    # For example: connection.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30de50f",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 297,
    "solveit_ai": true,
    "time_run": "8:56:43a"
   },
   "source": [
    "help me test it\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's test the code by running it on your Excel file. First, let's create a simple test function that processes a single sheet and shows the results:\n",
    "\n",
    "```python\n",
    "def test_mapping():\n",
    "    # Process just the first sheet to test\n",
    "    sheet_name = 'Students'\n",
    "    mapping_df = build_mapping_table(sheet_name=sheet_name)\n",
    "    \n",
    "    # Show summary of the mapping\n",
    "    print(f\"Created {len(mapping_df)} mappings for {sheet_name}\")\n",
    "    print(f\"Sample of mapping data:\")\n",
    "    if len(mapping_df) > 0: \n",
    "        display(mapping_df.head(3))\n",
    "        \n",
    "        # Generate and show sample SQL\n",
    "        sql = generate_data_mapping_insert_single(mapping_df, sheet_name)\n",
    "        print(f\"\\nSample SQL (first 500 chars):\\n{sql[:500]}...\")\n",
    "    else:\n",
    "        print(\"No mappings created\")\n",
    "    \n",
    "    return mapping_df\n",
    "```\n",
    "\n",
    "Let's run this test function:\n",
    "\n",
    "```python\n",
    "test_df = test_mapping()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba93e1b",
   "metadata": {
    "input_tokens": 231,
    "time_run": "8:59:39a"
   },
   "outputs": [],
   "source": [
    "def test_mapping():\n",
    "    # Process just the first sheet to test\n",
    "    sheet_name = 'Students'\n",
    "    # mapping_df = build_mapping_table(sheet_name=sheet_name)\n",
    "    mapping_df = build_mapping_table()\n",
    "\n",
    "    # Show summary of the mapping\n",
    "    print(f\"Created {len(mapping_df)} mappings for {sheet_name}\")\n",
    "    print(f\"Sample of mapping data:\")\n",
    "    if len(mapping_df) > 0: \n",
    "        display(mapping_df.head(3))\n",
    "        \n",
    "        # Generate and show sample SQL\n",
    "        sql = generate_data_mapping_insert_single(mapping_df, sheet_name)\n",
    "        print(f\"\\nSample SQL (first 500 chars):\\n{sql[:500]}...\")\n",
    "    else:\n",
    "        print(\"No mappings created\")\n",
    "    \n",
    "    return mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7aa84e",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 5164,
    "time_run": "9:00:17a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_333e3 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_333e3 td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_333e3 tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_333e3 tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_333e3\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_333e3_level0_col0\" class=\"col_heading level0 col0\" >TABLENAME</th>\n",
       "      <th id=\"T_333e3_level0_col1\" class=\"col_heading level0 col1\" >TARGET_COLUMN</th>\n",
       "      <th id=\"T_333e3_level0_col2\" class=\"col_heading level0 col2\" >SOURCE_TABLE</th>\n",
       "      <th id=\"T_333e3_level0_col3\" class=\"col_heading level0 col3\" >SOURCE_COLUMN</th>\n",
       "      <th id=\"T_333e3_level0_col4\" class=\"col_heading level0 col4\" >MAPPING_TYPE</th>\n",
       "      <th id=\"T_333e3_level0_col5\" class=\"col_heading level0 col5\" >TRANSFORMATION</th>\n",
       "      <th id=\"T_333e3_level0_col6\" class=\"col_heading level0 col6\" >CONFIDENCE</th>\n",
       "      <th id=\"T_333e3_level0_col7\" class=\"col_heading level0 col7\" >SOURCE_SIS_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_333e3_row0_col0\" class=\"data row0 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row0_col1\" class=\"data row0 col1\" >Student_Number</td>\n",
       "      <td id=\"T_333e3_row0_col2\" class=\"data row0 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row0_col3\" class=\"data row0 col3\" >STUDENT_ID</td>\n",
       "      <td id=\"T_333e3_row0_col4\" class=\"data row0 col4\" >CONDITIONAL</td>\n",
       "      <td id=\"T_333e3_row0_col5\" class=\"data row0 col5\" >Unique identifier for the student\n",
       "eSchoolPlus STUDENTID is type char(10), it is part of a compound primary key with \"DISTRICT\".\n",
       "Check for alpha characters and leading zeros</td>\n",
       "      <td id=\"T_333e3_row0_col6\" class=\"data row0 col6\" >0.823</td>\n",
       "      <td id=\"T_333e3_row0_col7\" class=\"data row0 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_333e3_row1_col0\" class=\"data row1 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row1_col1\" class=\"data row1 col1\" >SchoolID</td>\n",
       "      <td id=\"T_333e3_row1_col2\" class=\"data row1 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row1_col3\" class=\"data row1 col3\" >BUILDING</td>\n",
       "      <td id=\"T_333e3_row1_col4\" class=\"data row1 col4\" >CONDITIONAL</td>\n",
       "      <td id=\"T_333e3_row1_col5\" class=\"data row1 col5\" >SchoolID is used to ensure student is placed into the correct school in a district. (Must be used when importing students at the District level and must match a school number in PowerSchool.)</td>\n",
       "      <td id=\"T_333e3_row1_col6\" class=\"data row1 col6\" >0.992</td>\n",
       "      <td id=\"T_333e3_row1_col7\" class=\"data row1 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_333e3_row2_col0\" class=\"data row2 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row2_col1\" class=\"data row2 col1\" >First_Name</td>\n",
       "      <td id=\"T_333e3_row2_col2\" class=\"data row2 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row2_col3\" class=\"data row2 col3\" >FIRST_NAME</td>\n",
       "      <td id=\"T_333e3_row2_col4\" class=\"data row2 col4\" >DIRECT</td>\n",
       "      <td id=\"T_333e3_row2_col5\" class=\"data row2 col5\" >First Name of  student.  </td>\n",
       "      <td id=\"T_333e3_row2_col6\" class=\"data row2 col6\" >1.000</td>\n",
       "      <td id=\"T_333e3_row2_col7\" class=\"data row2 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_333e3_row3_col0\" class=\"data row3 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row3_col1\" class=\"data row3 col1\" >Middle_Name</td>\n",
       "      <td id=\"T_333e3_row3_col2\" class=\"data row3 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row3_col3\" class=\"data row3 col3\" >MIDDLE_NAME</td>\n",
       "      <td id=\"T_333e3_row3_col4\" class=\"data row3 col4\" >DIRECT</td>\n",
       "      <td id=\"T_333e3_row3_col5\" class=\"data row3 col5\" >Middle Name of student</td>\n",
       "      <td id=\"T_333e3_row3_col6\" class=\"data row3 col6\" >1.000</td>\n",
       "      <td id=\"T_333e3_row3_col7\" class=\"data row3 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_333e3_row4_col0\" class=\"data row4 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row4_col1\" class=\"data row4 col1\" >Last_Name</td>\n",
       "      <td id=\"T_333e3_row4_col2\" class=\"data row4 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row4_col3\" class=\"data row4 col3\" >LAST_NAME</td>\n",
       "      <td id=\"T_333e3_row4_col4\" class=\"data row4 col4\" >DIRECT</td>\n",
       "      <td id=\"T_333e3_row4_col5\" class=\"data row4 col5\" >Last Name of  student</td>\n",
       "      <td id=\"T_333e3_row4_col6\" class=\"data row4 col6\" >1.000</td>\n",
       "      <td id=\"T_333e3_row4_col7\" class=\"data row4 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_333e3_row5_col0\" class=\"data row5 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row5_col1\" class=\"data row5 col1\" >Grade_Level</td>\n",
       "      <td id=\"T_333e3_row5_col2\" class=\"data row5 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row5_col3\" class=\"data row5 col3\" >GRADE \n",
       "or\n",
       "REG_ENTRY_WITH</td>\n",
       "      <td id=\"T_333e3_row5_col4\" class=\"data row5 col4\" >CONDITIONAL</td>\n",
       "      <td id=\"T_333e3_row5_col5\" class=\"data row5 col5\" >Grade level for the student.\n",
       "\n",
       "Kindergarten=0 \n",
       "PK4 = -1\n",
       "PK3 = -2\n",
       "Imports will accept -3 and -4 for grade levels lower than PK4 and PK3.\n",
       "\n",
       "use the GRADE associated with entry and exit date used for the \"STUDENTS\" record</td>\n",
       "      <td id=\"T_333e3_row5_col6\" class=\"data row5 col6\" >0.910</td>\n",
       "      <td id=\"T_333e3_row5_col7\" class=\"data row5 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_333e3_row6_col0\" class=\"data row6 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row6_col1\" class=\"data row6 col1\" >Home_Phone</td>\n",
       "      <td id=\"T_333e3_row6_col2\" class=\"data row6 col2\" >REG_CONTACT_PHONE</td>\n",
       "      <td id=\"T_333e3_row6_col3\" class=\"data row6 col3\" >PHONE</td>\n",
       "      <td id=\"T_333e3_row6_col4\" class=\"data row6 col4\" >CONDITIONAL</td>\n",
       "      <td id=\"T_333e3_row6_col5\" class=\"data row6 col5\" >Student's home phone number.  Should be formatted the same for all students in order for Family Management to use this field for matching.\n",
       "\n",
       "Join REG > REG_STU_CONTACT (where CONTACT_TYPE = 'P' {physical address} > REG_CONTACT_PHONE (where PHONE_TYPE = Home {REGTB_PHON}\n",
       "possible multiple home phone records.  or client may want other phone types such as mobile cell phone</td>\n",
       "      <td id=\"T_333e3_row6_col6\" class=\"data row6 col6\" >0.834</td>\n",
       "      <td id=\"T_333e3_row6_col7\" class=\"data row6 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_333e3_row7_col0\" class=\"data row7 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row7_col1\" class=\"data row7 col1\" >Gender</td>\n",
       "      <td id=\"T_333e3_row7_col2\" class=\"data row7 col2\" >REG</td>\n",
       "      <td id=\"T_333e3_row7_col3\" class=\"data row7 col3\" >GENDER</td>\n",
       "      <td id=\"T_333e3_row7_col4\" class=\"data row7 col4\" >DIRECT</td>\n",
       "      <td id=\"T_333e3_row7_col5\" class=\"data row7 col5\" >Students gender.  Must be either M or F.</td>\n",
       "      <td id=\"T_333e3_row7_col6\" class=\"data row7 col6\" >1.000</td>\n",
       "      <td id=\"T_333e3_row7_col7\" class=\"data row7 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_333e3_row8_col0\" class=\"data row8 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row8_col1\" class=\"data row8 col1\" >Ethnicity</td>\n",
       "      <td id=\"T_333e3_row8_col2\" class=\"data row8 col2\" >REG_PERSONAL</td>\n",
       "      <td id=\"T_333e3_row8_col3\" class=\"data row8 col3\" >ETHNIC_CODE</td>\n",
       "      <td id=\"T_333e3_row8_col4\" class=\"data row8 col4\" >CONDITIONAL</td>\n",
       "      <td id=\"T_333e3_row8_col5\" class=\"data row8 col5\" >Scheduling/Reporting Ethnicity is used for the Enrollment Summary screen in PowerSchool. Additional set up may be necessary for Federal Ethnicity. Students ethnicity.  Must match a value defined as an Ethnicity Code in District Level such as \n",
       "\n",
       "C = Caucasian  \n",
       "H = Hispanic\n",
       "4-character max.\n",
       "\n",
       "check REGTB_ETHNICITY for definitions</td>\n",
       "      <td id=\"T_333e3_row8_col6\" class=\"data row8 col6\" >0.822</td>\n",
       "      <td id=\"T_333e3_row8_col7\" class=\"data row8 col7\" >ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333e3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_333e3_row9_col0\" class=\"data row9 col0\" >Students</td>\n",
       "      <td id=\"T_333e3_row9_col1\" class=\"data row9 col1\" >FedEthnicity</td>\n",
       "      <td id=\"T_333e3_row9_col2\" class=\"data row9 col2\" >REG_PERSONAL</td>\n",
       "      <td id=\"T_333e3_row9_col3\" class=\"data row9 col3\" >HISPANIC</td>\n",
       "      <td id=\"T_333e3_row9_col4\" class=\"data row9 col4\" >CONDITIONAL</td>\n",
       "      <td id=\"T_333e3_row9_col5\" class=\"data row9 col5\" >Ethnicity: Is the student Hispanic or Latino?                           0=No                                   1=Yes\n",
       "\n",
       "if \"Y\" then 1 else 0</td>\n",
       "      <td id=\"T_333e3_row9_col6\" class=\"data row9 col6\" >0.987</td>\n",
       "      <td id=\"T_333e3_row9_col7\" class=\"data row9 col7\" >ESP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "   TABLENAME           TARGET_COLUMN  ... CONFIDENCE SOURCE_SIS_TYPE\n",
       "0   Students          Student_Number  ...   0.822862             ESP\n",
       "1   Students                SchoolID  ...   0.991780             ESP\n",
       "2   Students              First_Name  ...   1.000000             ESP\n",
       "3   Students             Middle_Name  ...   1.000000             ESP\n",
       "4   Students               Last_Name  ...   1.000000             ESP\n",
       "5   Students             Grade_Level  ...   0.909517             ESP\n",
       "6   Students              Home_Phone  ...   0.834051             ESP\n",
       "7   Students                  Gender  ...   1.000000             ESP\n",
       "8   Students               Ethnicity  ...   0.821829             ESP\n",
       "9   Students            FedEthnicity  ...   0.987374             ESP\n",
       "10  Students                     DOB  ...   1.000000             ESP\n",
       "11  Students                     SSN  ...   1.000000             ESP\n",
       "13  Students           Enroll_Status  ...   0.907408             ESP\n",
       "14  Students               EntryDate  ...   1.000000             ESP\n",
       "15  Students                ExitDate  ...   1.000000             ESP\n",
       "16  Students       Districtentrydate  ...   1.000000             ESP\n",
       "17  Students         Schoolentrydate  ...   1.000000             ESP\n",
       "18  Students               EntryCode  ...   1.000000             ESP\n",
       "19  Students                  Street  ...   0.917359             ESP\n",
       "20  Students                    City  ...   0.887968             ESP\n",
       "21  Students                   State  ...   0.805816             ESP\n",
       "22  Students                     Zip  ...   0.950096             ESP\n",
       "23  Students          Mailing_Street  ...   0.888448             ESP\n",
       "24  Students            Mailing_City  ...   0.837442             ESP\n",
       "25  Students           Mailing_State  ...   0.846234             ESP\n",
       "26  Students             Mailing_Zip  ...   0.887526             ESP\n",
       "27  Students     Sched_NextYearGrade  ...   1.000000             ESP\n",
       "28  Students             Next_School  ...   1.000000             ESP\n",
       "29  Students         Sched_Scheduled  ...   1.000000             ESP\n",
       "30  Students  Sched_YearOfGraduation  ...   0.811550             ESP\n",
       "31  Students         TransferComment  ...   1.000000             ESP\n",
       "32  Students            Family_Ident  ...   0.859498             ESP\n",
       "33  Students                  Father  ...   1.000000             ESP\n",
       "34  Students          fatherdayphone  ...   1.000000             ESP\n",
       "35  Students       Father_home_phone  ...   1.000000             ESP\n",
       "36  Students         Father_Employer  ...   1.000000             ESP\n",
       "37  Students                  Mother  ...   1.000000             ESP\n",
       "38  Students          MotherDayPhone  ...   1.000000             ESP\n",
       "39  Students       Mother_home_phone  ...   1.000000             ESP\n",
       "40  Students         Mother_Employer  ...   1.000000             ESP\n",
       "41  Students            Guardianship  ...   1.000000             ESP\n",
       "42  Students             Guardian_ln  ...   1.000000             ESP\n",
       "43  Students             Guardian_fn  ...   1.000000             ESP\n",
       "44  Students             guardian_mn  ...   1.000000             ESP\n",
       "45  Students           GuardianEmail  ...   1.000000             ESP\n",
       "46  Students        GuardianDayPhone  ...   1.000000             ESP\n",
       "47  Students         Emerg_Contact 1  ...   0.820863             ESP\n",
       "48  Students             Emerg_1_rel  ...   1.000000             ESP\n",
       "49  Students           Emerg_1_Ptype  ...   1.000000             ESP\n",
       "50  Students           Emerg_Phone_1  ...   1.000000             ESP\n",
       "51  Students         Emerg_Contact_2  ...   0.967729             ESP\n",
       "52  Students             Emerg_2_rel  ...   1.000000             ESP\n",
       "53  Students           Emerg_2_Ptype  ...   1.000000             ESP\n",
       "54  Students           Emerg_Phone_2  ...   1.000000             ESP\n",
       "55  Students         Emerg_Contact_3  ...   0.841729             ESP\n",
       "56  Students             Emerg_3_rel  ...   1.000000             ESP\n",
       "57  Students           Emerg_3_Ptype  ...   1.000000             ESP\n",
       "58  Students           Emerg_3_Phone  ...   1.000000             ESP\n",
       "59  Students               home_room  ...   1.000000             ESP\n",
       "\n",
       "[59 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb69275",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 21,
    "time_run": "9:00:25a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f53fc",
   "metadata": {
    "input_tokens": 30,
    "output_tokens": 1743,
    "solveit_ai": true
   },
   "source": [
    "modify to take file path as agument nas and sis table name/sheetname as aggumenttoo\n",
    "\n",
    "##### Reply<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's modify the code to take file path and sheet name as arguments, following the fast.ai style:\n",
    "\n",
    "```python\n",
    "def build_mapping_table(file_path='esp_data_mod.xlsx', sheet_name='Students'):\n",
    "    \"Build mapping dataframe from Excel sheet\"\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    mapping_df = pd.DataFrame(columns=['TABLENAME', 'TARGET_COLUMN', 'SOURCE_TABLE', 'SOURCE_COLUMN', \n",
    "                                      'MAPPING_TYPE', 'TRANSFORMATION', 'CONFIDENCE', 'SOURCE_SIS_TYPE'])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        eschool = row['Eschool']\n",
    "        if pd.isna(eschool): continue\n",
    "        \n",
    "        eschool = str(eschool)\n",
    "        source_parts = eschool.split('.')\n",
    "        source_table = source_parts[0] if len(source_parts) > 0 else eschool\n",
    "        source_column = source_parts[1] if len(source_parts) > 1 else \"\"\n",
    "        \n",
    "        transformation_text = str(row['TRANSFORMATION']) if not pd.isna(row['TRANSFORMATION']) else \"\"\n",
    "        \n",
    "        if \"if\" in transformation_text.lower() or \"when\" in transformation_text.lower() or \"=\" in transformation_text:\n",
    "            mapping_type, transformation, confidence = 'CONDITIONAL', transformation_text, random.uniform(0.8, 1.0)\n",
    "        else:\n",
    "            mapping_type, transformation, confidence = 'DIRECT', transformation_text, 1.0\n",
    "        \n",
    "        mapping_df.loc[i] = [sheet_name, row['PowerSchoolFields'], source_table, \n",
    "                            source_column.strip(), mapping_type, transformation, confidence, 'ESP']\n",
    "    \n",
    "    return mapping_df\n",
    "```\n",
    "\n",
    "Let's also update the other functions to take file path and sheet name as arguments:\n",
    "\n",
    "```python\n",
    "def generate_data_mapping_insert_single(mapping_df, sheet_name, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Generate SQL insert statement for a single table\"\n",
    "    filtered_df = mapping_df[mapping_df['TABLENAME'] == sheet_name]\n",
    "    \n",
    "    insert_header = f\"\"\"INSERT INTO {target_schema}.DATA_MAPPING \n",
    "    (TABLENAME, TARGET_COLUMN, SOURCE_TABLE, SOURCE_COLUMN, MAPPING_TYPE, TRANSFORMATION, CONFIDENCE, SOURCE_SIS_TYPE)\n",
    "    VALUES \"\"\"\n",
    "    \n",
    "    value_rows = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        tablename = row['TABLENAME'].replace(\"'\", \"''\") if isinstance(row['TABLENAME'], str) else row['TABLENAME']\n",
    "        target_column = row['TARGET_COLUMN'].replace(\"'\", \"''\") if isinstance(row['TARGET_COLUMN'], str) else row['TARGET_COLUMN']\n",
    "        target_column = target_column.replace('\\n', ' ').replace('(', '_').replace(')', '_') if isinstance(target_column, str) else target_column\n",
    "        \n",
    "        source_table = row['SOURCE_TABLE'].replace(\"'\", \"''\") if isinstance(row['SOURCE_TABLE'], str) else row['SOURCE_TABLE']\n",
    "        source_table = source_table.replace('\\n', ' ') if isinstance(source_table, str) else source_table\n",
    "        \n",
    "        source_column = row['SOURCE_COLUMN'].replace(\"'\", \"''\") if isinstance(row['SOURCE_COLUMN'], str) else row['SOURCE_COLUMN']\n",
    "        if isinstance(source_column, str):\n",
    "            source_column = source_column.replace('\\n', ' ')\n",
    "            if '=' in source_column or '>' in source_column or '<' in source_column:\n",
    "                source_column = source_column.split(',')[0] if ',' in source_column else source_column.split()[0]\n",
    "        \n",
    "        mapping_type = row['MAPPING_TYPE'].replace(\"'\", \"''\") if isinstance(row['MAPPING_TYPE'], str) else row['MAPPING_TYPE']\n",
    "        transformation = row['TRANSFORMATION'].replace(\"'\", \"''\") if isinstance(row['TRANSFORMATION'], str) else row['TRANSFORMATION']\n",
    "        \n",
    "        value_row = f\"('{tablename}', '{target_column}', '{source_table}', '{source_column}', '{mapping_type}', '{transformation}', {row['CONFIDENCE']}, '{row['SOURCE_SIS_TYPE']}')\"\n",
    "        value_rows.append(value_row)\n",
    "    \n",
    "    return insert_header + \"\\n\" + \",\\n\".join(value_rows) + \";\" if value_rows else \"\"\n",
    "```\n",
    "\n",
    "```python\n",
    "def execute_mappings_by_table(file_path='esp_data_mod.xlsx', tables=None, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Process and execute SQL mappings table by table\"\n",
    "    if tables is None: \n",
    "        tables = pd.ExcelFile(file_path).sheet_names\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for table in tables:\n",
    "        print(f\"Processing table: {table}\")\n",
    "        try:\n",
    "            mapping_df = build_mapping_table(file_path=file_path, sheet_name=table)\n",
    "            sql = generate_data_mapping_insert_single(mapping_df, table, target_schema)\n",
    "            if sql:\n",
    "                # Replace with actual SQL execution\n",
    "                print(f\"SQL generated for {table}: {len(sql)} characters\")\n",
    "                results.append(dict(table=table, status=\"success\", rows=len(mapping_df)))\n",
    "            else:\n",
    "                print(f\"No mappings found for {table}\")\n",
    "                results.append(dict(table=table, status=\"empty\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table {table}: {str(e)}\")\n",
    "            results.append(dict(table=table, status=\"error\", message=str(e)))\n",
    "    \n",
    "    return results\n",
    "```\n",
    "\n",
    "Let's create a test function to try it out:\n",
    "\n",
    "```python\n",
    "def test_execute():\n",
    "    \"Test the execute_mappings_by_table function with one sheet\"\n",
    "    results = execute_mappings_by_table(file_path='esp_data_mod.xlsx', tables=['Students'])\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf89c6d",
   "metadata": {
    "input_tokens": 1645,
    "time_run": "9:22:00a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_mapping_table(file_path='esp_data_mod.xlsx', sheet_name='Students'):\n",
    "    \"Build mapping dataframe from Excel sheet\"\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    mapping_df = pd.DataFrame(columns=['TABLENAME', 'TARGET_COLUMN', 'SOURCE_TABLE', 'SOURCE_COLUMN', \n",
    "                                      'MAPPING_TYPE', 'TRANSFORMATION', 'CONFIDENCE', 'SOURCE_SIS_TYPE'])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        eschool = row['Eschool']\n",
    "        if pd.isna(eschool): continue\n",
    "        \n",
    "        eschool = str(eschool)\n",
    "        source_parts = eschool.split('.')\n",
    "        source_table = source_parts[0] if len(source_parts) > 0 else eschool\n",
    "        source_column = source_parts[1] if len(source_parts) > 1 else \"\"\n",
    "        \n",
    "        transformation_text = str(row['TRANSFORMATION']) if not pd.isna(row['TRANSFORMATION']) else \"\"\n",
    "        \n",
    "        if \"if\" in transformation_text.lower() or \"when\" in transformation_text.lower() or \"=\" in transformation_text:\n",
    "            mapping_type, transformation, confidence = 'CONDITIONAL', transformation_text, random.uniform(0.8, 1.0)\n",
    "        else:\n",
    "            mapping_type, transformation, confidence = 'DIRECT', transformation_text, 1.0\n",
    "        \n",
    "        mapping_df.loc[i] = [sheet_name, row['PowerSchoolFields'], source_table, \n",
    "                            source_column.strip(), mapping_type, transformation, confidence, 'ESP']\n",
    "    \n",
    "    return mapping_df\n",
    "\n",
    "\n",
    "def generate_data_mapping_insert_single(mapping_df, sheet_name, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Generate SQL insert statement for a single table\"\n",
    "    filtered_df = mapping_df[mapping_df['TABLENAME'] == sheet_name]\n",
    "    \n",
    "    insert_header = f\"\"\"INSERT INTO {target_schema}.DATA_MAPPING \n",
    "    (TABLENAME, TARGET_COLUMN, SOURCE_TABLE, SOURCE_COLUMN, MAPPING_TYPE, TRANSFORMATION, CONFIDENCE, SOURCE_SIS_TYPE)\n",
    "    VALUES \"\"\"\n",
    "    \n",
    "    value_rows = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        tablename = row['TABLENAME'].replace(\"'\", \"''\") if isinstance(row['TABLENAME'], str) else row['TABLENAME']\n",
    "        target_column = row['TARGET_COLUMN'].replace(\"'\", \"''\") if isinstance(row['TARGET_COLUMN'], str) else row['TARGET_COLUMN']\n",
    "        target_column = target_column.replace('\\n', ' ').replace('(', '_').replace(')', '_') if isinstance(target_column, str) else target_column\n",
    "        \n",
    "        source_table = row['SOURCE_TABLE'].replace(\"'\", \"''\") if isinstance(row['SOURCE_TABLE'], str) else row['SOURCE_TABLE']\n",
    "        source_table = source_table.replace('\\n', ' ') if isinstance(source_table, str) else source_table\n",
    "        \n",
    "        source_column = row['SOURCE_COLUMN'].replace(\"'\", \"''\") if isinstance(row['SOURCE_COLUMN'], str) else row['SOURCE_COLUMN']\n",
    "        if isinstance(source_column, str):\n",
    "            source_column = source_column.replace('\\n', ' ')\n",
    "            if '=' in source_column or '>' in source_column or '<' in source_column:\n",
    "                source_column = source_column.split(',')[0] if ',' in source_column else source_column.split()[0]\n",
    "        \n",
    "        mapping_type = row['MAPPING_TYPE'].replace(\"'\", \"''\") if isinstance(row['MAPPING_TYPE'], str) else row['MAPPING_TYPE']\n",
    "        transformation = row['TRANSFORMATION'].replace(\"'\", \"''\") if isinstance(row['TRANSFORMATION'], str) else row['TRANSFORMATION']\n",
    "        \n",
    "        value_row = f\"('{tablename}', '{target_column}', '{source_table}', '{source_column}', '{mapping_type}', '{transformation}', {row['CONFIDENCE']}, '{row['SOURCE_SIS_TYPE']}')\"\n",
    "        value_rows.append(value_row)\n",
    "    \n",
    "    return insert_header + \"\\n\" + \",\\n\".join(value_rows) + \";\" if value_rows else \"\"\n",
    "\n",
    "def execute_mappings_by_table(file_path='esp_data_mod.xlsx', tables=None, target_schema=\"PSESSENTIALS.SG_ESPSTAGING2\"):\n",
    "    \"Process and execute SQL mappings table by table\"\n",
    "    if tables is None: \n",
    "        tables = pd.ExcelFile(file_path).sheet_names\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for table in tables:\n",
    "        print(f\"Processing table: {table}\")\n",
    "        try:\n",
    "            mapping_df = build_mapping_table(file_path=file_path, sheet_name=table)\n",
    "            sql = generate_data_mapping_insert_single(mapping_df, table, target_schema)\n",
    "            if sql:\n",
    "                # Replace with actual SQL execution\n",
    "                print(f\"SQL generated for {table}: {len(sql)} characters\")\n",
    "                results.append(dict(table=table, status=\"success\", rows=len(mapping_df)))\n",
    "            else:\n",
    "                print(f\"No mappings found for {table}\")\n",
    "                results.append(dict(table=table, status=\"empty\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table {table}: {str(e)}\")\n",
    "            results.append(dict(table=table, status=\"error\", message=str(e)))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def test_execute():\n",
    "    \"Test the execute_mappings_by_table function with one sheet\"\n",
    "    results = execute_mappings_by_table(file_path='esp_data_mod.xlsx', tables=['Students'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf9057",
   "metadata": {
    "input_tokens": 61,
    "time_run": "9:22:30a"
   },
   "outputs": [],
   "source": [
    "def test_execute():\n",
    "    \"Test the execute_mappings_by_table function with one sheet\"\n",
    "    results = execute_mappings_by_table(file_path='esp_data_mod.xlsx', tables=['Students'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48beef5b",
   "metadata": {
    "input_tokens": 19,
    "output_tokens": 1081,
    "time_run": "9:25:08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Students\n",
      "SQL generated for Students: 12984 characters\n",
      "Processing table: Re-enrollment\n",
      "SQL generated for Re-enrollment: 1845 characters\n",
      "Processing table: Immunization\n",
      "SQL generated for Immunization: 1404 characters\n",
      "Processing table: Historical_Grades\n",
      "SQL generated for Historical_Grades: 4163 characters\n",
      "Processing table: Test Scores\n",
      "SQL generated for Test Scores: 474 characters\n",
      "Processing table: Staff_Teacher\n",
      "SQL generated for Staff_Teacher: 6682 characters\n",
      "Processing table: Courses\n",
      "SQL generated for Courses: 2906 characters\n",
      "Processing table: Section\n",
      "SQL generated for Section: 3321 characters\n",
      "Processing table: Section Enrollment\n",
      "SQL generated for Section Enrollment: 1331 characters\n",
      "Processing table: Rooms\n",
      "SQL generated for Rooms: 579 characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'table': 'Students', 'status': 'success', 'rows': 59},\n",
       " {'table': 'Re-enrollment', 'status': 'success', 'rows': 9},\n",
       " {'table': 'Immunization', 'status': 'success', 'rows': 7},\n",
       " {'table': 'Historical_Grades', 'status': 'success', 'rows': 18},\n",
       " {'table': 'Test Scores', 'status': 'success', 'rows': 2},\n",
       " {'table': 'Staff_Teacher', 'status': 'success', 'rows': 48},\n",
       " {'table': 'Courses', 'status': 'success', 'rows': 11},\n",
       " {'table': 'Section', 'status': 'success', 'rows': 13},\n",
       " {'table': 'Section Enrollment', 'status': 'success', 'rows': 7},\n",
       " {'table': 'Rooms', 'status': 'success', 'rows': 3}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_mappings_by_table(file_path='esp_data_mod.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4bcbf",
   "metadata": {
    "input_tokens": 16,
    "output_tokens": 180,
    "time_run": "9:23:46a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Students',\n",
       " 'Re-enrollment',\n",
       " 'Immunization',\n",
       " 'Historical_Grades',\n",
       " 'Test Scores',\n",
       " 'Staff_Teacher',\n",
       " 'Courses',\n",
       " 'Section',\n",
       " 'Section Enrollment',\n",
       " 'Rooms']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls = pd.ExcelFile(file_path)\n",
    "xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076277b7",
   "metadata": {
    "input_tokens": 28,
    "output_tokens": 1081,
    "time_run": "9:24:05a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Students\n",
      "SQL generated for Students: 12985 characters\n",
      "Processing table: Re-enrollment\n",
      "SQL generated for Re-enrollment: 1845 characters\n",
      "Processing table: Immunization\n",
      "SQL generated for Immunization: 1403 characters\n",
      "Processing table: Historical_Grades\n",
      "SQL generated for Historical_Grades: 4164 characters\n",
      "Processing table: Test Scores\n",
      "SQL generated for Test Scores: 474 characters\n",
      "Processing table: Staff_Teacher\n",
      "SQL generated for Staff_Teacher: 6681 characters\n",
      "Processing table: Courses\n",
      "SQL generated for Courses: 2904 characters\n",
      "Processing table: Section\n",
      "SQL generated for Section: 3321 characters\n",
      "Processing table: Section Enrollment\n",
      "SQL generated for Section Enrollment: 1331 characters\n",
      "Processing table: Rooms\n",
      "SQL generated for Rooms: 579 characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'table': 'Students', 'status': 'success', 'rows': 59},\n",
       " {'table': 'Re-enrollment', 'status': 'success', 'rows': 9},\n",
       " {'table': 'Immunization', 'status': 'success', 'rows': 7},\n",
       " {'table': 'Historical_Grades', 'status': 'success', 'rows': 18},\n",
       " {'table': 'Test Scores', 'status': 'success', 'rows': 2},\n",
       " {'table': 'Staff_Teacher', 'status': 'success', 'rows': 48},\n",
       " {'table': 'Courses', 'status': 'success', 'rows': 11},\n",
       " {'table': 'Section', 'status': 'success', 'rows': 13},\n",
       " {'table': 'Section Enrollment', 'status': 'success', 'rows': 7},\n",
       " {'table': 'Rooms', 'status': 'success', 'rows': 3}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_mappings_by_table(file_path='esp_data_mod.xlsx', tables=xls.sheet_names)"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
