{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c919898",
   "metadata": {
    "input_tokens": 6,
    "time_run": "9:11:07a"
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0449d",
   "metadata": {
    "collapsed": true,
    "input_tokens": 4,
    "output_tokens": 693,
    "time_run": "9:11:10a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fastcore.utils import L,first, last, groupby, mul, add, sub, truediv, patch, store_attr, BasicRepr\r\n",
      "from aocd import get_data\r\n",
      "import fastcore.all as fc, re, math, itertools, functools, numpy as np, types, typing, dataclasses, matplotlib.pyplot as plt,collections,regex \r\n",
      "from regex import search \r\n",
      "from collections import Counter \r\n",
      "from collections.abc import Iterable \r\n",
      "np.set_printoptions(linewidth=150)\r\n",
      "plt.rcParams['figure.dpi'] = 50\r\n",
      "def intro():\r\n",
      "    print(\"Note to solveit: Hi, I am Gaurav, and I am working with you today! When writing code for me, please follow fast.ai coding style: avoid comments; place single line if/loop/etc constructs on the same line; use concise variable names where appropriate. Follow the style you will see in my messages. As we work on this dialogue together.\")\r\n",
      "def show(m):\r\n",
      "    print('', '0123456789')\r\n",
      "    for i,o in enumerate(m): print(str(i)+(''.join(o)))\r\n",
      "def get_inp (year=None, day=None):\r\n",
      "    inp = get_data (year=year, day=day)\r\n",
      "    ilines = inp.splitlines()\r\n",
      "    print (len(ilines),'lines')\r\n",
      "    print(len(ilines [0]), 'chars', len(ilines [0].split()), 'tokens')\r\n",
      "    print (inp[:50], 'inp') \r\n",
      "    return inp\r\n",
      "def array(x): return x if isinstance(x, np.ndarray) else np.array(list(x) if isinstance(x, Iterable) else x)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/lancedb/__init__.py:220: UserWarning: lance is not fork-safe. If you are using multiprocessing, use spawn instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cat utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543190c8",
   "metadata": {
    "input_tokens": 9,
    "time_run": "9:11:15a"
   },
   "outputs": [],
   "source": [
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9c7d9",
   "metadata": {
    "input_tokens": 21,
    "time_run": "9:11:16a"
   },
   "outputs": [],
   "source": [
    "path = Path('/app/data/static/case study-2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b2820",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 51,
    "time_run": "9:11:19a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/app/data/static/case study-2024/train (6).csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22104a",
   "metadata": {
    "input_tokens": 7,
    "time_run": "9:11:25a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14c942",
   "metadata": {
    "input_tokens": 18,
    "time_run": "9:11:28a"
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(path.ls()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1310935",
   "metadata": {
    "collapsed": true,
    "input_tokens": 6,
    "output_tokens": 7390,
    "time_run": "9:07:54a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var14</th>\n",
       "      <th>Var15</th>\n",
       "      <th>Var16</th>\n",
       "      <th>Var17</th>\n",
       "      <th>Var18</th>\n",
       "      <th>Var19</th>\n",
       "      <th>Var20</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var23</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var26</th>\n",
       "      <th>Var27</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var29</th>\n",
       "      <th>Var30</th>\n",
       "      <th>Var31</th>\n",
       "      <th>Var32</th>\n",
       "      <th>Var33</th>\n",
       "      <th>Var34</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var36</th>\n",
       "      <th>Var37</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var39</th>\n",
       "      <th>Var40</th>\n",
       "      <th>...</th>\n",
       "      <th>Var191</th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var202</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "      <th>Var207</th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var209</th>\n",
       "      <th>Var210</th>\n",
       "      <th>Var211</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var213</th>\n",
       "      <th>Var214</th>\n",
       "      <th>Var215</th>\n",
       "      <th>Var216</th>\n",
       "      <th>Var217</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bZkvyxLkBI</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>lK27</td>\n",
       "      <td>ka_ns41</td>\n",
       "      <td>nQUveAzAF7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dXGu</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>FbIm</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XTbPUYD</td>\n",
       "      <td>sH5Z</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>1YVfGrO</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4764966.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CEat0G8rTN</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>2Ix5</td>\n",
       "      <td>qEdASpP</td>\n",
       "      <td>y2LIM01bE1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lg1t</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>k13i</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kZJyVg2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>0AJo2f2</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>904.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5883894.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eOQt0GoOh3</td>\n",
       "      <td>AERks4l</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ffXs</td>\n",
       "      <td>NldASpP</td>\n",
       "      <td>y4g9XoZ</td>\n",
       "      <td>vynJTq9</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>4bTR</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>MGOA</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "      <td>DHn_WUyBhW_whjA88g9bvA64_</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>UbxQ8lZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TTGHfSv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pMWAe2U</td>\n",
       "      <td>bHR7</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>JFM1BiF</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jg69tYsGvO</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ssAy</td>\n",
       "      <td>_ybO0dd</td>\n",
       "      <td>4hMlgkf58mhwh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W8mQ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>YULl</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kq0dQfu</td>\n",
       "      <td>eKej</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>L91KIiz</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IXSgUHShse</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>uNkU</td>\n",
       "      <td>EKR938I</td>\n",
       "      <td>ThrHXVS</td>\n",
       "      <td>0v21jmy</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>xklU</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>6JmL</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SJs3duv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11p4mKe</td>\n",
       "      <td>H3p7</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>OrnLfvc</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5  ...  Var226   Var227         Var228  Var229  Var230\n",
       "0   NaN   NaN   NaN   NaN   NaN  ...    xb3V     RAYp  F2FyR07IdsN7I     NaN     NaN\n",
       "1   NaN   NaN   NaN   NaN   NaN  ...    fKCe     RAYp  F2FyR07IdsN7I     NaN     NaN\n",
       "2   NaN   NaN   NaN   NaN   NaN  ...    Qu4f  02N6s8f  ib5G6X1eUxUn6    am7c     NaN\n",
       "3   NaN   NaN   NaN   NaN   NaN  ...    FSa2     RAYp  F2FyR07IdsN7I     NaN     NaN\n",
       "4   NaN   NaN   NaN   NaN   NaN  ...    FSa2     RAYp  F2FyR07IdsN7I    mj86     NaN\n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4aad3",
   "metadata": {
    "collapsed": true,
    "input_tokens": 6,
    "output_tokens": 12526,
    "time_run": "9:11:31a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var14</th>\n",
       "      <th>Var15</th>\n",
       "      <th>Var16</th>\n",
       "      <th>Var17</th>\n",
       "      <th>Var18</th>\n",
       "      <th>Var19</th>\n",
       "      <th>Var20</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var23</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var26</th>\n",
       "      <th>Var27</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var29</th>\n",
       "      <th>Var30</th>\n",
       "      <th>Var31</th>\n",
       "      <th>Var32</th>\n",
       "      <th>Var33</th>\n",
       "      <th>Var34</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var36</th>\n",
       "      <th>Var37</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var39</th>\n",
       "      <th>Var40</th>\n",
       "      <th>...</th>\n",
       "      <th>Var153</th>\n",
       "      <th>Var154</th>\n",
       "      <th>Var155</th>\n",
       "      <th>Var156</th>\n",
       "      <th>Var157</th>\n",
       "      <th>Var158</th>\n",
       "      <th>Var159</th>\n",
       "      <th>Var160</th>\n",
       "      <th>Var161</th>\n",
       "      <th>Var162</th>\n",
       "      <th>Var163</th>\n",
       "      <th>Var164</th>\n",
       "      <th>Var165</th>\n",
       "      <th>Var166</th>\n",
       "      <th>Var167</th>\n",
       "      <th>Var168</th>\n",
       "      <th>Var169</th>\n",
       "      <th>Var170</th>\n",
       "      <th>Var171</th>\n",
       "      <th>Var172</th>\n",
       "      <th>Var173</th>\n",
       "      <th>Var174</th>\n",
       "      <th>Var175</th>\n",
       "      <th>Var176</th>\n",
       "      <th>Var177</th>\n",
       "      <th>Var178</th>\n",
       "      <th>Var179</th>\n",
       "      <th>Var180</th>\n",
       "      <th>Var181</th>\n",
       "      <th>Var182</th>\n",
       "      <th>Var183</th>\n",
       "      <th>Var184</th>\n",
       "      <th>Var185</th>\n",
       "      <th>Var186</th>\n",
       "      <th>Var187</th>\n",
       "      <th>Var188</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var190</th>\n",
       "      <th>Var209</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>702.000000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>1.487000e+03</td>\n",
       "      <td>44471.000000</td>\n",
       "      <td>44461.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>1.487000e+03</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>44461.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44471.000000</td>\n",
       "      <td>44991.000000</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>42770.000000</td>\n",
       "      <td>44991.000000</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>44989.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.470000e+02</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>44991.000000</td>\n",
       "      <td>1.241000e+03</td>\n",
       "      <td>1.579000e+03</td>\n",
       "      <td>4.499100e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.499100e+04</td>\n",
       "      <td>7.020000e+02</td>\n",
       "      <td>1579.00000</td>\n",
       "      <td>694.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>44991.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>1.241000e+03</td>\n",
       "      <td>4.499100e+04</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>8.730000e+02</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>1.083000e+03</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>44991.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1.241000e+03</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>7.020000e+02</td>\n",
       "      <td>44991.000000</td>\n",
       "      <td>1.579000e+03</td>\n",
       "      <td>1.241000e+03</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>702.00000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>21022.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>2.387933e+05</td>\n",
       "      <td>1326.437116</td>\n",
       "      <td>6.809496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>3.926057e+05</td>\n",
       "      <td>8.625806</td>\n",
       "      <td>16.071685</td>\n",
       "      <td>1249.688401</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.239275</td>\n",
       "      <td>11.393287</td>\n",
       "      <td>7.215959</td>\n",
       "      <td>0.245092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.518225</td>\n",
       "      <td>290.245382</td>\n",
       "      <td>7.535306</td>\n",
       "      <td>4.507926</td>\n",
       "      <td>96.827010</td>\n",
       "      <td>0.070612</td>\n",
       "      <td>0.028245</td>\n",
       "      <td>224.507669</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>7.435897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.270050e+05</td>\n",
       "      <td>1.173247</td>\n",
       "      <td>0.716810</td>\n",
       "      <td>1.595539e+05</td>\n",
       "      <td>6.485221e+05</td>\n",
       "      <td>2.579107e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.962933</td>\n",
       "      <td>...</td>\n",
       "      <td>6.181967e+06</td>\n",
       "      <td>1.538221e+06</td>\n",
       "      <td>0.80114</td>\n",
       "      <td>169.472622</td>\n",
       "      <td>33.073516</td>\n",
       "      <td>1.896907</td>\n",
       "      <td>4.713940</td>\n",
       "      <td>38.803005</td>\n",
       "      <td>3.374288</td>\n",
       "      <td>3.360168e+05</td>\n",
       "      <td>4.860780e+05</td>\n",
       "      <td>1.753642</td>\n",
       "      <td>2.884236e+04</td>\n",
       "      <td>22.553463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.938575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.041096</td>\n",
       "      <td>3.674517e+05</td>\n",
       "      <td>9.744452</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>7.044965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.716129</td>\n",
       "      <td>6.188884e+05</td>\n",
       "      <td>16.687307</td>\n",
       "      <td>3.138062</td>\n",
       "      <td>3.776755e+06</td>\n",
       "      <td>0.611456</td>\n",
       "      <td>1.416638e+06</td>\n",
       "      <td>7.777380e+04</td>\n",
       "      <td>8.460919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.299145</td>\n",
       "      <td>16.54416</td>\n",
       "      <td>167.368477</td>\n",
       "      <td>270.142137</td>\n",
       "      <td>22007.045192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.709951</td>\n",
       "      <td>0.141933</td>\n",
       "      <td>4270.193518</td>\n",
       "      <td>1.275481</td>\n",
       "      <td>6.441259e+05</td>\n",
       "      <td>2685.693668</td>\n",
       "      <td>6.326053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.777855</td>\n",
       "      <td>9.280896e+05</td>\n",
       "      <td>2.869558</td>\n",
       "      <td>64.185508</td>\n",
       "      <td>2794.954874</td>\n",
       "      <td>3.714316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.386254</td>\n",
       "      <td>49.493856</td>\n",
       "      <td>34.415427</td>\n",
       "      <td>1.781497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>565.560147</td>\n",
       "      <td>704.489990</td>\n",
       "      <td>49.449472</td>\n",
       "      <td>9.928819</td>\n",
       "      <td>214.318283</td>\n",
       "      <td>0.528836</td>\n",
       "      <td>0.247210</td>\n",
       "      <td>98.520240</td>\n",
       "      <td>0.212436</td>\n",
       "      <td>8.852461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.957921e+05</td>\n",
       "      <td>4.377707</td>\n",
       "      <td>2.996007</td>\n",
       "      <td>3.277151e+05</td>\n",
       "      <td>1.382225e+06</td>\n",
       "      <td>3.010076e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.410005</td>\n",
       "      <td>...</td>\n",
       "      <td>4.348926e+06</td>\n",
       "      <td>2.280224e+06</td>\n",
       "      <td>3.04295</td>\n",
       "      <td>544.686538</td>\n",
       "      <td>187.525494</td>\n",
       "      <td>6.325709</td>\n",
       "      <td>11.027292</td>\n",
       "      <td>99.497149</td>\n",
       "      <td>8.579672</td>\n",
       "      <td>9.731987e+05</td>\n",
       "      <td>8.488638e+05</td>\n",
       "      <td>8.104872</td>\n",
       "      <td>1.157869e+05</td>\n",
       "      <td>96.211261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.879214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.921735</td>\n",
       "      <td>6.042377e+05</td>\n",
       "      <td>10.397319</td>\n",
       "      <td>0.132503</td>\n",
       "      <td>36.186111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.002253</td>\n",
       "      <td>1.306030e+06</td>\n",
       "      <td>59.016629</td>\n",
       "      <td>28.206035</td>\n",
       "      <td>3.785696e+06</td>\n",
       "      <td>2.495681</td>\n",
       "      <td>2.279786e+06</td>\n",
       "      <td>2.016188e+05</td>\n",
       "      <td>46.973777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.781967</td>\n",
       "      <td>60.22303</td>\n",
       "      <td>113.980072</td>\n",
       "      <td>86.707692</td>\n",
       "      <td>29085.146490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-6.420000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.794000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232346e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.360000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.917352e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>19.380000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>2732.670000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.290246e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.131560e+06</td>\n",
       "      <td>3.415240e+05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.346220e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.654884e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431310e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.167780e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>197.640000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>12668.940000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187425e+05</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.628630e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1604.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.080000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>266.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.297200e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.587940e+05</td>\n",
       "      <td>6.832260e+05</td>\n",
       "      <td>4.570944e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037338e+07</td>\n",
       "      <td>2.267270e+06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.825560e+05</td>\n",
       "      <td>6.159000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.270468e+05</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.544140e+05</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.471827e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.844952e+06</td>\n",
       "      <td>4.881000e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>252.960000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>29396.340000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>680.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>130668.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.048550e+06</td>\n",
       "      <td>131761.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>1.232559e+07</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1184.000000</td>\n",
       "      <td>197872.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>434.920000</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36272.000000</td>\n",
       "      <td>45340.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>13168.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5158.560000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.088640e+07</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>2.419600e+06</td>\n",
       "      <td>1.163502e+07</td>\n",
       "      <td>1.884690e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2648.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.390780e+07</td>\n",
       "      <td>1.504856e+07</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>8050.000000</td>\n",
       "      <td>5440.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>4862.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.088640e+07</td>\n",
       "      <td>1.451520e+07</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>1.209600e+06</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1270.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>957.000000</td>\n",
       "      <td>5.443200e+06</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>892.000000</td>\n",
       "      <td>8.554350e+06</td>\n",
       "      <td>1345.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.428483e+07</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.199478e+07</td>\n",
       "      <td>3.048400e+06</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>910.00000</td>\n",
       "      <td>628.620000</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>230427.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Var1         Var2           Var3  ...         Var190  Var209  Var230\n",
       "count  702.000000  1241.000000    1240.000000  ...     333.000000     0.0     0.0\n",
       "mean    11.487179     0.004029     425.298387  ...   22007.045192     NaN     NaN\n",
       "std     40.709951     0.141933    4270.193518  ...   29085.146490     NaN     NaN\n",
       "min      0.000000     0.000000       0.000000  ...       0.000000     NaN     NaN\n",
       "25%      0.000000     0.000000       0.000000  ...    2732.670000     NaN     NaN\n",
       "50%      0.000000     0.000000       0.000000  ...   12668.940000     NaN     NaN\n",
       "75%     16.000000     0.000000       0.000000  ...   29396.340000     NaN     NaN\n",
       "max    680.000000     5.000000  130668.000000  ...  230427.000000     NaN     NaN\n",
       "\n",
       "[8 rows x 192 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709e319",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 126,
    "time_run": "9:11:33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 230 entries, Var1 to Var230\n",
      "dtypes: float64(191), int64(1), object(38)\n",
      "memory usage: 87.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9bfb8",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:11:35a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 230)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863675ef",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 354,
    "time_run": "9:11:37a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var1', 'Var2', 'Var3', 'Var4', 'Var5', 'Var6', 'Var7', 'Var8', 'Var9',\n",
       "       'Var10',\n",
       "       ...\n",
       "       'Var221', 'Var222', 'Var223', 'Var224', 'Var225', 'Var226', 'Var227',\n",
       "       'Var228', 'Var229', 'Var230'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36160f5",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 51,
    "time_run": "9:11:46a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/app/data/static/case study-2024/train_churn_labels.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29e0f9",
   "metadata": {
    "input_tokens": 18,
    "time_run": "9:11:51a"
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv(path.ls()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d1ed9",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 360,
    "time_run": "9:11:53a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label\n",
       "0     -1\n",
       "1      1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b507a0b",
   "metadata": {
    "input_tokens": 232
   },
   "source": [
    "# Task & Expectations:\n",
    "- Attached is a training dataset and corresponding label file for a classification problem.\n",
    "- Your task is to propose a solution approach, documenting the steps, ideas, observations, data\n",
    "analysis, and feature engineering (if any). There’s no need to code the solution, but feel free to\n",
    "provide as much detail as you'd like.\n",
    "- Please include the success criteria and performance metrics you would use for model\n",
    "evaluation, along with the reasoning behind your choices. All decisions should be supported by\n",
    "data observations or sound reasoning.\n",
    "- We will assess the quality of your response based on the submitted document (Word or\n",
    "PowerPoint). Feel free to share other support documents like notebooks, excels etc. which can\n",
    "give us more confidence around the work done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ebf47",
   "metadata": {
    "input_tokens": 283
   },
   "source": [
    "## Plan\n",
    "\n",
    "1. **Data Understanding**\n",
    "   - Check basic statistics of features\n",
    "   - Analyze missing values\n",
    "   - Check distribution of churn labels (-1 and 1)\n",
    "\n",
    "2. **Data Preparation**\n",
    "   - Handle missing values (simple imputation)\n",
    "   - Convert categorical variables to numeric\n",
    "   - Create a clean dataset ready for modeling\n",
    "\n",
    "3. **Feature Selection**\n",
    "   - Identify the most important features\n",
    "   - Remove redundant or irrelevant features\n",
    "   - Focus on features with strongest relationship to churn\n",
    "\n",
    "4. **Modeling**\n",
    "   - Start with a simple model (like Random Forest)\n",
    "   - Train and evaluate the model\n",
    "   - Tune hyperparameters if needed\n",
    "\n",
    "5. **Evaluation**\n",
    "   - Use appropriate metrics (accuracy, precision, recall)\n",
    "   - Validate results with cross-validation\n",
    "   - Interpret model predictions\n",
    "\n",
    "6. **Business Insights**\n",
    "   - Identify key factors that predict churn\n",
    "   - Suggest actionable recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cee1f",
   "metadata": {
    "input_tokens": 72,
    "time_run": "9:11:58a"
   },
   "outputs": [],
   "source": [
    "# Categorize columns by missing percentage:\n",
    "\n",
    "## High (>50%): Consider dropping\n",
    "## Medium (10-50%): Impute with care or create \"missing\" flags\n",
    "## Low (<10%): Standard imputation is reasonable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c2ce5",
   "metadata": {
    "input_tokens": 72,
    "time_run": "10:22:21a"
   },
   "outputs": [],
   "source": [
    "def get_missing_cols(df, threshold=0.99):\n",
    "    missing_pct = df.isna().sum() / len(df)\n",
    "    mis_col = missing_pct[missing_pct > threshold].index.tolist()\n",
    "    return len(mis_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc0a46",
   "metadata": {
    "collapsed": true,
    "input_tokens": 49,
    "output_tokens": 30,
    "time_run": "10:22:23a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[161, 154, 154, 24]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = [0.50,0.80,0.90,0.99]\n",
    "[get_missing_cols(df_raw, t) for t in thresholds]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048d1c9",
   "metadata": {
    "input_tokens": 76
   },
   "source": [
    "Remove columns with >99% missing values as they provide minimal signal. For columns with 90-99% missing, evaluate whether the pattern of missingness itself is informative before deciding, and consider creating binary flags to capture this information rather than dropping completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55732822",
   "metadata": {
    "input_tokens": 28,
    "time_run": "9:12:08a"
   },
   "outputs": [],
   "source": [
    "cols_to_drop_90,_ = get_missing_cols(df_raw,threshold=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa578d5",
   "metadata": {
    "input_tokens": 15,
    "output_tokens": 90,
    "time_run": "9:12:14a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var1', 'Var2', 'Var3', 'Var4', 'Var5']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop_90[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5586ee6",
   "metadata": {
    "input_tokens": 22,
    "time_run": "9:12:19a"
   },
   "outputs": [],
   "source": [
    "df_clean =  df_raw.drop(columns=cols_to_drop_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1432fb",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:12:24a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd82093",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:12:30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 230)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1ef68",
   "metadata": {
    "input_tokens": 12,
    "time_run": "9:12:34a"
   },
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bcc572",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:12:38a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c89e66",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 1207,
    "time_run": "9:12:43a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var6', 'Var7', 'Var13', 'Var21', 'Var22', 'Var24', 'Var25', 'Var28',\n",
       "       'Var35', 'Var38', 'Var44', 'Var57', 'Var65', 'Var72', 'Var73', 'Var74',\n",
       "       'Var76', 'Var78', 'Var81', 'Var83', 'Var85', 'Var94', 'Var109',\n",
       "       'Var112', 'Var113', 'Var119', 'Var123', 'Var125', 'Var126', 'Var132',\n",
       "       'Var133', 'Var134', 'Var140', 'Var143', 'Var144', 'Var149', 'Var153',\n",
       "       'Var160', 'Var163', 'Var173', 'Var181', 'Var189', 'Var192', 'Var193',\n",
       "       'Var194', 'Var195', 'Var196', 'Var197', 'Var198', 'Var199', 'Var200',\n",
       "       'Var201', 'Var202', 'Var203', 'Var204', 'Var205', 'Var206', 'Var207',\n",
       "       'Var208', 'Var210', 'Var211', 'Var212', 'Var214', 'Var216', 'Var217',\n",
       "       'Var218', 'Var219', 'Var220', 'Var221', 'Var222', 'Var223', 'Var225',\n",
       "       'Var226', 'Var227', 'Var228', 'Var229'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c4e8d",
   "metadata": {
    "input_tokens": 18,
    "time_run": "9:12:51a"
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv(path.ls()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890b420",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 57,
    "time_run": "9:12:53a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "-1       0.92656\n",
       " 1       0.07344\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaccc17",
   "metadata": {
    "input_tokens": 34,
    "time_run": "9:12:56a"
   },
   "outputs": [],
   "source": [
    "cont_names, cat_names  = cont_cat_split(df_clean, max_card =20 ,dep_var='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d21727",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 21,
    "time_run": "9:13:00a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 34)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_names),len(cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344e63d",
   "metadata": {
    "input_tokens": 13,
    "output_tokens": 340,
    "time_run": "9:13:06a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var192      361\n",
       "Var193       51\n",
       "Var194        3\n",
       "Var195       23\n",
       "Var196        4\n",
       "Var197      225\n",
       "Var198     4291\n",
       "Var199     5073\n",
       "Var200    15415\n",
       "Var201        2\n",
       "Var202     5713\n",
       "Var203        5\n",
       "Var204      100\n",
       "Var205        3\n",
       "Var206       21\n",
       "Var207       14\n",
       "Var208        2\n",
       "Var210        6\n",
       "Var211        2\n",
       "Var212       81\n",
       "Var214    15415\n",
       "Var216     2016\n",
       "Var217    13990\n",
       "Var218        2\n",
       "Var219       22\n",
       "Var220     4291\n",
       "Var221        7\n",
       "Var222     4291\n",
       "Var223        4\n",
       "Var225        3\n",
       "Var226       23\n",
       "Var227        7\n",
       "Var228       30\n",
       "Var229        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[cat_names].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c061061",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 202,
    "time_run": "9:13:12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        bZkvyxLkBI\n",
       "1        CEat0G8rTN\n",
       "2        eOQt0GoOh3\n",
       "3        jg69tYsGvO\n",
       "4        IXSgUHShse\n",
       "            ...    \n",
       "49995    xOXr4RXktW\n",
       "49996    S8dr4RQxul\n",
       "49997    uUdt0G8EIb\n",
       "49998    FoxgUHSK8h\n",
       "49999    bZkvyxLkBI\n",
       "Name: Var192, Length: 50000, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Var192']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8997b796",
   "metadata": {
    "input_tokens": 798
   },
   "source": [
    "For high cardinality categorical columns in fastai, you have several options:\n",
    "\n",
    "**Simple approaches first:**\n",
    "\n",
    "```python\n",
    "# 1. Set a higher cardinality threshold when splitting columns\n",
    "cont_names, cat_names = cont_cat_split(df_clean, max_card=100, dep_var='label')\n",
    "\n",
    "# 2. Move specific high-cardinality columns to continuous\n",
    "high_card_cols = ['Var198', 'Var199', 'Var200', 'Var202', 'Var214', 'Var216', 'Var217', 'Var220', 'Var222']\n",
    "for col in high_card_cols:\n",
    "    if col in cat_names: \n",
    "        cat_names.remove(col)\n",
    "        cont_names.append(col)\n",
    "```\n",
    "\n",
    "**More advanced approaches:**\n",
    "\n",
    "1. **Target encoding** - Replace categories with their target mean:\n",
    "   ```python\n",
    "   from sklearn.preprocessing import TargetEncoder\n",
    "   \n",
    "   def apply_target_encoding(df, cols, target='label'):\n",
    "       df_new = df.copy()\n",
    "       for col in cols:\n",
    "           encoder = TargetEncoder()\n",
    "           df_new[f'{col}_encoded'] = encoder.fit_transform(df[col].fillna('missing'), df[target])\n",
    "       return df_new\n",
    "   ```\n",
    "\n",
    "2. **Clustering similar values** - Group rare categories:\n",
    "   ```python\n",
    "   def cluster_rare_categories(df, col, min_freq=100):\n",
    "       counts = df[col].value_counts()\n",
    "       rare_cats = counts[counts < min_freq].index\n",
    "       df_new = df.copy()\n",
    "       df_new[col] = df_new[col].apply(lambda x: 'rare_category' if x in rare_cats else x)\n",
    "       return df_new\n",
    "   ```\n",
    "\n",
    "3. **Text embeddings** - For text-like categorical columns:\n",
    "   ```python\n",
    "   # For columns that look like text, consider embeddings\n",
    "   from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "   from sklearn.decomposition import TruncatedSVD\n",
    "   \n",
    "   def embed_text_columns(df, text_cols, n_components=5):\n",
    "       df_new = df.copy()\n",
    "       for col in text_cols:\n",
    "           tfidf = TfidfVectorizer(min_df=5)\n",
    "           text_data = df[col].fillna('').astype(str)\n",
    "           tfidf_matrix = tfidf.fit_transform(text_data)\n",
    "           svd = TruncatedSVD(n_components=n_components)\n",
    "           text_features = svd.fit_transform(tfidf_matrix)\n",
    "           for i in range(n_components):\n",
    "               df_new[f'{col}_emb_{i}'] = text_features[:, i]\n",
    "       return df_new\n",
    "   ```\n",
    "\n",
    "Start with the simpler approaches and evaluate model performance before moving to more complex techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f6536",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:13:17a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ce30b",
   "metadata": {
    "input_tokens": 33,
    "time_run": "9:13:22a"
   },
   "outputs": [],
   "source": [
    "cont_names, cat_names = cont_cat_split(df_clean, max_card=100, dep_var='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b38bc1",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 21,
    "time_run": "9:13:27a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 34)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_names),len(cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d17bb",
   "metadata": {
    "collapsed": true,
    "input_tokens": 3,
    "output_tokens": 574,
    "time_run": "9:13:33a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var192',\n",
       " 'Var193',\n",
       " 'Var194',\n",
       " 'Var195',\n",
       " 'Var196',\n",
       " 'Var197',\n",
       " 'Var198',\n",
       " 'Var199',\n",
       " 'Var200',\n",
       " 'Var201',\n",
       " 'Var202',\n",
       " 'Var203',\n",
       " 'Var204',\n",
       " 'Var205',\n",
       " 'Var206',\n",
       " 'Var207',\n",
       " 'Var208',\n",
       " 'Var210',\n",
       " 'Var211',\n",
       " 'Var212',\n",
       " 'Var214',\n",
       " 'Var216',\n",
       " 'Var217',\n",
       " 'Var218',\n",
       " 'Var219',\n",
       " 'Var220',\n",
       " 'Var221',\n",
       " 'Var222',\n",
       " 'Var223',\n",
       " 'Var225',\n",
       " 'Var226',\n",
       " 'Var227',\n",
       " 'Var228',\n",
       " 'Var229']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb06d0f",
   "metadata": {
    "collapsed": true,
    "input_tokens": 6,
    "output_tokens": 1810,
    "time_run": "9:13:39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 76 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Var6    44471 non-null  float64\n",
      " 1   Var7    44461 non-null  float64\n",
      " 2   Var13   44461 non-null  float64\n",
      " 3   Var21   44471 non-null  float64\n",
      " 4   Var22   44991 non-null  float64\n",
      " 5   Var24   42770 non-null  float64\n",
      " 6   Var25   44991 non-null  float64\n",
      " 7   Var28   44989 non-null  float64\n",
      " 8   Var35   44991 non-null  float64\n",
      " 9   Var38   44991 non-null  float64\n",
      " 10  Var44   44991 non-null  float64\n",
      " 11  Var57   50000 non-null  float64\n",
      " 12  Var65   44461 non-null  float64\n",
      " 13  Var72   27620 non-null  float64\n",
      " 14  Var73   50000 non-null  int64  \n",
      " 15  Var74   44461 non-null  float64\n",
      " 16  Var76   44991 non-null  float64\n",
      " 17  Var78   44991 non-null  float64\n",
      " 18  Var81   44471 non-null  float64\n",
      " 19  Var83   44991 non-null  float64\n",
      " 20  Var85   44991 non-null  float64\n",
      " 21  Var94   27620 non-null  float64\n",
      " 22  Var109  42770 non-null  float64\n",
      " 23  Var112  44991 non-null  float64\n",
      " 24  Var113  50000 non-null  float64\n",
      " 25  Var119  44471 non-null  float64\n",
      " 26  Var123  44991 non-null  float64\n",
      " 27  Var125  44461 non-null  float64\n",
      " 28  Var126  36080 non-null  float64\n",
      " 29  Var132  44991 non-null  float64\n",
      " 30  Var133  44991 non-null  float64\n",
      " 31  Var134  44991 non-null  float64\n",
      " 32  Var140  44461 non-null  float64\n",
      " 33  Var143  44991 non-null  float64\n",
      " 34  Var144  44471 non-null  float64\n",
      " 35  Var149  42770 non-null  float64\n",
      " 36  Var153  44991 non-null  float64\n",
      " 37  Var160  44991 non-null  float64\n",
      " 38  Var163  44991 non-null  float64\n",
      " 39  Var173  44991 non-null  float64\n",
      " 40  Var181  44991 non-null  float64\n",
      " 41  Var189  21022 non-null  float64\n",
      " 42  Var192  49631 non-null  object \n",
      " 43  Var193  50000 non-null  object \n",
      " 44  Var194  12784 non-null  object \n",
      " 45  Var195  50000 non-null  object \n",
      " 46  Var196  50000 non-null  object \n",
      " 47  Var197  49857 non-null  object \n",
      " 48  Var198  50000 non-null  object \n",
      " 49  Var199  49996 non-null  object \n",
      " 50  Var200  24592 non-null  object \n",
      " 51  Var201  12783 non-null  object \n",
      " 52  Var202  49999 non-null  object \n",
      " 53  Var203  49857 non-null  object \n",
      " 54  Var204  50000 non-null  object \n",
      " 55  Var205  48066 non-null  object \n",
      " 56  Var206  44471 non-null  object \n",
      " 57  Var207  50000 non-null  object \n",
      " 58  Var208  49857 non-null  object \n",
      " 59  Var210  50000 non-null  object \n",
      " 60  Var211  50000 non-null  object \n",
      " 61  Var212  50000 non-null  object \n",
      " 62  Var214  24592 non-null  object \n",
      " 63  Var216  50000 non-null  object \n",
      " 64  Var217  49297 non-null  object \n",
      " 65  Var218  49297 non-null  object \n",
      " 66  Var219  44789 non-null  object \n",
      " 67  Var220  50000 non-null  object \n",
      " 68  Var221  50000 non-null  object \n",
      " 69  Var222  50000 non-null  object \n",
      " 70  Var223  44789 non-null  object \n",
      " 71  Var225  23856 non-null  object \n",
      " 72  Var226  50000 non-null  object \n",
      " 73  Var227  50000 non-null  object \n",
      " 74  Var228  50000 non-null  object \n",
      " 75  Var229  21568 non-null  object \n",
      "dtypes: float64(41), int64(1), object(34)\n",
      "memory usage: 29.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb054d",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 6750,
    "time_run": "9:13:44a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var202</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "      <th>Var207</th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var210</th>\n",
       "      <th>Var211</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var214</th>\n",
       "      <th>Var216</th>\n",
       "      <th>Var217</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bZkvyxLkBI</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>lK27</td>\n",
       "      <td>ka_ns41</td>\n",
       "      <td>nQUveAzAF7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dXGu</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>FbIm</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XTbPUYD</td>\n",
       "      <td>sH5Z</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>1YVfGrO</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEat0G8rTN</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>2Ix5</td>\n",
       "      <td>qEdASpP</td>\n",
       "      <td>y2LIM01bE1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lg1t</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>k13i</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kZJyVg2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>0AJo2f2</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eOQt0GoOh3</td>\n",
       "      <td>AERks4l</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ffXs</td>\n",
       "      <td>NldASpP</td>\n",
       "      <td>y4g9XoZ</td>\n",
       "      <td>vynJTq9</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>4bTR</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>MGOA</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "      <td>DHn_WUyBhW_whjA88g9bvA64_</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>UbxQ8lZ</td>\n",
       "      <td>TTGHfSv</td>\n",
       "      <td>pMWAe2U</td>\n",
       "      <td>bHR7</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>JFM1BiF</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jg69tYsGvO</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ssAy</td>\n",
       "      <td>_ybO0dd</td>\n",
       "      <td>4hMlgkf58mhwh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W8mQ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>YULl</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kq0dQfu</td>\n",
       "      <td>eKej</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>L91KIiz</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IXSgUHShse</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>uNkU</td>\n",
       "      <td>EKR938I</td>\n",
       "      <td>ThrHXVS</td>\n",
       "      <td>0v21jmy</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>xklU</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>6JmL</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>SJs3duv</td>\n",
       "      <td>11p4mKe</td>\n",
       "      <td>H3p7</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>OrnLfvc</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>xOXr4RXktW</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ZNsX</td>\n",
       "      <td>7nPy3El</td>\n",
       "      <td>h3WsUQk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bIER</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>ZKJc</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kZJyVg2</td>\n",
       "      <td>XXsx</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>3JmRJnY</td>\n",
       "      <td>oslk</td>\n",
       "      <td>EROH7Cg</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7FJQ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>S8dr4RQxul</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>I9xt3GBDKUbd8</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>JLbT</td>\n",
       "      <td>kJ1JA2C</td>\n",
       "      <td>7aPrx0x</td>\n",
       "      <td>tkF1jmy</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>P9KQ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>sYC_</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>XHaRWnH</td>\n",
       "      <td>beK4AFX</td>\n",
       "      <td>4a9J</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>MMTv4zN</td>\n",
       "      <td>oslk</td>\n",
       "      <td>GfSQowC</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>uUdt0G8EIb</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>0Xwj</td>\n",
       "      <td>LK5nVRA</td>\n",
       "      <td>k10MzgT</td>\n",
       "      <td>_VHQRHe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TKnx</td>\n",
       "      <td>F3hy</td>\n",
       "      <td>k13i</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>kxE9</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>vdKemiX</td>\n",
       "      <td>_JdcICD</td>\n",
       "      <td>DV70</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>FM28hdx</td>\n",
       "      <td>oslk</td>\n",
       "      <td>dh6qI2t</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>ELof</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>FoxgUHSK8h</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>AHgj</td>\n",
       "      <td>VcW4jEC</td>\n",
       "      <td>LH0kFz12FM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HJ88</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>mTeA</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mAj3FSW</td>\n",
       "      <td>8Mfr</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>BV9YlW4</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2fF2Oqu</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>bZkvyxLkBI</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>TIPl</td>\n",
       "      <td>6KF0k8W</td>\n",
       "      <td>P9HTde2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e9dM</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>vzJD</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mAjbk_S</td>\n",
       "      <td>k0HX</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>ot6oLzk</td>\n",
       "      <td>oslk</td>\n",
       "      <td>IIvC99a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var192   Var193 Var194  ...   Var227               Var228 Var229\n",
       "0      bZkvyxLkBI     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "1      CEat0G8rTN     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "2      eOQt0GoOh3  AERks4l   SEuy  ...  02N6s8f        ib5G6X1eUxUn6   am7c\n",
       "3      jg69tYsGvO     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "4      IXSgUHShse     RO12   SEuy  ...     RAYp        F2FyR07IdsN7I   mj86\n",
       "...           ...      ...    ...  ...      ...                  ...    ...\n",
       "49995  xOXr4RXktW     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "49996  S8dr4RQxul  2Knk1KF   SEuy  ...     RAYp              55YFVY9   am7c\n",
       "49997  uUdt0G8EIb  2Knk1KF    NaN  ...     RAYp  TCU50_Yjmm6GIBZ0lL_    NaN\n",
       "49998  FoxgUHSK8h     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "49999  bZkvyxLkBI     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "\n",
       "[50000 rows x 34 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c9ece",
   "metadata": {
    "input_tokens": 25,
    "time_run": "9:13:49a"
   },
   "outputs": [],
   "source": [
    "more_than_100 = df_clean.select_dtypes('object').nunique()>100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb53477",
   "metadata": {
    "input_tokens": 24,
    "output_tokens": 133,
    "time_run": "9:13:54a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var192      361\n",
       "Var197      225\n",
       "Var198     4291\n",
       "Var199     5073\n",
       "Var200    15415\n",
       "Var202     5713\n",
       "Var214    15415\n",
       "Var216     2016\n",
       "Var217    13990\n",
       "Var220     4291\n",
       "Var222     4291\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.select_dtypes('object').nunique()[more_than_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be2c4a",
   "metadata": {
    "input_tokens": 34,
    "time_run": "9:13:59a"
   },
   "outputs": [],
   "source": [
    "high_card_cols = df_clean.select_dtypes('object').nunique()[more_than_100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1185d0",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 195,
    "time_run": "9:14:01a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var192',\n",
       " 'Var197',\n",
       " 'Var198',\n",
       " 'Var199',\n",
       " 'Var200',\n",
       " 'Var202',\n",
       " 'Var214',\n",
       " 'Var216',\n",
       " 'Var217',\n",
       " 'Var220',\n",
       " 'Var222']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_card_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72df4c",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 202,
    "time_run": "9:14:04a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        bZkvyxLkBI\n",
       "1        CEat0G8rTN\n",
       "2        eOQt0GoOh3\n",
       "3        jg69tYsGvO\n",
       "4        IXSgUHShse\n",
       "            ...    \n",
       "49995    xOXr4RXktW\n",
       "49996    S8dr4RQxul\n",
       "49997    uUdt0G8EIb\n",
       "49998    FoxgUHSK8h\n",
       "49999    bZkvyxLkBI\n",
       "Name: Var192, Length: 50000, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Var192']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8bb59",
   "metadata": {
    "input_tokens": 18,
    "output_tokens": 117,
    "time_run": "9:14:08a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        225\n",
       "1         91\n",
       "2        248\n",
       "3        269\n",
       "4        131\n",
       "        ... \n",
       "49995    341\n",
       "49996    179\n",
       "49997    326\n",
       "49998    115\n",
       "49999    225\n",
       "Length: 50000, dtype: int16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Var192'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5097471",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:14:13a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd632ef",
   "metadata": {
    "input_tokens": 33,
    "time_run": "9:14:17a"
   },
   "outputs": [],
   "source": [
    "cont_names, cat_names = cont_cat_split(df_clean, max_card=100, dep_var='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf598bb4",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 21,
    "time_run": "9:14:20a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 34)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_names),len(cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e245205",
   "metadata": {
    "input_tokens": 76,
    "time_run": "9:14:26a"
   },
   "outputs": [],
   "source": [
    "for col in high_card_cols:\n",
    "    if col in cat_names:\n",
    "        df_clean[f'{col}_encoded'] = df_clean[col].astype('category').cat.codes\n",
    "        \n",
    "        cat_names.remove(col)\n",
    "        cont_names.append(f'{col}_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c49718",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 22,
    "time_run": "9:14:31a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 87)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac17aa4",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 6750,
    "time_run": "9:07:57a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var202</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "      <th>Var207</th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var210</th>\n",
       "      <th>Var211</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var214</th>\n",
       "      <th>Var216</th>\n",
       "      <th>Var217</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bZkvyxLkBI</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>lK27</td>\n",
       "      <td>ka_ns41</td>\n",
       "      <td>nQUveAzAF7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dXGu</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>FbIm</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XTbPUYD</td>\n",
       "      <td>sH5Z</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>1YVfGrO</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEat0G8rTN</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>2Ix5</td>\n",
       "      <td>qEdASpP</td>\n",
       "      <td>y2LIM01bE1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lg1t</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>k13i</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kZJyVg2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>0AJo2f2</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eOQt0GoOh3</td>\n",
       "      <td>AERks4l</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ffXs</td>\n",
       "      <td>NldASpP</td>\n",
       "      <td>y4g9XoZ</td>\n",
       "      <td>vynJTq9</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>4bTR</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>MGOA</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "      <td>DHn_WUyBhW_whjA88g9bvA64_</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>UbxQ8lZ</td>\n",
       "      <td>TTGHfSv</td>\n",
       "      <td>pMWAe2U</td>\n",
       "      <td>bHR7</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>JFM1BiF</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jg69tYsGvO</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ssAy</td>\n",
       "      <td>_ybO0dd</td>\n",
       "      <td>4hMlgkf58mhwh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W8mQ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>YULl</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kq0dQfu</td>\n",
       "      <td>eKej</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>L91KIiz</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IXSgUHShse</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>uNkU</td>\n",
       "      <td>EKR938I</td>\n",
       "      <td>ThrHXVS</td>\n",
       "      <td>0v21jmy</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>xklU</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>6JmL</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>SJs3duv</td>\n",
       "      <td>11p4mKe</td>\n",
       "      <td>H3p7</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>OrnLfvc</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>xOXr4RXktW</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ZNsX</td>\n",
       "      <td>7nPy3El</td>\n",
       "      <td>h3WsUQk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bIER</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>ZKJc</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kZJyVg2</td>\n",
       "      <td>XXsx</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>3JmRJnY</td>\n",
       "      <td>oslk</td>\n",
       "      <td>EROH7Cg</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7FJQ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>S8dr4RQxul</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>I9xt3GBDKUbd8</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>JLbT</td>\n",
       "      <td>kJ1JA2C</td>\n",
       "      <td>7aPrx0x</td>\n",
       "      <td>tkF1jmy</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>P9KQ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>sYC_</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>XHaRWnH</td>\n",
       "      <td>beK4AFX</td>\n",
       "      <td>4a9J</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>MMTv4zN</td>\n",
       "      <td>oslk</td>\n",
       "      <td>GfSQowC</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>uUdt0G8EIb</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>0Xwj</td>\n",
       "      <td>LK5nVRA</td>\n",
       "      <td>k10MzgT</td>\n",
       "      <td>_VHQRHe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TKnx</td>\n",
       "      <td>F3hy</td>\n",
       "      <td>k13i</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>kxE9</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>vdKemiX</td>\n",
       "      <td>_JdcICD</td>\n",
       "      <td>DV70</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>FM28hdx</td>\n",
       "      <td>oslk</td>\n",
       "      <td>dh6qI2t</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>ELof</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>FoxgUHSK8h</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>AHgj</td>\n",
       "      <td>VcW4jEC</td>\n",
       "      <td>LH0kFz12FM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HJ88</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>mTeA</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mAj3FSW</td>\n",
       "      <td>8Mfr</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>BV9YlW4</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2fF2Oqu</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>bZkvyxLkBI</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>TIPl</td>\n",
       "      <td>6KF0k8W</td>\n",
       "      <td>P9HTde2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e9dM</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>vzJD</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mAjbk_S</td>\n",
       "      <td>k0HX</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>ot6oLzk</td>\n",
       "      <td>oslk</td>\n",
       "      <td>IIvC99a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var192   Var193 Var194  ...   Var227               Var228 Var229\n",
       "0      bZkvyxLkBI     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "1      CEat0G8rTN     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "2      eOQt0GoOh3  AERks4l   SEuy  ...  02N6s8f        ib5G6X1eUxUn6   am7c\n",
       "3      jg69tYsGvO     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "4      IXSgUHShse     RO12   SEuy  ...     RAYp        F2FyR07IdsN7I   mj86\n",
       "...           ...      ...    ...  ...      ...                  ...    ...\n",
       "49995  xOXr4RXktW     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "49996  S8dr4RQxul  2Knk1KF   SEuy  ...     RAYp              55YFVY9   am7c\n",
       "49997  uUdt0G8EIb  2Knk1KF    NaN  ...     RAYp  TCU50_Yjmm6GIBZ0lL_    NaN\n",
       "49998  FoxgUHSK8h     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "49999  bZkvyxLkBI     RO12    NaN  ...     RAYp        F2FyR07IdsN7I    NaN\n",
       "\n",
       "[50000 rows x 34 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c7c43",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 21,
    "time_run": "9:14:42a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 23)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_names),len(cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761d4e8",
   "metadata": {
    "input_tokens": 7,
    "output_tokens": 16,
    "time_run": "9:07:57a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_card_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23294e7c",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 16,
    "time_run": "9:07:57a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 + 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b93e0",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 16,
    "time_run": "9:07:58a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34 -11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1829a68",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 9523,
    "time_run": "9:14:50a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var44</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var72</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var85</th>\n",
       "      <th>Var94</th>\n",
       "      <th>Var109</th>\n",
       "      <th>Var112</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var119</th>\n",
       "      <th>Var123</th>\n",
       "      <th>Var125</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var132</th>\n",
       "      <th>Var133</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>Var143</th>\n",
       "      <th>Var144</th>\n",
       "      <th>Var149</th>\n",
       "      <th>Var153</th>\n",
       "      <th>Var160</th>\n",
       "      <th>Var163</th>\n",
       "      <th>Var173</th>\n",
       "      <th>Var181</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var192_encoded</th>\n",
       "      <th>Var197_encoded</th>\n",
       "      <th>Var198_encoded</th>\n",
       "      <th>Var199_encoded</th>\n",
       "      <th>Var200_encoded</th>\n",
       "      <th>Var202_encoded</th>\n",
       "      <th>Var214_encoded</th>\n",
       "      <th>Var216_encoded</th>\n",
       "      <th>Var217_encoded</th>\n",
       "      <th>Var220_encoded</th>\n",
       "      <th>Var222_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1526.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.076907</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1350864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7333.11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>117625.60</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1212385.0</td>\n",
       "      <td>69134.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>397579.0</td>\n",
       "      <td>1812252.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>38418.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>225</td>\n",
       "      <td>177</td>\n",
       "      <td>3302</td>\n",
       "      <td>4015</td>\n",
       "      <td>-1</td>\n",
       "      <td>3682</td>\n",
       "      <td>-1</td>\n",
       "      <td>788</td>\n",
       "      <td>12236</td>\n",
       "      <td>94</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4764966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.408032</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2872928.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151098.90</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58158.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-356411.60</td>\n",
       "      <td>590.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4136430.0</td>\n",
       "      <td>357038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>278334.0</td>\n",
       "      <td>10439160.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>238572.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>13</td>\n",
       "      <td>3697</td>\n",
       "      <td>4890</td>\n",
       "      <td>-1</td>\n",
       "      <td>4422</td>\n",
       "      <td>-1</td>\n",
       "      <td>1317</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5236.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>220.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5883894.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.599658</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "      <td>518.0</td>\n",
       "      <td>1675776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16211.58</td>\n",
       "      <td>40.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>312.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>405104.00</td>\n",
       "      <td>3230.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>5967.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3478905.0</td>\n",
       "      <td>248932.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>320565.0</td>\n",
       "      <td>9826360.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>434946.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248</td>\n",
       "      <td>157</td>\n",
       "      <td>1686</td>\n",
       "      <td>4900</td>\n",
       "      <td>14524</td>\n",
       "      <td>448</td>\n",
       "      <td>7211</td>\n",
       "      <td>1612</td>\n",
       "      <td>8473</td>\n",
       "      <td>1293</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.988250</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-275703.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269</td>\n",
       "      <td>202</td>\n",
       "      <td>2575</td>\n",
       "      <td>362</td>\n",
       "      <td>-1</td>\n",
       "      <td>2953</td>\n",
       "      <td>-1</td>\n",
       "      <td>1425</td>\n",
       "      <td>9161</td>\n",
       "      <td>1444</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.552446</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82</td>\n",
       "      <td>224.0</td>\n",
       "      <td>784448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37423.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89754.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10714.84</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15111.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150650.0</td>\n",
       "      <td>66046.0</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>267162.0</td>\n",
       "      <td>644836.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131</td>\n",
       "      <td>208</td>\n",
       "      <td>971</td>\n",
       "      <td>2399</td>\n",
       "      <td>249</td>\n",
       "      <td>5511</td>\n",
       "      <td>6952</td>\n",
       "      <td>6</td>\n",
       "      <td>3834</td>\n",
       "      <td>1731</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6042420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.757958</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2764800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219451.20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3825.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>85899.60</td>\n",
       "      <td>510.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4467425.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>604800.0</td>\n",
       "      <td>10367040.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341</td>\n",
       "      <td>138</td>\n",
       "      <td>560</td>\n",
       "      <td>3502</td>\n",
       "      <td>-1</td>\n",
       "      <td>3489</td>\n",
       "      <td>-1</td>\n",
       "      <td>1317</td>\n",
       "      <td>7428</td>\n",
       "      <td>257</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2736.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594958</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>132</td>\n",
       "      <td>420.0</td>\n",
       "      <td>224344.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8836.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4812.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-1461768.00</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29862.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1433830.0</td>\n",
       "      <td>39652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85120.0</td>\n",
       "      <td>1344900.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>179</td>\n",
       "      <td>73</td>\n",
       "      <td>3269</td>\n",
       "      <td>596</td>\n",
       "      <td>14112</td>\n",
       "      <td>2353</td>\n",
       "      <td>8145</td>\n",
       "      <td>895</td>\n",
       "      <td>1060</td>\n",
       "      <td>1512</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>2807.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.574023</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>166</td>\n",
       "      <td>91.0</td>\n",
       "      <td>633552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6124.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>161457.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>105957.60</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>734845.0</td>\n",
       "      <td>131588.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>1242044.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>61734.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>326</td>\n",
       "      <td>2</td>\n",
       "      <td>1491</td>\n",
       "      <td>3705</td>\n",
       "      <td>8963</td>\n",
       "      <td>2692</td>\n",
       "      <td>14324</td>\n",
       "      <td>858</td>\n",
       "      <td>3040</td>\n",
       "      <td>1041</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.562059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-345201.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.0</td>\n",
       "      <td>115</td>\n",
       "      <td>34</td>\n",
       "      <td>2237</td>\n",
       "      <td>1770</td>\n",
       "      <td>-1</td>\n",
       "      <td>1652</td>\n",
       "      <td>-1</td>\n",
       "      <td>1472</td>\n",
       "      <td>1874</td>\n",
       "      <td>837</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1694.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>220.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2691228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.134800</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4571696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61882.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32274.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>150766.40</td>\n",
       "      <td>665.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10296.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7412900.0</td>\n",
       "      <td>95728.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10679800.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>165270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>109</td>\n",
       "      <td>453</td>\n",
       "      <td>2096</td>\n",
       "      <td>-1</td>\n",
       "      <td>3736</td>\n",
       "      <td>-1</td>\n",
       "      <td>1548</td>\n",
       "      <td>10438</td>\n",
       "      <td>3621</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Var6  Var7   Var13  ...  Var217_encoded  Var220_encoded  Var222_encoded\n",
       "0      1526.0   7.0   184.0  ...           12236              94            2964\n",
       "1       525.0   0.0     0.0  ...              -1              10             125\n",
       "2      5236.0   7.0   904.0  ...            8473            1293            1610\n",
       "3         NaN   0.0     0.0  ...            9161            1444             817\n",
       "4      1029.0   7.0  3216.0  ...            3834            1731              65\n",
       "...       ...   ...     ...  ...             ...             ...             ...\n",
       "49995   357.0   0.0     0.0  ...            7428             257             969\n",
       "49996  1078.0   0.0  2736.0  ...            1060            1512            1125\n",
       "49997  2807.0   7.0  1460.0  ...            3040            1041            2834\n",
       "49998     NaN   NaN     NaN  ...            1874             837             142\n",
       "49999  1694.0   7.0   828.0  ...           10438            3621            1262\n",
       "\n",
       "[50000 rows x 53 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[cont_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28566fb8",
   "metadata": {
    "input_tokens": 13,
    "output_tokens": 2142,
    "time_run": "9:14:55a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var192_encoded</th>\n",
       "      <th>Var197_encoded</th>\n",
       "      <th>Var198_encoded</th>\n",
       "      <th>Var199_encoded</th>\n",
       "      <th>Var200_encoded</th>\n",
       "      <th>Var202_encoded</th>\n",
       "      <th>Var214_encoded</th>\n",
       "      <th>Var216_encoded</th>\n",
       "      <th>Var217_encoded</th>\n",
       "      <th>Var220_encoded</th>\n",
       "      <th>Var222_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225</td>\n",
       "      <td>177</td>\n",
       "      <td>3302</td>\n",
       "      <td>4015</td>\n",
       "      <td>-1</td>\n",
       "      <td>3682</td>\n",
       "      <td>-1</td>\n",
       "      <td>788</td>\n",
       "      <td>12236</td>\n",
       "      <td>94</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>13</td>\n",
       "      <td>3697</td>\n",
       "      <td>4890</td>\n",
       "      <td>-1</td>\n",
       "      <td>4422</td>\n",
       "      <td>-1</td>\n",
       "      <td>1317</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248</td>\n",
       "      <td>157</td>\n",
       "      <td>1686</td>\n",
       "      <td>4900</td>\n",
       "      <td>14524</td>\n",
       "      <td>448</td>\n",
       "      <td>7211</td>\n",
       "      <td>1612</td>\n",
       "      <td>8473</td>\n",
       "      <td>1293</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269</td>\n",
       "      <td>202</td>\n",
       "      <td>2575</td>\n",
       "      <td>362</td>\n",
       "      <td>-1</td>\n",
       "      <td>2953</td>\n",
       "      <td>-1</td>\n",
       "      <td>1425</td>\n",
       "      <td>9161</td>\n",
       "      <td>1444</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>208</td>\n",
       "      <td>971</td>\n",
       "      <td>2399</td>\n",
       "      <td>249</td>\n",
       "      <td>5511</td>\n",
       "      <td>6952</td>\n",
       "      <td>6</td>\n",
       "      <td>3834</td>\n",
       "      <td>1731</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>341</td>\n",
       "      <td>138</td>\n",
       "      <td>560</td>\n",
       "      <td>3502</td>\n",
       "      <td>-1</td>\n",
       "      <td>3489</td>\n",
       "      <td>-1</td>\n",
       "      <td>1317</td>\n",
       "      <td>7428</td>\n",
       "      <td>257</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>179</td>\n",
       "      <td>73</td>\n",
       "      <td>3269</td>\n",
       "      <td>596</td>\n",
       "      <td>14112</td>\n",
       "      <td>2353</td>\n",
       "      <td>8145</td>\n",
       "      <td>895</td>\n",
       "      <td>1060</td>\n",
       "      <td>1512</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>326</td>\n",
       "      <td>2</td>\n",
       "      <td>1491</td>\n",
       "      <td>3705</td>\n",
       "      <td>8963</td>\n",
       "      <td>2692</td>\n",
       "      <td>14324</td>\n",
       "      <td>858</td>\n",
       "      <td>3040</td>\n",
       "      <td>1041</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>115</td>\n",
       "      <td>34</td>\n",
       "      <td>2237</td>\n",
       "      <td>1770</td>\n",
       "      <td>-1</td>\n",
       "      <td>1652</td>\n",
       "      <td>-1</td>\n",
       "      <td>1472</td>\n",
       "      <td>1874</td>\n",
       "      <td>837</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>225</td>\n",
       "      <td>109</td>\n",
       "      <td>453</td>\n",
       "      <td>2096</td>\n",
       "      <td>-1</td>\n",
       "      <td>3736</td>\n",
       "      <td>-1</td>\n",
       "      <td>1548</td>\n",
       "      <td>10438</td>\n",
       "      <td>3621</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var192_encoded  Var197_encoded  ...  Var220_encoded  Var222_encoded\n",
       "0                 225             177  ...              94            2964\n",
       "1                  91              13  ...              10             125\n",
       "2                 248             157  ...            1293            1610\n",
       "3                 269             202  ...            1444             817\n",
       "4                 131             208  ...            1731              65\n",
       "...               ...             ...  ...             ...             ...\n",
       "49995             341             138  ...             257             969\n",
       "49996             179              73  ...            1512            1125\n",
       "49997             326               2  ...            1041            2834\n",
       "49998             115              34  ...             837             142\n",
       "49999             225             109  ...            3621            1262\n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[cont_names[-11:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5315d9",
   "metadata": {
    "input_tokens": 18,
    "time_run": "9:15:01a"
   },
   "outputs": [],
   "source": [
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a9b01",
   "metadata": {
    "input_tokens": 10,
    "time_run": "9:15:41a"
   },
   "outputs": [],
   "source": [
    "df_clean = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c791e",
   "metadata": {
    "input_tokens": 25,
    "time_run": "9:16:56a"
   },
   "outputs": [],
   "source": [
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad53c79",
   "metadata": {
    "input_tokens": 73,
    "output_tokens": 11313,
    "time_run": "9:17:02a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'label'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m to = \u001b[43mTabularPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcont_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcont_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      2\u001b[39m \u001b[43m                  \u001b[49m\u001b[43my_names\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_block\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43mCategoryBlock\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m      4\u001b[39m to.show(\u001b[32m3\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/tabular/core.py:170\u001b[39m, in \u001b[36mTabular.__init__\u001b[39m\u001b[34m(self, df, procs, cat_names, cont_names, y_names, y_block, splits, do_setup, device, inplace, reduce_memory)\u001b[39m\n",
      "\u001b[32m    168\u001b[39m \u001b[38;5;28mself\u001b[39m.cat_names,\u001b[38;5;28mself\u001b[39m.cont_names,\u001b[38;5;28mself\u001b[39m.procs = L(cat_names),L(cont_names),Pipeline(procs)\n",
      "\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m.split = \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;28;01mif\u001b[39;00m splits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(splits[\u001b[32m0\u001b[39m])\n",
      "\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_setup: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/tabular/core.py:181\u001b[39m, in \u001b[36mTabular.setup\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastcore/transform.py:202\u001b[39m, in \u001b[36mPipeline.setup\u001b[39m\u001b[34m(self, items, train_setup)\u001b[39m\n",
      "\u001b[32m    200\u001b[39m tfms = \u001b[38;5;28mself\u001b[39m.fs[:]\n",
      "\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.fs.clear()\n",
      "\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tfms: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_setup\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastcore/transform.py:206\u001b[39m, in \u001b[36mPipeline.add\u001b[39m\u001b[34m(self, ts, items, train_setup)\u001b[39m\n",
      "\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m,ts, items=\u001b[38;5;28;01mNone\u001b[39;00m, train_setup=\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_listy(ts): ts=[ts]\n",
      "\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ts: \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_setup\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m.fs+=ts\n",
      "\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m.fs = \u001b[38;5;28mself\u001b[39m.fs.sorted(key=\u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastcore/transform.py:89\u001b[39m, in \u001b[36mTransform.setup\u001b[39m\u001b[34m(self, items, train_setup)\u001b[39m\n",
      "\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, items=\u001b[38;5;28;01mNone\u001b[39;00m, train_setup=\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[32m     88\u001b[39m     train_setup = train_setup \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_setup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_setup\n",
      "\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetups\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_setup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastcore/dispatch.py:122\u001b[39m, in \u001b[36mTypeDispatch.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m    120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f = MethodType(f, \u001b[38;5;28mself\u001b[39m.inst)\n",
      "\u001b[32m    121\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.owner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f = MethodType(f, \u001b[38;5;28mself\u001b[39m.owner)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/tabular/core.py:256\u001b[39m, in \u001b[36msetups\u001b[39m\u001b[34m(self, to)\u001b[39m\n",
      "\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to.y_names) > \u001b[32m0\u001b[39m:\n",
      "\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m         \u001b[38;5;28mself\u001b[39m.vocab = CategoryMap(\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mto\u001b[49m\u001b[43m.\u001b[49m\u001b[43my_names\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.items, strict=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m    257\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m.vocab = CategoryMap(\u001b[38;5;28mself\u001b[39m.vocab, sort=\u001b[38;5;28;01mFalse\u001b[39;00m, add_na=\u001b[38;5;28mself\u001b[39m.add_na)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/tabular/core.py:141\u001b[39m, in \u001b[36m_TabIloc.__getitem__\u001b[39m\u001b[34m(self, idxs)\u001b[39m\n",
      "\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idxs,\u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[32m    140\u001b[39m     rows,cols = idxs\n",
      "\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     cols = df.columns.isin(cols) \u001b[38;5;28;01mif\u001b[39;00m is_listy(cols) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: rows,cols = idxs,\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m    143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to.new(df.iloc[rows, cols])\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n",
      "\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n",
      "\u001b[32m   3810\u001b[39m     ):\n",
      "\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'label'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'label'\n",
      "\nThe above exception was the direct cause of the following exception:\n\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-36eb55331fa8>\", line 1, in <module>\n    to = TabularPandas(df_clean, procs=procs, cat_names=cat_names, cont_names=cont_names,\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py\", line 170, in __init__\n    if do_setup: self.setup()\n                 ^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py\", line 181, in setup\n    def setup(self): self.procs.setup(self)\n                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastcore/transform.py\", line 202, in setup\n    for t in tfms: self.add(t,items, train_setup)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastcore/transform.py\", line 206, in add\n    for t in ts: t.setup(items, train_setup)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastcore/transform.py\", line 89, in setup\n    return self.setups(getattr(items, 'train', items) if train_setup else items)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastcore/dispatch.py\", line 122, in __call__\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py\", line 256, in setups\n    self.vocab = CategoryMap(getattr(to, 'train', to).iloc[:,to.y_names[0]].items, strict=True)\n                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/tabular/core.py\", line 141, in __getitem__\n    cols = df.columns.isin(cols) if is_listy(cols) else df.columns.get_loc(cols)\n                                                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\n",
      "KeyError: 'label'\n"
     ]
    }
   ],
   "source": [
    "to = TabularPandas(df_clean, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                  y_names='label', y_block =CategoryBlock ,splits=splits)\n",
    "\n",
    "to.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c40f621",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 304,
    "solveit_ai": true
   },
   "source": [
    "please help me fix the above err\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "It looks like you're getting a `KeyError: 'label'` because the 'label' column doesn't exist in your dataframe. You need to add the label data from `df_label` to your `df_clean` dataframe before creating the TabularPandas object.\n",
    "\n",
    "Let's fix this:\n",
    "\n",
    "```python\n",
    "# Combine the cleaned data with the labels\n",
    "df_clean['label'] = df_label['Label'].values\n",
    "\n",
    "# Now create the TabularPandas object\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df_raw))\n",
    "\n",
    "to = TabularPandas(df_clean, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                  y_names='label', y_block=CategoryBlock, splits=splits)\n",
    "\n",
    "# Now try showing the data\n",
    "to.show(3)\n",
    "```\n",
    "\n",
    "This should resolve the error by adding the 'label' column to your dataframe before creating the TabularPandas object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf9ca8",
   "metadata": {
    "input_tokens": 210,
    "output_tokens": 6849,
    "time_run": "9:22:47a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "      <th>Var207</th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var210</th>\n",
       "      <th>Var211</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var6_na</th>\n",
       "      <th>Var7_na</th>\n",
       "      <th>Var13_na</th>\n",
       "      <th>Var21_na</th>\n",
       "      <th>Var22_na</th>\n",
       "      <th>Var24_na</th>\n",
       "      <th>Var25_na</th>\n",
       "      <th>Var28_na</th>\n",
       "      <th>Var35_na</th>\n",
       "      <th>Var38_na</th>\n",
       "      <th>Var44_na</th>\n",
       "      <th>Var65_na</th>\n",
       "      <th>Var72_na</th>\n",
       "      <th>Var74_na</th>\n",
       "      <th>Var76_na</th>\n",
       "      <th>Var78_na</th>\n",
       "      <th>Var81_na</th>\n",
       "      <th>Var83_na</th>\n",
       "      <th>Var85_na</th>\n",
       "      <th>Var94_na</th>\n",
       "      <th>Var109_na</th>\n",
       "      <th>Var112_na</th>\n",
       "      <th>Var119_na</th>\n",
       "      <th>Var123_na</th>\n",
       "      <th>Var125_na</th>\n",
       "      <th>Var126_na</th>\n",
       "      <th>Var132_na</th>\n",
       "      <th>Var133_na</th>\n",
       "      <th>Var134_na</th>\n",
       "      <th>Var140_na</th>\n",
       "      <th>Var143_na</th>\n",
       "      <th>Var144_na</th>\n",
       "      <th>Var149_na</th>\n",
       "      <th>Var153_na</th>\n",
       "      <th>Var160_na</th>\n",
       "      <th>Var163_na</th>\n",
       "      <th>Var173_na</th>\n",
       "      <th>Var181_na</th>\n",
       "      <th>Var189_na</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var44</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var72</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var85</th>\n",
       "      <th>Var94</th>\n",
       "      <th>Var109</th>\n",
       "      <th>Var112</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var119</th>\n",
       "      <th>Var123</th>\n",
       "      <th>Var125</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var132</th>\n",
       "      <th>Var133</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>Var143</th>\n",
       "      <th>Var144</th>\n",
       "      <th>Var149</th>\n",
       "      <th>Var153</th>\n",
       "      <th>Var160</th>\n",
       "      <th>Var163</th>\n",
       "      <th>Var173</th>\n",
       "      <th>Var181</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var192_encoded</th>\n",
       "      <th>Var197_encoded</th>\n",
       "      <th>Var198_encoded</th>\n",
       "      <th>Var199_encoded</th>\n",
       "      <th>Var200_encoded</th>\n",
       "      <th>Var202_encoded</th>\n",
       "      <th>Var214_encoded</th>\n",
       "      <th>Var216_encoded</th>\n",
       "      <th>Var217_encoded</th>\n",
       "      <th>Var220_encoded</th>\n",
       "      <th>Var222_encoded</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44747</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>rGJy</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>Kxdu</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>9pUnzWLbztKTo</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>am14IcfM7tWLrUmRT52KtA</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>133.119995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.601795</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>521488.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14511.509766</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>124686.398438</td>\n",
       "      <td>985.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36018.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600915.0</td>\n",
       "      <td>117818.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.546040e+05</td>\n",
       "      <td>2099680.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>371562.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>8651.0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27168</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>vzJD</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>889.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>290.399994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7045500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.366374</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170928.906250</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125898.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26165.000000</td>\n",
       "      <td>920.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1601460.0</td>\n",
       "      <td>668962.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.910383e-11</td>\n",
       "      <td>9760200.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1036800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5137.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23848</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>HLqf</td>\n",
       "      <td>000J</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>haYg</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>sBgB</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>xG3x</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>286.959991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5686488.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.396070</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2701920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35954.101563</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>203322.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>580.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2379470.0</td>\n",
       "      <td>974970.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.658030e+05</td>\n",
       "      <td>10579600.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>475230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>3204.0</td>\n",
       "      <td>8647.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9139.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the cleaned data with the labels\n",
    "df_clean['label'] = df_label['Label'].values\n",
    "\n",
    "# Now create the TabularPandas object\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df_raw))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Then run your TabularPandas code\n",
    "to = TabularPandas(df_clean, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                  y_names='label', y_block=CategoryBlock, splits=splits)\n",
    "\n",
    "\n",
    "# Now try showing the data\n",
    "to.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f771876",
   "metadata": {
    "collapsed": true,
    "input_tokens": 7,
    "output_tokens": 36193,
    "time_run": "9:22:54a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "      <th>Var207</th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var210</th>\n",
       "      <th>Var211</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var6_na</th>\n",
       "      <th>Var7_na</th>\n",
       "      <th>Var13_na</th>\n",
       "      <th>Var21_na</th>\n",
       "      <th>Var22_na</th>\n",
       "      <th>Var24_na</th>\n",
       "      <th>Var25_na</th>\n",
       "      <th>Var28_na</th>\n",
       "      <th>Var35_na</th>\n",
       "      <th>Var38_na</th>\n",
       "      <th>Var44_na</th>\n",
       "      <th>Var65_na</th>\n",
       "      <th>Var72_na</th>\n",
       "      <th>Var74_na</th>\n",
       "      <th>Var76_na</th>\n",
       "      <th>Var78_na</th>\n",
       "      <th>Var81_na</th>\n",
       "      <th>Var83_na</th>\n",
       "      <th>Var85_na</th>\n",
       "      <th>Var94_na</th>\n",
       "      <th>Var109_na</th>\n",
       "      <th>Var112_na</th>\n",
       "      <th>Var119_na</th>\n",
       "      <th>Var123_na</th>\n",
       "      <th>Var125_na</th>\n",
       "      <th>Var126_na</th>\n",
       "      <th>Var132_na</th>\n",
       "      <th>Var133_na</th>\n",
       "      <th>Var134_na</th>\n",
       "      <th>Var140_na</th>\n",
       "      <th>Var143_na</th>\n",
       "      <th>Var144_na</th>\n",
       "      <th>Var149_na</th>\n",
       "      <th>Var153_na</th>\n",
       "      <th>Var160_na</th>\n",
       "      <th>Var163_na</th>\n",
       "      <th>Var173_na</th>\n",
       "      <th>Var181_na</th>\n",
       "      <th>Var189_na</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var44</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var72</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var85</th>\n",
       "      <th>Var94</th>\n",
       "      <th>Var109</th>\n",
       "      <th>Var112</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var119</th>\n",
       "      <th>Var123</th>\n",
       "      <th>Var125</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var132</th>\n",
       "      <th>Var133</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>Var143</th>\n",
       "      <th>Var144</th>\n",
       "      <th>Var149</th>\n",
       "      <th>Var153</th>\n",
       "      <th>Var160</th>\n",
       "      <th>Var163</th>\n",
       "      <th>Var173</th>\n",
       "      <th>Var181</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var192_encoded</th>\n",
       "      <th>Var197_encoded</th>\n",
       "      <th>Var198_encoded</th>\n",
       "      <th>Var199_encoded</th>\n",
       "      <th>Var200_encoded</th>\n",
       "      <th>Var202_encoded</th>\n",
       "      <th>Var214_encoded</th>\n",
       "      <th>Var216_encoded</th>\n",
       "      <th>Var217_encoded</th>\n",
       "      <th>Var220_encoded</th>\n",
       "      <th>Var222_encoded</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44747</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>rGJy</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>Kxdu</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>9pUnzWLbztKTo</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>am14IcfM7tWLrUmRT52KtA</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>133.119995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.601795</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>521488.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14511.509766</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>124686.398438</td>\n",
       "      <td>985.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.601800e+04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600915.0</td>\n",
       "      <td>117818.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.546040e+05</td>\n",
       "      <td>2099680.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.715620e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>8651.0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27168</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>vzJD</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>889.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>290.399994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7045500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.366374</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170928.906250</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125898.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26165.000000</td>\n",
       "      <td>920.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>9.270000e+02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1601460.0</td>\n",
       "      <td>668962.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.910383e-11</td>\n",
       "      <td>9760200.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.036800e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5137.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23848</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>HLqf</td>\n",
       "      <td>000J</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>haYg</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>sBgB</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>xG3x</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>286.959991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5686488.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.396070</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2701920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35954.101563</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>203322.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>580.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.727000e+03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2379470.0</td>\n",
       "      <td>974970.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.658030e+05</td>\n",
       "      <td>10579600.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.752300e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>3204.0</td>\n",
       "      <td>8647.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9139.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42912</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>xQ2A</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>5Acm</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>784.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.079987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11340420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.020295</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216748.500000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165269.593750</td>\n",
       "      <td>495.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2.277000e+03</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39775.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.910383e-11</td>\n",
       "      <td>10697040.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>3676.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>7878.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36874</th>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>HLqf</td>\n",
       "      <td>0A_v</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>Tkho</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>sBgB</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>PM2D</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>166.559998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103397</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>613576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18528.179688</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-212132.000000</td>\n",
       "      <td>795.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.501000e+03</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397020.0</td>\n",
       "      <td>59090.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.910383e-11</td>\n",
       "      <td>1066624.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.657560e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>10283.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>8632.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>3621.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>SkZj</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>hAFG</td>\n",
       "      <td>NKv3VA1BpP</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>Ie_5MZs</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Aoh3</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>875.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>286.959991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6741720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.693228</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2649688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147334.796875</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40140.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>75818.796875</td>\n",
       "      <td>530.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.277100e+04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3195970.0</td>\n",
       "      <td>385402.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.048000e+05</td>\n",
       "      <td>10529320.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>8931.0</td>\n",
       "      <td>4620.0</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>9526.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38567</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>YGOC</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>hAFG</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>ELof</td>\n",
       "      <td>szEZ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>133.119995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.491348</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>1335288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29471.640625</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20184.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-239377.203125</td>\n",
       "      <td>545.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.082600e+04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341140.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.024400e+04</td>\n",
       "      <td>1403356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.129400e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>11751.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20772</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>HLqf</td>\n",
       "      <td>F_Lu</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>hAFG</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>sBgB</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>ELof</td>\n",
       "      <td>TNEC</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>273.119995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6150240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.151250</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>2625296.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102744.296875</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>246132.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>47923.601562</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.517900e+04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4054460.0</td>\n",
       "      <td>44848.0</td>\n",
       "      <td>5715.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.338980e+05</td>\n",
       "      <td>9978720.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.202400e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7738.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>5488.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>12804.0</td>\n",
       "      <td>3792.0</td>\n",
       "      <td>2327.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>Y9Bl</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>qxDb</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>uWr3</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.959991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4671036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.485580</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8784160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214998.593750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19614.720703</td>\n",
       "      <td>265.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-3.637979e-12</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1887560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.233600e+06</td>\n",
       "      <td>10221840.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4744.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>12836.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22473</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>e7QV</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>#na#</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.204657</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>898320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27084.150391</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>59622.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-20028.560547</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.150200e+04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1756885.0</td>\n",
       "      <td>1152232.0</td>\n",
       "      <td>5115.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.100540e+05</td>\n",
       "      <td>5985080.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.774146e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>9020.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40653</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>Ew1Q</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>DHn_WUyBhW_whjA88g9bvA64_</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>PWD40mS</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>wX53</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.371075</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2764800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132702.906250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-13313.719727</td>\n",
       "      <td>435.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-3.637979e-12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5728950.0</td>\n",
       "      <td>1223682.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.910383e-11</td>\n",
       "      <td>9539480.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.147536e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3522.0</td>\n",
       "      <td>3018.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32672</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>KubS</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Qcbd</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>186.639999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4136202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.600299</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1581624.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52983.300781</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53031.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>726012.000000</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-3.637979e-12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2558015.0</td>\n",
       "      <td>813540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.183410e+05</td>\n",
       "      <td>8445400.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.207260e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>4156.0</td>\n",
       "      <td>4264.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>7584.0</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>4168.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>4N0K</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>kxE9</td>\n",
       "      <td>7M47J5GA0pTYIFxg5uy</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>iyHGyLCEkQ</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>332.399994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1124334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858577</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>799136.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7398.089844</td>\n",
       "      <td>65.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>335997.593750</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.890000e+03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>939705.0</td>\n",
       "      <td>320518.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.287670e+05</td>\n",
       "      <td>3073052.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.809660e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3012.0</td>\n",
       "      <td>4053.0</td>\n",
       "      <td>7977.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>10174.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>13841.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47610</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>QBpP</td>\n",
       "      <td>#na#</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>DHn_WUyBhW_whjA88g9bvA64_</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>CrNX</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>d0EEeJi</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>ELof</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>nIGXDli</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>819.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2476.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>254.800003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3390618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.533860</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1267288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225075.296875</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63132.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>455860.000000</td>\n",
       "      <td>540.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.400000e+02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4552615.0</td>\n",
       "      <td>950688.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.108877e+06</td>\n",
       "      <td>10338480.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.425702e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>4264.0</td>\n",
       "      <td>11900.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>14367.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>5225.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23339</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>TFSW</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>6JmL</td>\n",
       "      <td>7M47J5GA0pTYIFxg5uy</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>7A3j</td>\n",
       "      <td>L84s</td>\n",
       "      <td>Ie_5MZs</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Xa3G</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>361.200012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4209780.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.672720</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>2529904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155533.500000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>165984.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>147204.000000</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.894000e+03</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3719100.0</td>\n",
       "      <td>976666.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.654200e+04</td>\n",
       "      <td>10752320.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.169220e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>2409.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>12662.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2751.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12908</th>\n",
       "      <td>AERks4l</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>H9GL</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>wMei</td>\n",
       "      <td>7M47J5GA0pTYIFxg5uy</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>4kVnq_T26xq1p</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Aoh3</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>166.559998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5466126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.141850</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2777024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119556.898438</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>124167.601562</td>\n",
       "      <td>630.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.024900e+04</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2734085.0</td>\n",
       "      <td>326450.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.518650e+05</td>\n",
       "      <td>8987520.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.059200e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>7577.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2751.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45129</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>TFSW</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>DHn_WUyBhW_whjA88g9bvA64_</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>CrNX</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>#na#</td>\n",
       "      <td>d0EEeJi</td>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Xa3G</td>\n",
       "      <td>nIGXDli</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>220.080002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165648.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.661611</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3409704.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162789.296875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-278309.593750</td>\n",
       "      <td>160.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.527000e+03</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634385.0</td>\n",
       "      <td>691202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.642910e+05</td>\n",
       "      <td>6363400.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.872760e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>3912.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>11632.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34489</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>000J</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>CoYW</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>AU8pNoi</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.237342</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>651360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8642.400391</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44535.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>105424.796875</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.507000e+03</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>760335.0</td>\n",
       "      <td>67784.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.877600e+04</td>\n",
       "      <td>1165004.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.382520e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>2706.0</td>\n",
       "      <td>4503.0</td>\n",
       "      <td>10851.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>6290.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>k13i</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>hAFG</td>\n",
       "      <td>7M47J5GA0pTYIFxg5uy</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>ELof</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>166.559998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2094066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.178381</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2330312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97005.296875</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7752.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>386693.187500</td>\n",
       "      <td>855.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.517000e+03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986280.0</td>\n",
       "      <td>591110.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.691140e+05</td>\n",
       "      <td>6423160.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.173940e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>10981.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>3497.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32021</th>\n",
       "      <td>AERks4l</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>0A_v</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>hAFG</td>\n",
       "      <td>7M47J5GA0pTYIFxg5uy</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>9fipLB8rlL</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>PM2D</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>952.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.919998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9849600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.225166</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204360.593750</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7203.160156</td>\n",
       "      <td>480.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6.541200e+04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.910383e-11</td>\n",
       "      <td>9676800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.820766e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>7292.0</td>\n",
       "      <td>3875.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>11443.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2751.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29820f3b",
   "metadata": {
    "input_tokens": 18,
    "time_run": "9:23:01a"
   },
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a8d62",
   "metadata": {
    "collapsed": true,
    "input_tokens": 13,
    "output_tokens": 20145,
    "time_run": "9:23:11a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "      <th>Var207</th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var210</th>\n",
       "      <th>Var211</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var6_na</th>\n",
       "      <th>Var7_na</th>\n",
       "      <th>Var13_na</th>\n",
       "      <th>Var21_na</th>\n",
       "      <th>Var22_na</th>\n",
       "      <th>Var24_na</th>\n",
       "      <th>Var25_na</th>\n",
       "      <th>Var28_na</th>\n",
       "      <th>Var35_na</th>\n",
       "      <th>Var38_na</th>\n",
       "      <th>Var44_na</th>\n",
       "      <th>Var65_na</th>\n",
       "      <th>Var72_na</th>\n",
       "      <th>Var74_na</th>\n",
       "      <th>Var76_na</th>\n",
       "      <th>Var78_na</th>\n",
       "      <th>Var81_na</th>\n",
       "      <th>Var83_na</th>\n",
       "      <th>Var85_na</th>\n",
       "      <th>Var94_na</th>\n",
       "      <th>Var109_na</th>\n",
       "      <th>Var112_na</th>\n",
       "      <th>Var119_na</th>\n",
       "      <th>Var123_na</th>\n",
       "      <th>Var125_na</th>\n",
       "      <th>Var126_na</th>\n",
       "      <th>Var132_na</th>\n",
       "      <th>Var133_na</th>\n",
       "      <th>Var134_na</th>\n",
       "      <th>Var140_na</th>\n",
       "      <th>Var143_na</th>\n",
       "      <th>Var144_na</th>\n",
       "      <th>Var149_na</th>\n",
       "      <th>Var153_na</th>\n",
       "      <th>Var160_na</th>\n",
       "      <th>Var163_na</th>\n",
       "      <th>Var173_na</th>\n",
       "      <th>Var181_na</th>\n",
       "      <th>Var189_na</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var44</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var72</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var85</th>\n",
       "      <th>Var94</th>\n",
       "      <th>Var109</th>\n",
       "      <th>Var112</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var119</th>\n",
       "      <th>Var123</th>\n",
       "      <th>Var125</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var132</th>\n",
       "      <th>Var133</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>Var143</th>\n",
       "      <th>Var144</th>\n",
       "      <th>Var149</th>\n",
       "      <th>Var153</th>\n",
       "      <th>Var160</th>\n",
       "      <th>Var163</th>\n",
       "      <th>Var173</th>\n",
       "      <th>Var181</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var192_encoded</th>\n",
       "      <th>Var197_encoded</th>\n",
       "      <th>Var198_encoded</th>\n",
       "      <th>Var199_encoded</th>\n",
       "      <th>Var200_encoded</th>\n",
       "      <th>Var202_encoded</th>\n",
       "      <th>Var214_encoded</th>\n",
       "      <th>Var216_encoded</th>\n",
       "      <th>Var217_encoded</th>\n",
       "      <th>Var220_encoded</th>\n",
       "      <th>Var222_encoded</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>e7QV</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>231.000030</td>\n",
       "      <td>-3.108308e-07</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>39.999995</td>\n",
       "      <td>50.000006</td>\n",
       "      <td>1.067975e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>186.640000</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>5.111538e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>3.179449</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.999999</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>6.587280e+05</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>257465.405655</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.111247e-08</td>\n",
       "      <td>1011.000445</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>8.000001e+00</td>\n",
       "      <td>1.590792e+05</td>\n",
       "      <td>445.000004</td>\n",
       "      <td>12.000001</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>-27.999999</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>9.832900e+06</td>\n",
       "      <td>-1.600465e-02</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>2.714428e-07</td>\n",
       "      <td>-4.506366e-03</td>\n",
       "      <td>1.168056e+07</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>-2.404768e-02</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>326.000004</td>\n",
       "      <td>16.999999</td>\n",
       "      <td>3097.999971</td>\n",
       "      <td>1770.000038</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>191.999920</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>1544.999995</td>\n",
       "      <td>2036.000028</td>\n",
       "      <td>1524.999986</td>\n",
       "      <td>491.999961</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>X8zP</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Aoh3</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>882.000015</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>412.000034</td>\n",
       "      <td>124.000001</td>\n",
       "      <td>154.999998</td>\n",
       "      <td>1.067975e-07</td>\n",
       "      <td>8.000003</td>\n",
       "      <td>220.080002</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>2.638368e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>6.111728</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>5.459544e+06</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>142706.406001</td>\n",
       "      <td>-5.130590e-08</td>\n",
       "      <td>1.111247e-08</td>\n",
       "      <td>41172.000718</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>1.341896e+05</td>\n",
       "      <td>509.999989</td>\n",
       "      <td>36.000001</td>\n",
       "      <td>6561.000410</td>\n",
       "      <td>38.000001</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>6.912150e+06</td>\n",
       "      <td>5.097799e+04</td>\n",
       "      <td>140.000009</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>-4.506366e-03</td>\n",
       "      <td>1.012036e+07</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>-2.404768e-02</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>277.999998</td>\n",
       "      <td>182.999997</td>\n",
       "      <td>2941.000028</td>\n",
       "      <td>1760.000012</td>\n",
       "      <td>14543.999704</td>\n",
       "      <td>5229.999983</td>\n",
       "      <td>1924.999990</td>\n",
       "      <td>1548.000003</td>\n",
       "      <td>11061.000191</td>\n",
       "      <td>1637.000017</td>\n",
       "      <td>2922.000021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>yrDU</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>kxE9</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>XfqtO3UdzaXh_</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Qcbd</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>959.000009</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>4.000010</td>\n",
       "      <td>31.999996</td>\n",
       "      <td>40.000001</td>\n",
       "      <td>1.067975e-07</td>\n",
       "      <td>15.999998</td>\n",
       "      <td>305.040006</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>3.594906e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>0.236274</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>4.841793e-02</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>211693.499706</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.111247e-08</td>\n",
       "      <td>1778.999527</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-2.503975e-07</td>\n",
       "      <td>-8.875725e+02</td>\n",
       "      <td>484.999997</td>\n",
       "      <td>5.999998</td>\n",
       "      <td>2006.999230</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>9.980650e+06</td>\n",
       "      <td>3.002840e+05</td>\n",
       "      <td>129.999993</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>-4.506366e-03</td>\n",
       "      <td>1.158892e+07</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-2.404768e-02</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>176.999997</td>\n",
       "      <td>2346.999999</td>\n",
       "      <td>1778.000009</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>1828.999971</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>788.000008</td>\n",
       "      <td>13490.999766</td>\n",
       "      <td>3569.000073</td>\n",
       "      <td>1727.999990</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>iVbl</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>#na#</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>7aLG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>854.000017</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>232.000023</td>\n",
       "      <td>143.999998</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>47.999999</td>\n",
       "      <td>220.080002</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>1.271490e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>2.807520</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>6.999998e+00</td>\n",
       "      <td>8.730480e+05</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>73550.405745</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>41172.000718</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>-1.418584e+06</td>\n",
       "      <td>560.000003</td>\n",
       "      <td>30.000001</td>\n",
       "      <td>6462.000590</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>1.479380e+06</td>\n",
       "      <td>2.094560e+05</td>\n",
       "      <td>220.000013</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>5.290599e+04</td>\n",
       "      <td>8.153040e+06</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.359720e+05</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>384.000006</td>\n",
       "      <td>30.999998</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1129.000016</td>\n",
       "      <td>2589.999999</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>2859.999999</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>1543.999992</td>\n",
       "      <td>10500.999981</td>\n",
       "      <td>707.999972</td>\n",
       "      <td>986.999988</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>ZKJc</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>43pnToF</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>7FJQ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1477.000004</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>220.000023</td>\n",
       "      <td>116.000001</td>\n",
       "      <td>145.000003</td>\n",
       "      <td>1.067975e-07</td>\n",
       "      <td>72.000001</td>\n",
       "      <td>432.480012</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>1.412760e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>2.605640</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>5.935184e+06</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>55068.299317</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.111247e-08</td>\n",
       "      <td>120020.998060</td>\n",
       "      <td>39.999999</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>-3.523828e+04</td>\n",
       "      <td>705.000004</td>\n",
       "      <td>24.000001</td>\n",
       "      <td>1971.000764</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.150870e+06</td>\n",
       "      <td>6.629760e+05</td>\n",
       "      <td>1680.000005</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>-4.506366e-03</td>\n",
       "      <td>7.272160e+06</td>\n",
       "      <td>12.000001</td>\n",
       "      <td>-2.404768e-02</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>60.000002</td>\n",
       "      <td>137.999999</td>\n",
       "      <td>1125.000003</td>\n",
       "      <td>2882.000016</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>5698.000020</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>1548.000003</td>\n",
       "      <td>8326.999944</td>\n",
       "      <td>672.000066</td>\n",
       "      <td>2439.000014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>FbIm</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1057.000001</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>139.999965</td>\n",
       "      <td>343.999998</td>\n",
       "      <td>430.000003</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>23.999999</td>\n",
       "      <td>166.559997</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>6.480039e+02</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>0.863063</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.000001</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>3.392400e+05</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>5946.930978</td>\n",
       "      <td>-5.130590e-08</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>60188.999966</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>7.553879e+04</td>\n",
       "      <td>1080.000003</td>\n",
       "      <td>5.999998</td>\n",
       "      <td>10962.000031</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>3.582000e+05</td>\n",
       "      <td>7.823995e+03</td>\n",
       "      <td>3324.999986</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>2.714428e-07</td>\n",
       "      <td>4.806200e+04</td>\n",
       "      <td>4.734559e+05</td>\n",
       "      <td>111.999999</td>\n",
       "      <td>1.794007e+03</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>201.999996</td>\n",
       "      <td>2869.999965</td>\n",
       "      <td>2394.999996</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>5093.999962</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>1548.000003</td>\n",
       "      <td>4515.999986</td>\n",
       "      <td>2950.999974</td>\n",
       "      <td>3801.999966</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>Ew1Q</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>wX53</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>531.999969</td>\n",
       "      <td>-3.108308e-07</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>165.000003</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>324.000004</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>1.339464e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>2.936979</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.000001</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>6.912000e+05</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>225182.698895</td>\n",
       "      <td>-5.130590e-08</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>120705.001112</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000001e+00</td>\n",
       "      <td>1.061032e+05</td>\n",
       "      <td>499.999998</td>\n",
       "      <td>24.000001</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.731335e+06</td>\n",
       "      <td>2.764800e+06</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>6.048000e+05</td>\n",
       "      <td>1.022684e+07</td>\n",
       "      <td>12.000001</td>\n",
       "      <td>3.110400e+06</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>2.999999</td>\n",
       "      <td>35.999999</td>\n",
       "      <td>3684.999951</td>\n",
       "      <td>799.000081</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>1901.000000</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>499.000013</td>\n",
       "      <td>220.000028</td>\n",
       "      <td>2976.000008</td>\n",
       "      <td>1719.000010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>HLqf</td>\n",
       "      <td>TjV7</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>sBgB</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>657.999996</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2228.000005</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>160.000001</td>\n",
       "      <td>1.067975e-07</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>2.456576e-02</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>4.852382</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>107.999999</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>1.930640e+05</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>23069.131460</td>\n",
       "      <td>-5.130590e-08</td>\n",
       "      <td>1.111247e-08</td>\n",
       "      <td>693.002502</td>\n",
       "      <td>8.000002</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.980836e+05</td>\n",
       "      <td>590.000005</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>5337.000056</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>1.244055e+06</td>\n",
       "      <td>1.831398e+04</td>\n",
       "      <td>3334.999883</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>2.714428e-07</td>\n",
       "      <td>-4.506366e-03</td>\n",
       "      <td>1.128404e+06</td>\n",
       "      <td>49.999999</td>\n",
       "      <td>-2.404768e-02</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>335.999999</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>1.999997</td>\n",
       "      <td>4240.000044</td>\n",
       "      <td>1576.000011</td>\n",
       "      <td>15328.000527</td>\n",
       "      <td>4000.999993</td>\n",
       "      <td>9215.999855</td>\n",
       "      <td>895.000004</td>\n",
       "      <td>301.000046</td>\n",
       "      <td>3389.999970</td>\n",
       "      <td>1424.999992</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>TjV7</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>IYzP</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>L84s</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>153.999999</td>\n",
       "      <td>-3.108308e-07</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>184.000001</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>144.000002</td>\n",
       "      <td>166.559997</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>5.585398e+04</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>5.079684</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.000001</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>2.768080e+05</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>27694.172894</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>41172.000718</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>1.945412e+05</td>\n",
       "      <td>424.999993</td>\n",
       "      <td>5.999998</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>5.563400e+05</td>\n",
       "      <td>5.056500e+05</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>2.714428e-07</td>\n",
       "      <td>1.767570e+05</td>\n",
       "      <td>1.786800e+06</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.231340e+05</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>44.999998</td>\n",
       "      <td>176.999997</td>\n",
       "      <td>555.000023</td>\n",
       "      <td>998.000039</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>976.000096</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>1543.999992</td>\n",
       "      <td>6604.000003</td>\n",
       "      <td>472.999965</td>\n",
       "      <td>3119.999989</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RO12</td>\n",
       "      <td>#na#</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>#na#</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>t_4G</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>zm5i</td>\n",
       "      <td>me75fM6ugJ</td>\n",
       "      <td>kIsH</td>\n",
       "      <td>uKAI</td>\n",
       "      <td>Mtgm</td>\n",
       "      <td>NhsEn4L</td>\n",
       "      <td>#na#</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>oslk</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>545.999968</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>139.999999</td>\n",
       "      <td>174.999998</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>23.999999</td>\n",
       "      <td>253.520004</td>\n",
       "      <td>1.403175e-08</td>\n",
       "      <td>1.171776e+06</td>\n",
       "      <td>2.520943e-09</td>\n",
       "      <td>0.115146</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.000001</td>\n",
       "      <td>5.222973e-07</td>\n",
       "      <td>4.780816e+06</td>\n",
       "      <td>-1.223175e-08</td>\n",
       "      <td>202998.591512</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8384.999236</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>5.600000e+01</td>\n",
       "      <td>1.644276e+06</td>\n",
       "      <td>605.000006</td>\n",
       "      <td>24.000001</td>\n",
       "      <td>187730.996904</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>1.060625e-07</td>\n",
       "      <td>7.596050e+06</td>\n",
       "      <td>4.752200e+05</td>\n",
       "      <td>80.000035</td>\n",
       "      <td>7.400162e-10</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.368814e+06</td>\n",
       "      <td>1.058224e+07</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.752120e+05</td>\n",
       "      <td>1.414058e-10</td>\n",
       "      <td>1.757930e-08</td>\n",
       "      <td>582.000004</td>\n",
       "      <td>81.000001</td>\n",
       "      <td>215.999997</td>\n",
       "      <td>1841.000016</td>\n",
       "      <td>279.000046</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>1261.999957</td>\n",
       "      <td>-1.000108</td>\n",
       "      <td>1548.000003</td>\n",
       "      <td>-0.999800</td>\n",
       "      <td>959.000037</td>\n",
       "      <td>3885.000030</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a10c9",
   "metadata": {
    "input_tokens": 73,
    "time_run": "9:23:29a"
   },
   "outputs": [],
   "source": [
    "from fastai.metrics import accuracy, F1Score, RocAuc,Precision,RocAucBinary\n",
    "\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(),Precision(),RocAucBinary()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ba2cc",
   "metadata": {
    "input_tokens": 19,
    "output_tokens": 4669,
    "time_run": "9:23:46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r",
      "epoch     train_loss  valid_loss  accuracy  f1_score  precision_score  roc_auc_score  time    \n",
      "█\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.16% [1/625 00:00<00:51]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.32% [2/625 00:00<00:33 0.7471]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.48% [3/625 00:00<00:26 0.7447]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.64% [4/625 00:00<00:23 0.7241]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.80% [5/625 00:00<00:21 0.7264]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 1.60% [10/625 00:00<00:17 0.7270]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 2.56% [16/625 00:00<00:16 0.7167]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 3.68% [23/625 00:00<00:15 0.6961]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 4.80% [30/625 00:00<00:14 0.6822]\r",
      "\r",
      "Epoch 1/1 : |██--------------------------------------| 6.08% [38/625 00:00<00:13 0.6676]\r",
      "\r",
      "Epoch 1/1 : |██--------------------------------------| 7.36% [46/625 00:00<00:12 0.6502]\r",
      "\r",
      "Epoch 1/1 : |███-------------------------------------| 8.80% [55/625 00:01<00:11 0.6252]\r",
      "\r",
      "Epoch 1/1 : |████------------------------------------| 10.24% [64/625 00:01<00:10 0.5943]\r",
      "\r",
      "Epoch 1/1 : |████------------------------------------| 11.84% [74/625 00:01<00:10 0.5482]\r",
      "\r",
      "Epoch 1/1 : |█████-----------------------------------| 13.44% [84/625 00:01<00:10 0.4985]\r",
      "\r",
      "Epoch 1/1 : |██████----------------------------------| 15.04% [94/625 00:01<00:09 0.4513]\r",
      "\r",
      "Epoch 1/1 : |██████----------------------------------| 16.64% [104/625 00:01<00:09 0.4270]\r",
      "\r",
      "Epoch 1/1 : |███████---------------------------------| 18.40% [115/625 00:02<00:09 0.3885]\r",
      "\r",
      "Epoch 1/1 : |████████--------------------------------| 20.16% [126/625 00:02<00:08 0.3559]\r",
      "\r",
      "Epoch 1/1 : |████████--------------------------------| 21.92% [137/625 00:02<00:08 0.3407]\r",
      "\r",
      "Epoch 1/1 : |█████████-------------------------------| 23.68% [148/625 00:02<00:08 0.3334]\r",
      "\r",
      "Epoch 1/1 : |██████████------------------------------| 25.44% [159/625 00:02<00:08 0.3239]\r",
      "\r",
      "Epoch 1/1 : |██████████------------------------------| 27.20% [170/625 00:02<00:07 0.3025]\r",
      "\r",
      "Epoch 1/1 : |███████████-----------------------------| 28.96% [181/625 00:03<00:07 0.2966]\r",
      "\r",
      "Epoch 1/1 : |████████████----------------------------| 30.72% [192/625 00:03<00:07 0.2870]\r",
      "\r",
      "Epoch 1/1 : |████████████----------------------------| 32.48% [203/625 00:03<00:07 0.2795]\r",
      "\r",
      "Epoch 1/1 : |█████████████---------------------------| 34.24% [214/625 00:03<00:06 0.2740]\r",
      "\r",
      "Epoch 1/1 : |██████████████--------------------------| 36.00% [225/625 00:03<00:06 0.2691]\r",
      "\r",
      "Epoch 1/1 : |███████████████-------------------------| 37.76% [236/625 00:04<00:06 0.2716]\r",
      "\r",
      "Epoch 1/1 : |███████████████-------------------------| 39.52% [247/625 00:04<00:06 0.2585]\r",
      "\r",
      "Epoch 1/1 : |████████████████------------------------| 41.28% [258/625 00:04<00:06 0.2609]\r",
      "\r",
      "Epoch 1/1 : |█████████████████-----------------------| 43.04% [269/625 00:04<00:06 0.2630]\r",
      "\r",
      "Epoch 1/1 : |█████████████████-----------------------| 44.80% [280/625 00:04<00:05 0.2647]\r",
      "\r",
      "Epoch 1/1 : |██████████████████----------------------| 46.56% [291/625 00:04<00:05 0.2626]\r",
      "\r",
      "Epoch 1/1 : |███████████████████---------------------| 48.32% [302/625 00:05<00:05 0.2595]\r",
      "\r",
      "Epoch 1/1 : |████████████████████--------------------| 50.08% [313/625 00:05<00:05 0.2633]\r",
      "\r",
      "Epoch 1/1 : |████████████████████--------------------| 51.84% [324/625 00:05<00:05 0.2591]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████-------------------| 53.60% [335/625 00:05<00:04 0.2556]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████------------------| 55.36% [346/625 00:05<00:04 0.2604]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████------------------| 57.12% [357/625 00:05<00:04 0.2553]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████-----------------| 58.88% [368/625 00:06<00:04 0.2554]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████----------------| 60.64% [379/625 00:06<00:04 0.2577]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████----------------| 62.40% [390/625 00:06<00:03 0.2517]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████---------------| 64.16% [401/625 00:06<00:03 0.2577]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████--------------| 65.92% [412/625 00:06<00:03 0.2534]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████-------------| 67.68% [423/625 00:07<00:03 0.2461]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████-------------| 69.44% [434/625 00:07<00:03 0.2387]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████------------| 71.20% [445/625 00:07<00:03 0.2309]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████-----------| 72.96% [456/625 00:07<00:02 0.2279]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████-----------| 74.72% [467/625 00:07<00:02 0.2342]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████----------| 76.48% [478/625 00:07<00:02 0.2369]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████---------| 78.24% [489/625 00:08<00:02 0.2387]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████--------| 80.00% [500/625 00:08<00:02 0.2413]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████--------| 81.76% [511/625 00:08<00:01 0.2403]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████████-------| 83.52% [522/625 00:08<00:01 0.2378]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████████------| 85.28% [533/625 00:08<00:01 0.2424]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████████------| 87.04% [544/625 00:09<00:01 0.2453]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████████-----| 88.80% [555/625 00:09<00:01 0.2489]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████----| 90.56% [566/625 00:09<00:00 0.2566]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████----| 92.48% [578/625 00:09<00:00 0.2531]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████████████---| 94.40% [590/625 00:09<00:00 0.2488]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████████████--| 96.32% [602/625 00:10<00:00 0.2489]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████████████-| 98.24% [614/625 00:10<00:00 0.2437]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.2463]\r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.2451]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.2451]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.2451]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.2451]\r",
      "\r",
      "Epoch 1/1 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.2451]\r",
      "\r",
      "Epoch 1/1 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.2451]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.2451]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.2451]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.2451]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.2451]\r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "0         0.245125    0.308676    0.929200  0.011173  0.095238         0.707033       00:11     \n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bab61d",
   "metadata": {
    "input_tokens": 27,
    "output_tokens": 511,
    "solveit_ai": true
   },
   "source": [
    "Can you analyze the metric and give me the result? I think we're doing very badly.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the metrics from your model training, you're absolutely right - the model is performing poorly, especially considering this appears to be an imbalanced classification problem.\n",
    "\n",
    "Here's the analysis of your metrics:\n",
    "\n",
    "1. **Accuracy (0.929)**: This looks good at first glance, but it's misleading. With imbalanced data (your label distribution showed approximately 93% negative class and 7% positive class), a model can achieve high accuracy by simply predicting the majority class for everything.\n",
    "\n",
    "2. **F1 Score (0.011)**: This is extremely low. F1 score is the harmonic mean of precision and recall, and a value this close to zero indicates the model is failing to identify the positive class effectively.\n",
    "\n",
    "3. **Precision (0.095)**: Very poor. This means that when your model predicts the positive class, it's correct only about 9.5% of the time - most predictions are false positives.\n",
    "\n",
    "4. **ROC AUC (0.707)**: This is mediocre. While better than random (0.5), it's not strong enough for a reliable model, especially with such imbalanced data.\n",
    "\n",
    "The model is likely predicting almost everything as the majority class (-1), which gives high accuracy but fails at actually detecting the minority class (1). \n",
    "\n",
    "To improve this, you should consider:\n",
    "\n",
    "1. Using class weights or oversampling techniques to address the imbalance\n",
    "2. Using metrics better suited for imbalanced data (like precision-recall AUC)\n",
    "3. Trying different learning rates and training for more epochs\n",
    "4. Adding regularization to prevent overfitting to the majority class\n",
    "\n",
    "Would you like me to suggest specific code changes to implement any of these improvements?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122bbb2d",
   "metadata": {
    "input_tokens": 55,
    "output_tokens": 282,
    "solveit_ai": true
   },
   "source": [
    "\n",
    "\n",
    "let try with tthee two first\n",
    "\n",
    "Using class weights or oversampling techniques to address the imbalance\n",
    "Using metrics better suited for imbalanced data (like precision-recall AUC\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's implement these two improvements. First, let's use class weights to address the imbalance, and then add precision-recall AUC as a metric:\n",
    "\n",
    "```python\n",
    "# Calculate class weights based on the label distribution\n",
    "weights = torch.FloatTensor([1, 12]) # Approximate weights based on ~93% vs ~7% distribution\n",
    "\n",
    "# Create a new learner with class weights and PR-AUC metric\n",
    "from fastai.metrics import PrecisionRecallScore\n",
    "\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PrecisionRecallScore()], \n",
    "                        loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train the model with the same parameters\n",
    "learn.fit_one_cycle(1, 1e-2)\n",
    "```\n",
    "\n",
    "This should help the model focus more on the minority class and give us a better evaluation metric (PR-AUC) that's more suitable for imbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981258a1",
   "metadata": {
    "input_tokens": 169,
    "output_tokens": 306,
    "time_run": "9:26:58a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n",
      "\u001b[32m      1\u001b[39m weights = torch.FloatTensor([\u001b[32m1\u001b[39m, \u001b[32m12\u001b[39m]) \u001b[38;5;66;03m# Approximate weights based on ~93% vs ~7% distribution\u001b[39;00m\n",
      "\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create a new learner with class weights and PR-AUC metric\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecisionRecallScore\n",
      "\u001b[32m      6\u001b[39m learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PrecisionRecallScore()], \n",
      "\u001b[32m      7\u001b[39m                         loss_func=CrossEntropyLossFlat(weight=weights))\n",
      "\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Train the model with the same parameters\u001b[39;00m\n",
      "\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PrecisionRecallScore' from 'fastai.metrics' (/app/data/.local/lib/python3.11/site-packages/fastai/metrics.py)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PrecisionRecallScore' from 'fastai.metrics' (/app/data/.local/lib/python3.11/site-packages/fastai/metrics.py)",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-0ce97ca43348>\", line 4, in <module>\n    from fastai.metrics import PrecisionRecallScore\n",
      "ImportError: cannot import name 'PrecisionRecallScore' from 'fastai.metrics' (/app/data/.local/lib/python3.11/site-packages/fastai/metrics.py)\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor([1, 12]) # Approximate weights based on ~93% vs ~7% distribution\n",
    "\n",
    "# Create a new learner with class weights and PR-AUC metric\n",
    "from fastai.metrics import PrecisionRecallScore\n",
    "\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PrecisionRecallScore()], \n",
    "                        loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train the model with the same parameters\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf425a",
   "metadata": {
    "input_tokens": 15,
    "output_tokens": 448,
    "solveit_ai": true
   },
   "source": [
    "pleas ehelp em wuth anove err\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "It seems PrecisionRecallScore isn't directly available in fastai's metrics. Let's create our own precision-recall AUC metric and try again with the class weights:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from fastai.metrics import Metric\n",
    "\n",
    "class PRAUCScore(Metric):\n",
    "    \"Precision-Recall AUC\"\n",
    "    def __init__(self): self.name = \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return auc(recall, precision)\n",
    "\n",
    "# Now let's create the learner with class weights and our custom PR-AUC metric\n",
    "weights = torch.FloatTensor([1, 12])\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train the model with the same parameters\n",
    "learn.fit_one_cycle(1, 1e-2)\n",
    "```\n",
    "\n",
    "This should help address the class imbalance with weights and give us a better metric for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05449178",
   "metadata": {
    "input_tokens": 366,
    "output_tokens": 333,
    "time_run": "9:28:31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n",
      "\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Now let's create the learner with class weights and our custom PR-AUC metric\u001b[39;00m\n",
      "\u001b[32m     22\u001b[39m weights = torch.FloatTensor([\u001b[32m1\u001b[39m, \u001b[32m12\u001b[39m])\n",
      "\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), \u001b[43mPRAUCScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m], \n",
      "\u001b[32m     24\u001b[39m                       loss_func=CrossEntropyLossFlat(weight=weights))\n",
      "\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Train the model with the same parameters\u001b[39;00m\n",
      "\u001b[32m     27\u001b[39m learn.fit_one_cycle(\u001b[32m1\u001b[39m, \u001b[32m1e-2\u001b[39m)\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mPRAUCScore.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m = \u001b[33m\"\u001b[39m\u001b[33mprauc\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: property 'name' of 'PRAUCScore' object has no setter\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "property 'name' of 'PRAUCScore' object has no setter",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-2f81d4e17793>\", line 23, in <module>\n    learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()],\n                                                                                           ^^^^^^^^^^^^\n",
      "  File \"<ipython-input-1-2f81d4e17793>\", line 6, in __init__\n    def __init__(self): self.name = \"prauc\"\n                        ^^^^^^^^^\n",
      "AttributeError: property 'name' of 'PRAUCScore' object has no setter\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from fastai.metrics import Metric\n",
    "\n",
    "class PRAUCScore(Metric):\n",
    "    \"Precision-Recall AUC\"\n",
    "    def __init__(self): self.name = \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return auc(recall, precision)\n",
    "\n",
    "# Now let's create the learner with class weights and our custom PR-AUC metric\n",
    "weights = torch.FloatTensor([1, 12])\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train the model with the same parameters\n",
    "learn.fit_one_cycle(1, 1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b651c9",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 451,
    "solveit_ai": true
   },
   "source": [
    "please hlp me with above err..\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "It looks like there's an issue with the `name` attribute in our custom metric. In fastai, `name` is a property, not a regular attribute. Let's fix that and try again:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from fastai.metrics import Metric\n",
    "\n",
    "class PRAUCScore(Metric):\n",
    "    \"Precision-Recall AUC\"\n",
    "    @property\n",
    "    def name(self): return \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return auc(recall, precision)\n",
    "\n",
    "# Create the learner with class weights and our fixed PR-AUC metric\n",
    "weights = torch.FloatTensor([1, 12])\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(1, 1e-2)\n",
    "```\n",
    "\n",
    "This should properly define the custom metric and apply the class weights to help with the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9cec1",
   "metadata": {
    "input_tokens": 357,
    "output_tokens": 4684,
    "time_run": "9:29:46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r",
      "epoch     train_loss  valid_loss  accuracy  f1_score  precision_score  roc_auc_score  prauc     time    \n",
      "█\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.16% [1/625 00:00<00:35]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.32% [2/625 00:00<00:25 0.6485]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.48% [3/625 00:00<00:21 0.6787]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.64% [4/625 00:00<00:19 0.7483]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.80% [5/625 00:00<00:17 0.7466]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 1.76% [11/625 00:00<00:15 0.7821]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 3.04% [19/625 00:00<00:13 0.7597]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 4.48% [28/625 00:00<00:12 0.7569]\r",
      "\r",
      "Epoch 1/1 : |██--------------------------------------| 5.92% [37/625 00:00<00:11 0.7526]\r",
      "\r",
      "Epoch 1/1 : |███-------------------------------------| 7.52% [47/625 00:00<00:10 0.7322]\r",
      "\r",
      "Epoch 1/1 : |███-------------------------------------| 9.12% [57/625 00:01<00:10 0.7384]\r",
      "\r",
      "Epoch 1/1 : |████------------------------------------| 10.72% [67/625 00:01<00:09 0.7305]\r",
      "\r",
      "Epoch 1/1 : |████------------------------------------| 12.48% [78/625 00:01<00:09 0.7416]\r",
      "\r",
      "Epoch 1/1 : |█████-----------------------------------| 14.24% [89/625 00:01<00:09 0.7189]\r",
      "\r",
      "Epoch 1/1 : |██████----------------------------------| 16.00% [100/625 00:01<00:09 0.7070]\r",
      "\r",
      "Epoch 1/1 : |███████---------------------------------| 17.76% [111/625 00:01<00:08 0.7105]\r",
      "\r",
      "Epoch 1/1 : |███████---------------------------------| 19.52% [122/625 00:02<00:08 0.7043]\r",
      "\r",
      "Epoch 1/1 : |████████--------------------------------| 21.28% [133/625 00:02<00:08 0.6988]\r",
      "\r",
      "Epoch 1/1 : |█████████-------------------------------| 23.04% [144/625 00:02<00:08 0.7038]\r",
      "\r",
      "Epoch 1/1 : |█████████-------------------------------| 24.80% [155/625 00:02<00:08 0.7037]\r",
      "\r",
      "Epoch 1/1 : |██████████------------------------------| 26.56% [166/625 00:02<00:07 0.6798]\r",
      "\r",
      "Epoch 1/1 : |███████████-----------------------------| 28.32% [177/625 00:03<00:07 0.6944]\r",
      "\r",
      "Epoch 1/1 : |████████████----------------------------| 30.08% [188/625 00:03<00:07 0.7043]\r",
      "\r",
      "Epoch 1/1 : |████████████----------------------------| 31.84% [199/625 00:03<00:07 0.6947]\r",
      "\r",
      "Epoch 1/1 : |█████████████---------------------------| 33.60% [210/625 00:03<00:07 0.6821]\r",
      "\r",
      "Epoch 1/1 : |██████████████--------------------------| 35.36% [221/625 00:03<00:06 0.6859]\r",
      "\r",
      "Epoch 1/1 : |██████████████--------------------------| 37.12% [232/625 00:03<00:06 0.6848]\r",
      "\r",
      "Epoch 1/1 : |███████████████-------------------------| 38.88% [243/625 00:04<00:06 0.6706]\r",
      "\r",
      "Epoch 1/1 : |████████████████------------------------| 40.64% [254/625 00:04<00:06 0.6704]\r",
      "\r",
      "Epoch 1/1 : |████████████████------------------------| 42.40% [265/625 00:04<00:06 0.6591]\r",
      "\r",
      "Epoch 1/1 : |█████████████████-----------------------| 44.16% [276/625 00:04<00:05 0.6501]\r",
      "\r",
      "Epoch 1/1 : |██████████████████----------------------| 45.92% [287/625 00:04<00:05 0.6398]\r",
      "\r",
      "Epoch 1/1 : |███████████████████---------------------| 47.68% [298/625 00:05<00:05 0.6675]\r",
      "\r",
      "Epoch 1/1 : |███████████████████---------------------| 49.44% [309/625 00:05<00:05 0.6812]\r",
      "\r",
      "Epoch 1/1 : |████████████████████--------------------| 51.20% [320/625 00:05<00:05 0.6858]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████-------------------| 52.96% [331/625 00:05<00:04 0.6789]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████-------------------| 54.72% [342/625 00:05<00:04 0.6565]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████------------------| 56.48% [353/625 00:05<00:04 0.6651]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████-----------------| 58.24% [364/625 00:06<00:04 0.6557]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████----------------| 60.00% [375/625 00:06<00:04 0.6485]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████----------------| 61.76% [386/625 00:06<00:04 0.6353]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████---------------| 63.52% [397/625 00:06<00:03 0.6300]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████--------------| 65.28% [408/625 00:06<00:03 0.6295]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████--------------| 67.04% [419/625 00:07<00:03 0.6298]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████-------------| 68.80% [430/625 00:07<00:03 0.6243]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████------------| 70.56% [441/625 00:07<00:03 0.6235]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████------------| 72.32% [452/625 00:07<00:02 0.6265]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████-----------| 74.08% [463/625 00:07<00:02 0.6243]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████----------| 75.84% [474/625 00:07<00:02 0.6253]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████---------| 77.60% [485/625 00:08<00:02 0.6227]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████---------| 79.36% [496/625 00:08<00:02 0.6234]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████--------| 81.12% [507/625 00:08<00:01 0.6133]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████████-------| 82.88% [518/625 00:08<00:01 0.6171]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████████-------| 84.64% [529/625 00:08<00:01 0.6184]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████████------| 86.40% [540/625 00:09<00:01 0.6095]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████████-----| 88.16% [551/625 00:09<00:01 0.6128]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████████-----| 89.92% [562/625 00:09<00:01 0.6120]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████----| 91.68% [573/625 00:09<00:00 0.6117]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████████████---| 93.44% [584/625 00:09<00:00 0.6237]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████████████--| 95.20% [595/625 00:10<00:00 0.6156]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████████████████████--| 96.96% [606/625 00:10<00:00 0.6214]\r",
      "\r",
      "Epoch 1/1 : |███████████████████████████████████████-| 98.72% [617/625 00:10<00:00 0.6298]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6273]\r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6256]\r",
      "\r",
      "Epoch 1/1 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6256]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6256]\r",
      "\r",
      "Epoch 1/1 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6256]\r",
      "\r",
      "Epoch 1/1 : |███████---------------------------------| 19.75% [31/157 00:00<00:00 0.6256]\r",
      "\r",
      "Epoch 1/1 : |███████████████-------------------------| 37.58% [59/157 00:00<00:00 0.6256]\r",
      "\r",
      "Epoch 1/1 : |██████████████████████------------------| 55.41% [87/157 00:00<00:00 0.6256]\r",
      "\r",
      "Epoch 1/1 : |█████████████████████████████-----------| 73.25% [115/157 00:00<00:00 0.6256]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████----| 91.08% [143/157 00:00<00:00 0.6256]\r",
      "\r",
      "Epoch 1/1 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6256]\r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "\r",
      "Epoch 1/1 :                                                                                \r",
      "0         0.625568    0.621104    0.740100  0.214091  0.134447         0.705112       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b680b0f590>>00:11     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from fastai.metrics import Metric\n",
    "\n",
    "class PRAUCScore(Metric):\n",
    "    \"Precision-Recall AUC\"\n",
    "    @property\n",
    "    def name(self): return \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return auc(recall, precision)\n",
    "\n",
    "# Create the learner with class weights and our fixed PR-AUC metric\n",
    "weights = torch.FloatTensor([1, 12])\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(1, 1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6287f",
   "metadata": {
    "input_tokens": 42,
    "output_tokens": 912,
    "solveit_ai": true
   },
   "source": [
    "Could you analyze our metrics and give me your commentary? Is it good or bad? If it's bad, what can we do about it?\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at your metrics after applying class weights, we've seen some improvement but the model is still struggling with the imbalanced classification task:\n",
    "\n",
    "1. **Accuracy: 0.740** - This has decreased from the previous 0.929, which is actually a good sign! The model is no longer just predicting the majority class for everything.\n",
    "\n",
    "2. **F1 Score: 0.214** - This has improved significantly from 0.011, showing better balance between precision and recall, but it's still quite low.\n",
    "\n",
    "3. **Precision: 0.134** - Slightly improved from 0.095, but still poor. Only about 13% of positive predictions are correct.\n",
    "\n",
    "4. **ROC AUC: 0.705** - Essentially unchanged, which is still mediocre.\n",
    "\n",
    "5. **PR-AUC**: Unfortunately there's an issue with the display of this metric, but it would have given us a better view of performance on the minority class.\n",
    "\n",
    "**Assessment**: The model is still performing poorly, but the class weights have helped somewhat by forcing the model to pay more attention to the minority class.\n",
    "\n",
    "**What we can do next:**\n",
    "\n",
    "1. **Train for more epochs** - One epoch isn't enough for the model to learn properly:\n",
    "   ```python\n",
    "   learn.fit_one_cycle(5, 1e-2)\n",
    "   ```\n",
    "\n",
    "2. **Try different weight ratios** - Our current 1:12 ratio might need adjustment:\n",
    "   ```python\n",
    "   weights = torch.FloatTensor([1, 15])  # Try increasing minority class weight\n",
    "   learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary()], \n",
    "                         loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "   ```\n",
    "\n",
    "3. **Use oversampling** - We can create a new dataloader with oversampling:\n",
    "   ```python\n",
    "   from fastai.callback.data import BalancedSampler\n",
    "   \n",
    "   dls_balanced = dls.new(after_batch=[BalancedSampler()])\n",
    "   learn = tabular_learner(dls_balanced, metrics=[accuracy, F1Score(), Precision(), RocAucBinary()])\n",
    "   ```\n",
    "\n",
    "4. **Fix the PR-AUC metric** to properly display:\n",
    "   ```python\n",
    "   class PRAUCScore(Metric):\n",
    "       @property\n",
    "       def name(self): return \"prauc\"\n",
    "       \n",
    "       def reset(self): self.preds, self.targs = [], []\n",
    "       \n",
    "       def accumulate(self, learn):\n",
    "           pred = learn.pred[:,1]\n",
    "           self.preds.append(pred)\n",
    "           self.targs.append(learn.y)\n",
    "       \n",
    "       def value(self):\n",
    "           preds = torch.cat(self.preds).cpu().numpy()\n",
    "           targs = torch.cat(self.targs).cpu().numpy()\n",
    "           precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "           return torch.tensor(auc(recall, precision))\n",
    "   ```\n",
    "\n",
    "I'd recommend trying the oversampling approach with more epochs as the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abac9e1",
   "metadata": {
    "input_tokens": 189,
    "time_run": "9:37:34a"
   },
   "outputs": [],
   "source": [
    "class PRAUCScore(Metric):\n",
    "    @property\n",
    "    def name(self): return \"prauc\"\n",
    "\n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "\n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return torch.tensor(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca52c4",
   "metadata": {
    "input_tokens": 93,
    "time_run": "9:38:16a"
   },
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor([1, 15])  # Try increasing minority class weight\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(),PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5927f98",
   "metadata": {
    "input_tokens": 19,
    "output_tokens": 21880,
    "time_run": "9:39:27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r",
      "epoch     train_loss  valid_loss  accuracy  f1_score  precision_score  roc_auc_score  prauc     time    \n",
      "█\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.16% [1/625 00:00<00:39]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.32% [2/625 00:00<00:26 0.8353]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.48% [3/625 00:00<00:21 0.7919]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.64% [4/625 00:00<00:18 0.7536]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.80% [5/625 00:00<00:17 0.7357]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.92% [12/625 00:00<00:13 0.7643]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 3.36% [21/625 00:00<00:11 0.7532]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 4.96% [31/625 00:00<00:10 0.7250]\r",
      "\r",
      "Epoch 1/5 : |██--------------------------------------| 6.56% [41/625 00:00<00:10 0.7340]\r",
      "\r",
      "Epoch 1/5 : |███-------------------------------------| 8.32% [52/625 00:00<00:10 0.7064]\r",
      "\r",
      "Epoch 1/5 : |████------------------------------------| 10.08% [63/625 00:01<00:09 0.6950]\r",
      "\r",
      "Epoch 1/5 : |████------------------------------------| 11.84% [74/625 00:01<00:09 0.6863]\r",
      "\r",
      "Epoch 1/5 : |█████-----------------------------------| 13.60% [85/625 00:01<00:09 0.6789]\r",
      "\r",
      "Epoch 1/5 : |██████----------------------------------| 15.36% [96/625 00:01<00:09 0.6740]\r",
      "\r",
      "Epoch 1/5 : |██████----------------------------------| 17.12% [107/625 00:01<00:08 0.6749]\r",
      "\r",
      "Epoch 1/5 : |███████---------------------------------| 18.88% [118/625 00:02<00:08 0.6707]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 20.64% [129/625 00:02<00:08 0.6625]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 22.40% [140/625 00:02<00:08 0.6652]\r",
      "\r",
      "Epoch 1/5 : |█████████-------------------------------| 24.16% [151/625 00:02<00:08 0.6807]\r",
      "\r",
      "Epoch 1/5 : |██████████------------------------------| 25.92% [162/625 00:02<00:07 0.6826]\r",
      "\r",
      "Epoch 1/5 : |███████████-----------------------------| 27.68% [173/625 00:02<00:07 0.6700]\r",
      "\r",
      "Epoch 1/5 : |███████████-----------------------------| 29.44% [184/625 00:03<00:07 0.6663]\r",
      "\r",
      "Epoch 1/5 : |████████████----------------------------| 31.20% [195/625 00:03<00:07 0.6661]\r",
      "\r",
      "Epoch 1/5 : |█████████████---------------------------| 32.96% [206/625 00:03<00:07 0.6545]\r",
      "\r",
      "Epoch 1/5 : |█████████████---------------------------| 34.72% [217/625 00:03<00:06 0.6625]\r",
      "\r",
      "Epoch 1/5 : |██████████████--------------------------| 36.48% [228/625 00:03<00:06 0.6614]\r",
      "\r",
      "Epoch 1/5 : |███████████████-------------------------| 38.24% [239/625 00:04<00:06 0.6655]\r",
      "\r",
      "Epoch 1/5 : |████████████████------------------------| 40.00% [250/625 00:04<00:06 0.6540]\r",
      "\r",
      "Epoch 1/5 : |████████████████------------------------| 41.76% [261/625 00:04<00:06 0.6491]\r",
      "\r",
      "Epoch 1/5 : |█████████████████-----------------------| 43.52% [272/625 00:04<00:05 0.6407]\r",
      "\r",
      "Epoch 1/5 : |██████████████████----------------------| 45.28% [283/625 00:04<00:05 0.6408]\r",
      "\r",
      "Epoch 1/5 : |██████████████████----------------------| 47.04% [294/625 00:04<00:05 0.6492]\r",
      "\r",
      "Epoch 1/5 : |███████████████████---------------------| 48.80% [305/625 00:05<00:05 0.6507]\r",
      "\r",
      "Epoch 1/5 : |████████████████████--------------------| 50.56% [316/625 00:05<00:05 0.6562]\r",
      "\r",
      "Epoch 1/5 : |████████████████████--------------------| 52.32% [327/625 00:05<00:04 0.6534]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████-------------------| 54.08% [338/625 00:05<00:04 0.6504]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████------------------| 56.00% [350/625 00:05<00:04 0.6550]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 57.92% [362/625 00:06<00:04 0.6508]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 59.84% [374/625 00:06<00:04 0.6548]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████----------------| 61.76% [386/625 00:06<00:03 0.6507]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████---------------| 63.68% [398/625 00:06<00:03 0.6566]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████--------------| 65.60% [410/625 00:06<00:03 0.6450]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████-------------| 67.52% [422/625 00:07<00:03 0.6391]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████-------------| 69.44% [434/625 00:07<00:03 0.6453]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████------------| 71.36% [446/625 00:07<00:02 0.6531]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████-----------| 73.28% [458/625 00:07<00:02 0.6523]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 75.20% [470/625 00:07<00:02 0.6517]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 77.12% [482/625 00:08<00:02 0.6440]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████---------| 79.04% [494/625 00:08<00:02 0.6437]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████--------| 80.96% [506/625 00:08<00:01 0.6446]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████-------| 82.88% [518/625 00:08<00:01 0.6525]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████-------| 84.80% [530/625 00:08<00:01 0.6552]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████████------| 86.72% [542/625 00:08<00:01 0.6520]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████-----| 88.64% [554/625 00:09<00:01 0.6540]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████----| 90.56% [566/625 00:09<00:00 0.6594]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████----| 92.48% [578/625 00:09<00:00 0.6541]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 94.40% [590/625 00:09<00:00 0.6654]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████████████--| 96.32% [602/625 00:09<00:00 0.6547]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████████-| 98.24% [614/625 00:10<00:00 0.6562]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6539]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6532]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6532]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6532]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6532]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.6532]\r",
      "\r",
      "Epoch 1/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.6532]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.6532]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.6532]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.6532]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6532]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "0         0.653208    0.706873    0.506800  0.128314  0.072833         0.551551       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b66ae4c350>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.32% [2/625 00:00<00:12 0.6532]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.6559]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.6563]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.6578]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6613]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.6704]\r",
      "\r",
      "Epoch 2/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.6622]\r",
      "\r",
      "Epoch 2/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.6599]\r",
      "\r",
      "Epoch 2/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.6585]\r",
      "\r",
      "Epoch 2/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.6617]\r",
      "\r",
      "Epoch 2/5 : |█████-----------------------------------| 13.12% [82/625 00:01<00:09 0.6544]\r",
      "\r",
      "Epoch 2/5 : |██████----------------------------------| 15.04% [94/625 00:01<00:08 0.6610]\r",
      "\r",
      "Epoch 2/5 : |██████----------------------------------| 16.96% [106/625 00:01<00:08 0.6665]\r",
      "\r",
      "Epoch 2/5 : |███████---------------------------------| 18.88% [118/625 00:01<00:08 0.6623]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 20.80% [130/625 00:02<00:08 0.6444]\r",
      "\r",
      "Epoch 2/5 : |█████████-------------------------------| 22.72% [142/625 00:02<00:08 0.6544]\r",
      "\r",
      "Epoch 2/5 : |█████████-------------------------------| 24.64% [154/625 00:02<00:07 0.6578]\r",
      "\r",
      "Epoch 2/5 : |██████████------------------------------| 26.56% [166/625 00:02<00:07 0.6527]\r",
      "\r",
      "Epoch 2/5 : |███████████-----------------------------| 28.48% [178/625 00:02<00:07 0.6526]\r",
      "\r",
      "Epoch 2/5 : |████████████----------------------------| 30.40% [190/625 00:03<00:07 0.6348]\r",
      "\r",
      "Epoch 2/5 : |████████████----------------------------| 32.32% [202/625 00:03<00:06 0.6291]\r",
      "\r",
      "Epoch 2/5 : |█████████████---------------------------| 34.24% [214/625 00:03<00:06 0.6219]\r",
      "\r",
      "Epoch 2/5 : |██████████████--------------------------| 36.16% [226/625 00:03<00:06 0.6378]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 38.08% [238/625 00:03<00:06 0.6391]\r",
      "\r",
      "Epoch 2/5 : |████████████████------------------------| 40.00% [250/625 00:04<00:06 0.6353]\r",
      "\r",
      "Epoch 2/5 : |████████████████------------------------| 41.92% [262/625 00:04<00:05 0.6269]\r",
      "\r",
      "Epoch 2/5 : |█████████████████-----------------------| 43.84% [274/625 00:04<00:05 0.6317]\r",
      "\r",
      "Epoch 2/5 : |██████████████████----------------------| 45.76% [286/625 00:04<00:05 0.6198]\r",
      "\r",
      "Epoch 2/5 : |███████████████████---------------------| 47.68% [298/625 00:04<00:05 0.6326]\r",
      "\r",
      "Epoch 2/5 : |███████████████████---------------------| 49.60% [310/625 00:05<00:05 0.6185]\r",
      "\r",
      "Epoch 2/5 : |████████████████████--------------------| 51.52% [322/625 00:05<00:04 0.6216]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████-------------------| 53.44% [334/625 00:05<00:04 0.6377]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████------------------| 55.36% [346/625 00:05<00:04 0.6411]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████------------------| 57.28% [358/625 00:05<00:04 0.6428]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████-----------------| 59.20% [370/625 00:06<00:04 0.6472]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████----------------| 61.12% [382/625 00:06<00:04 0.6376]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████---------------| 63.04% [394/625 00:06<00:03 0.6416]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████---------------| 64.96% [406/625 00:06<00:03 0.6418]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████--------------| 66.88% [418/625 00:06<00:03 0.6359]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████-------------| 68.80% [430/625 00:07<00:03 0.6298]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████------------| 70.72% [442/625 00:07<00:03 0.6301]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████-----------| 72.64% [454/625 00:07<00:02 0.6233]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████-----------| 74.56% [466/625 00:07<00:02 0.6353]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████----------| 76.48% [478/625 00:07<00:02 0.6351]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████---------| 78.40% [490/625 00:08<00:02 0.6336]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████--------| 80.32% [502/625 00:08<00:02 0.6361]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████--------| 82.24% [514/625 00:08<00:01 0.6351]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████-------| 84.16% [526/625 00:08<00:01 0.6362]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████------| 86.08% [538/625 00:08<00:01 0.6366]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████-----| 88.00% [550/625 00:09<00:01 0.6283]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████-----| 89.92% [562/625 00:09<00:01 0.6250]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████----| 91.84% [574/625 00:09<00:00 0.6309]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████████---| 93.76% [586/625 00:09<00:00 0.6272]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████████--| 95.68% [598/625 00:09<00:00 0.6242]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████████-| 97.60% [610/625 00:10<00:00 0.6106]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████████-| 99.52% [622/625 00:10<00:00 0.6157]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6176]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6159]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6159]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6159]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6159]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.6159]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.6159]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.6159]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.6159]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.6159]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6159]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "1         0.615858    0.650903    0.510300  0.176283  0.099412         0.699230       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b66ae4c350>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.6173]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.6180]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.6213]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.6234]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6251]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.6262]\r",
      "\r",
      "Epoch 3/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.6266]\r",
      "\r",
      "Epoch 3/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.6278]\r",
      "\r",
      "Epoch 3/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.6277]\r",
      "\r",
      "Epoch 3/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.6206]\r",
      "\r",
      "Epoch 3/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.6115]\r",
      "\r",
      "Epoch 3/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:08 0.6032]\r",
      "\r",
      "Epoch 3/5 : |██████----------------------------------| 16.64% [104/625 00:01<00:08 0.6130]\r",
      "\r",
      "Epoch 3/5 : |███████---------------------------------| 18.56% [116/625 00:01<00:08 0.6064]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 20.48% [128/625 00:02<00:08 0.6104]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 22.40% [140/625 00:02<00:08 0.6172]\r",
      "\r",
      "Epoch 3/5 : |█████████-------------------------------| 24.32% [152/625 00:02<00:07 0.6160]\r",
      "\r",
      "Epoch 3/5 : |██████████------------------------------| 26.24% [164/625 00:02<00:07 0.6116]\r",
      "\r",
      "Epoch 3/5 : |███████████-----------------------------| 28.16% [176/625 00:02<00:07 0.6130]\r",
      "\r",
      "Epoch 3/5 : |████████████----------------------------| 30.08% [188/625 00:03<00:07 0.6215]\r",
      "\r",
      "Epoch 3/5 : |████████████----------------------------| 32.00% [200/625 00:03<00:07 0.6162]\r",
      "\r",
      "Epoch 3/5 : |█████████████---------------------------| 33.92% [212/625 00:03<00:06 0.6116]\r",
      "\r",
      "Epoch 3/5 : |██████████████--------------------------| 35.84% [224/625 00:03<00:06 0.6104]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 37.76% [236/625 00:03<00:06 0.6097]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 39.68% [248/625 00:04<00:06 0.6098]\r",
      "\r",
      "Epoch 3/5 : |████████████████------------------------| 41.60% [260/625 00:04<00:06 0.6079]\r",
      "\r",
      "Epoch 3/5 : |█████████████████-----------------------| 43.52% [272/625 00:04<00:05 0.5952]\r",
      "\r",
      "Epoch 3/5 : |██████████████████----------------------| 45.44% [284/625 00:04<00:05 0.5917]\r",
      "\r",
      "Epoch 3/5 : |██████████████████----------------------| 47.36% [296/625 00:04<00:05 0.5900]\r",
      "\r",
      "Epoch 3/5 : |███████████████████---------------------| 49.28% [308/625 00:05<00:05 0.5997]\r",
      "\r",
      "Epoch 3/5 : |████████████████████--------------------| 51.20% [320/625 00:05<00:05 0.6064]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████-------------------| 53.12% [332/625 00:05<00:04 0.6003]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████------------------| 55.04% [344/625 00:05<00:04 0.5994]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████------------------| 56.96% [356/625 00:05<00:04 0.6077]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████-----------------| 58.88% [368/625 00:06<00:04 0.5967]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████----------------| 60.80% [380/625 00:06<00:04 0.6008]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████---------------| 62.72% [392/625 00:06<00:03 0.6041]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████---------------| 64.64% [404/625 00:06<00:03 0.6080]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████--------------| 66.56% [416/625 00:06<00:03 0.6025]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████-------------| 68.48% [428/625 00:07<00:03 0.6049]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████------------| 70.40% [440/625 00:07<00:03 0.6018]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████------------| 72.32% [452/625 00:07<00:02 0.6143]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████-----------| 74.24% [464/625 00:07<00:02 0.6147]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 76.16% [476/625 00:07<00:02 0.6086]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████---------| 78.08% [488/625 00:08<00:02 0.6142]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████--------| 80.00% [500/625 00:08<00:02 0.6092]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████--------| 81.92% [512/625 00:08<00:01 0.6002]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████-------| 83.84% [524/625 00:08<00:01 0.6011]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████------| 85.76% [536/625 00:08<00:01 0.6003]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████-----| 87.68% [548/625 00:09<00:01 0.5949]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████-----| 89.60% [560/625 00:09<00:01 0.5917]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████----| 91.52% [572/625 00:09<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 93.44% [584/625 00:09<00:00 0.5974]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████████--| 95.36% [596/625 00:09<00:00 0.6001]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████████--| 97.28% [608/625 00:10<00:00 0.6050]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████████-| 99.20% [620/625 00:10<00:00 0.6072]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6028]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6027]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6027]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6027]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6027]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.6027]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.6027]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.6027]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.6027]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.6027]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6027]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "2         0.602726    0.677109    0.720000  0.211712  0.130646         0.711746       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b66ae4c350>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.16% [1/625 00:00<00:16]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.6031]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.6029]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.64% [4/625 00:00<00:12 0.6034]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.6014]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6003]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.5974]\r",
      "\r",
      "Epoch 4/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.6010]\r",
      "\r",
      "Epoch 4/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5998]\r",
      "\r",
      "Epoch 4/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.6036]\r",
      "\r",
      "Epoch 4/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.6015]\r",
      "\r",
      "Epoch 4/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.6016]\r",
      "\r",
      "Epoch 4/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:08 0.5977]\r",
      "\r",
      "Epoch 4/5 : |██████----------------------------------| 16.48% [103/625 00:01<00:08 0.5954]\r",
      "\r",
      "Epoch 4/5 : |███████---------------------------------| 18.24% [114/625 00:01<00:08 0.5889]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 20.00% [125/625 00:02<00:08 0.5770]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 21.76% [136/625 00:02<00:08 0.5769]\r",
      "\r",
      "Epoch 4/5 : |█████████-------------------------------| 23.52% [147/625 00:02<00:07 0.5742]\r",
      "\r",
      "Epoch 4/5 : |██████████------------------------------| 25.28% [158/625 00:02<00:07 0.5790]\r",
      "\r",
      "Epoch 4/5 : |██████████------------------------------| 27.04% [169/625 00:02<00:07 0.5795]\r",
      "\r",
      "Epoch 4/5 : |███████████-----------------------------| 28.80% [180/625 00:03<00:07 0.5847]\r",
      "\r",
      "Epoch 4/5 : |████████████----------------------------| 30.56% [191/625 00:03<00:07 0.5902]\r",
      "\r",
      "Epoch 4/5 : |████████████----------------------------| 32.48% [203/625 00:03<00:07 0.5865]\r",
      "\r",
      "Epoch 4/5 : |█████████████---------------------------| 34.40% [215/625 00:03<00:06 0.5813]\r",
      "\r",
      "Epoch 4/5 : |██████████████--------------------------| 36.32% [227/625 00:03<00:06 0.5870]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 38.08% [238/625 00:03<00:06 0.5862]\r",
      "\r",
      "Epoch 4/5 : |████████████████------------------------| 40.00% [250/625 00:04<00:06 0.5788]\r",
      "\r",
      "Epoch 4/5 : |████████████████------------------------| 41.92% [262/625 00:04<00:06 0.5765]\r",
      "\r",
      "Epoch 4/5 : |█████████████████-----------------------| 43.84% [274/625 00:04<00:05 0.5729]\r",
      "\r",
      "Epoch 4/5 : |██████████████████----------------------| 45.76% [286/625 00:04<00:05 0.5810]\r",
      "\r",
      "Epoch 4/5 : |███████████████████---------------------| 47.68% [298/625 00:04<00:05 0.5839]\r",
      "\r",
      "Epoch 4/5 : |███████████████████---------------------| 49.60% [310/625 00:05<00:05 0.5866]\r",
      "\r",
      "Epoch 4/5 : |████████████████████--------------------| 51.52% [322/625 00:05<00:05 0.5976]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████-------------------| 53.44% [334/625 00:05<00:04 0.5928]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████------------------| 55.36% [346/625 00:05<00:04 0.5831]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████------------------| 57.28% [358/625 00:05<00:04 0.5815]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████-----------------| 59.20% [370/625 00:06<00:04 0.5732]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████----------------| 61.12% [382/625 00:06<00:04 0.5758]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████---------------| 63.04% [394/625 00:06<00:03 0.5708]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████---------------| 64.96% [406/625 00:06<00:03 0.5855]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████--------------| 66.88% [418/625 00:06<00:03 0.5853]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████-------------| 68.80% [430/625 00:07<00:03 0.5872]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████------------| 70.72% [442/625 00:07<00:03 0.5941]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████-----------| 72.64% [454/625 00:07<00:02 0.5956]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████-----------| 74.56% [466/625 00:07<00:02 0.5916]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████----------| 76.48% [478/625 00:07<00:02 0.5915]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████---------| 78.40% [490/625 00:08<00:02 0.5926]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████--------| 80.32% [502/625 00:08<00:02 0.5935]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████--------| 82.24% [514/625 00:08<00:01 0.5907]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████-------| 84.16% [526/625 00:08<00:01 0.5890]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████------| 86.08% [538/625 00:08<00:01 0.5816]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████-----| 88.00% [550/625 00:09<00:01 0.5812]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████-----| 89.92% [562/625 00:09<00:01 0.5900]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████----| 91.84% [574/625 00:09<00:00 0.5863]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████████---| 93.76% [586/625 00:09<00:00 0.5904]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████████--| 95.68% [598/625 00:09<00:00 0.5917]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████████-| 97.60% [610/625 00:10<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████████-| 99.52% [622/625 00:10<00:00 0.5922]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5931]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5961]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5961]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5961]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5961]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5961]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "3         0.596093    0.857505    0.630900  0.198480  0.116255         0.709487       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b66ae4c350>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.16% [1/625 00:00<00:16]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.5958]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.5939]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.5972]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.5971]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.5883]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.5885]\r",
      "\r",
      "Epoch 5/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.5822]\r",
      "\r",
      "Epoch 5/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5909]\r",
      "\r",
      "Epoch 5/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.5906]\r",
      "\r",
      "Epoch 5/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.5931]\r",
      "\r",
      "Epoch 5/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.5874]\r",
      "\r",
      "Epoch 5/5 : |█████-----------------------------------| 14.88% [93/625 00:01<00:08 0.5819]\r",
      "\r",
      "Epoch 5/5 : |██████----------------------------------| 16.80% [105/625 00:01<00:08 0.5843]\r",
      "\r",
      "Epoch 5/5 : |███████---------------------------------| 18.72% [117/625 00:01<00:08 0.5815]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 20.64% [129/625 00:02<00:08 0.5838]\r",
      "\r",
      "Epoch 5/5 : |█████████-------------------------------| 22.56% [141/625 00:02<00:08 0.5949]\r",
      "\r",
      "Epoch 5/5 : |█████████-------------------------------| 24.48% [153/625 00:02<00:07 0.5871]\r",
      "\r",
      "Epoch 5/5 : |██████████------------------------------| 26.40% [165/625 00:02<00:07 0.5830]\r",
      "\r",
      "Epoch 5/5 : |███████████-----------------------------| 28.32% [177/625 00:02<00:07 0.5908]\r",
      "\r",
      "Epoch 5/5 : |████████████----------------------------| 30.24% [189/625 00:03<00:07 0.5900]\r",
      "\r",
      "Epoch 5/5 : |████████████----------------------------| 32.16% [201/625 00:03<00:07 0.5860]\r",
      "\r",
      "Epoch 5/5 : |█████████████---------------------------| 34.08% [213/625 00:03<00:06 0.5916]\r",
      "\r",
      "Epoch 5/5 : |██████████████--------------------------| 36.00% [225/625 00:03<00:06 0.5973]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 37.92% [237/625 00:03<00:06 0.5913]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 39.84% [249/625 00:04<00:06 0.5823]\r",
      "\r",
      "Epoch 5/5 : |████████████████------------------------| 41.76% [261/625 00:04<00:06 0.5826]\r",
      "\r",
      "Epoch 5/5 : |█████████████████-----------------------| 43.68% [273/625 00:04<00:05 0.5771]\r",
      "\r",
      "Epoch 5/5 : |██████████████████----------------------| 45.60% [285/625 00:04<00:05 0.5811]\r",
      "\r",
      "Epoch 5/5 : |███████████████████---------------------| 47.52% [297/625 00:04<00:05 0.5898]\r",
      "\r",
      "Epoch 5/5 : |███████████████████---------------------| 49.44% [309/625 00:05<00:05 0.5830]\r",
      "\r",
      "Epoch 5/5 : |████████████████████--------------------| 51.36% [321/625 00:05<00:05 0.5777]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████-------------------| 53.28% [333/625 00:05<00:04 0.5801]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████------------------| 55.20% [345/625 00:05<00:04 0.5775]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████------------------| 57.12% [357/625 00:05<00:04 0.5795]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████-----------------| 59.04% [369/625 00:06<00:04 0.5763]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████----------------| 60.96% [381/625 00:06<00:04 0.5836]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████---------------| 62.88% [393/625 00:06<00:03 0.5852]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████---------------| 64.80% [405/625 00:06<00:03 0.5819]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████--------------| 66.72% [417/625 00:06<00:03 0.5810]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████-------------| 68.64% [429/625 00:07<00:03 0.5781]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████------------| 70.56% [441/625 00:07<00:03 0.5771]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████------------| 72.48% [453/625 00:07<00:02 0.5730]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████-----------| 74.40% [465/625 00:07<00:02 0.5777]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████----------| 76.32% [477/625 00:07<00:02 0.5760]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████---------| 78.24% [489/625 00:08<00:02 0.5751]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████--------| 80.16% [501/625 00:08<00:02 0.5732]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████--------| 82.08% [513/625 00:08<00:01 0.5717]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████-------| 84.00% [525/625 00:08<00:01 0.5662]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████------| 85.92% [537/625 00:08<00:01 0.5740]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████-----| 87.84% [549/625 00:09<00:01 0.5773]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████-----| 89.76% [561/625 00:09<00:01 0.5804]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████----| 91.68% [573/625 00:09<00:00 0.5765]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████████---| 93.60% [585/625 00:09<00:00 0.5809]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████████--| 95.52% [597/625 00:09<00:00 0.5775]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████████--| 97.44% [609/625 00:10<00:00 0.5756]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████████-| 99.36% [621/625 00:10<00:00 0.5741]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5786]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5784]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5784]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5784]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5784]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5784]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5784]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5784]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5784]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5784]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5784]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "4         0.578350    0.671111    0.658600  0.203453  0.120709         0.715169       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b66ae4c350>>00:11     \n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5646cc9",
   "metadata": {
    "input_tokens": 46,
    "output_tokens": 933,
    "solveit_ai": true
   },
   "source": [
    "Can you analyze these metrics and give me your observations? Am I still doing better? I think there's something still wrong with this precision-recall curve metric.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the metrics from your 5-epoch training with increased class weights (1:15), there's definitely improvement, but some issues remain:\n",
    "\n",
    "### Metric Analysis\n",
    "\n",
    "1. **Accuracy**: Improved from 0.506 (epoch 1) to 0.658 (epoch 5). This is more balanced than the initial 0.93, suggesting the model is no longer just predicting the majority class.\n",
    "\n",
    "2. **F1 Score**: Improved from 0.128 to 0.203. Still low, but better than our initial 0.011.\n",
    "\n",
    "3. **Precision**: Increased from 0.072 to 0.120. Still low - only about 12% of positive predictions are correct.\n",
    "\n",
    "4. **ROC AUC**: Improved from 0.551 to 0.715. This is a moderate improvement and suggests better discrimination ability.\n",
    "\n",
    "5. **PR-AUC**: Unfortunately, this metric is still showing as a method reference rather than a value. The issue is that we need to return a tensor rather than a numpy value.\n",
    "\n",
    "### Observations\n",
    "\n",
    "1. **Training Progress**: The metrics improved over epochs, suggesting the model is learning, but we're still seeing relatively low precision and F1 scores.\n",
    "\n",
    "2. **Class Imbalance**: The increased class weights (1:15) have helped, but the model still struggles with the minority class.\n",
    "\n",
    "3. **Best Epoch**: Epoch 3 had the highest accuracy (0.72) but lower F1 and precision than epoch 5, showing the trade-off between overall accuracy and minority class detection.\n",
    "\n",
    "4. **PR-AUC Issue**: The PR-AUC metric is still not displaying properly. We need to fix the return value to be a tensor.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Let's fix the PR-AUC metric:\n",
    "\n",
    "```python\n",
    "class PRAUCScore(Metric):\n",
    "    @property\n",
    "    def name(self): return \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return torch.tensor(auc(recall, precision), dtype=torch.float32)\n",
    "```\n",
    "\n",
    "2. Consider trying balanced sampling instead of class weights:\n",
    "\n",
    "```python\n",
    "from fastai.callback.data import BalancedSampler\n",
    "\n",
    "dls_balanced = dls.new(after_batch=[BalancedSampler()])\n",
    "learn = tabular_learner(dls_balanced, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()])\n",
    "```\n",
    "\n",
    "The model is doing better than before, but precision and F1 scores are still quite low, indicating that while we've improved from the initial state, the model still struggles with correctly identifying the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12de22",
   "metadata": {
    "input_tokens": 82,
    "output_tokens": 226,
    "time_run": "9:42:18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BalancedSampler\n",
      "\u001b[32m      3\u001b[39m dls_balanced = dls.new(after_batch=[BalancedSampler()])\n",
      "\u001b[32m      4\u001b[39m learn = tabular_learner(dls_balanced, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()])\n",
      "\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'BalancedSampler' from 'fastai.callback.data' (/app/data/.local/lib/python3.11/site-packages/fastai/callback/data.py)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BalancedSampler' from 'fastai.callback.data' (/app/data/.local/lib/python3.11/site-packages/fastai/callback/data.py)",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-56b4c84c6746>\", line 1, in <module>\n    from fastai.callback.data import BalancedSampler\n",
      "ImportError: cannot import name 'BalancedSampler' from 'fastai.callback.data' (/app/data/.local/lib/python3.11/site-packages/fastai/callback/data.py)\n"
     ]
    }
   ],
   "source": [
    "from fastai.callback.data import BalancedSampler\n",
    "\n",
    "dls_balanced = dls.new(after_batch=[BalancedSampler()])\n",
    "learn = tabular_learner(dls_balanced, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a18fc",
   "metadata": {
    "input_tokens": 7,
    "output_tokens": 816,
    "solveit_ai": true
   },
   "source": [
    "help me fix the err\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "It seems the `BalancedSampler` isn't available in your version of fastai. Let's implement our own balanced sampler to oversample the minority class:\n",
    "\n",
    "```python\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "# Fix the PR-AUC metric first\n",
    "class PRAUCScore(Metric):\n",
    "    @property\n",
    "    def name(self): return \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return torch.tensor(auc(recall, precision), dtype=torch.float32)\n",
    "\n",
    "# Create a balanced dataloader\n",
    "def create_balanced_dataloader(dls):\n",
    "    # Get training indices\n",
    "    train_idx = dls.train_ds.indices\n",
    "    \n",
    "    # Get labels for training data\n",
    "    train_labels = [dls.train_ds.dataset.y[i] for i in train_idx]\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    \n",
    "    # Calculate class weights (inverse of class frequency)\n",
    "    class_counts = torch.bincount(train_labels)\n",
    "    class_weights = 1. / class_counts.float()\n",
    "    \n",
    "    # Assign weight to each sample\n",
    "    weights = class_weights[train_labels]\n",
    "    \n",
    "    # Create sampler\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "    \n",
    "    # Create new dataloader with sampler\n",
    "    new_dls = dls.new(after_item=dls.after_item, \n",
    "                      after_batch=dls.after_batch, \n",
    "                      train_bs=dls.train_bs,\n",
    "                      valid_bs=dls.valid_bs)\n",
    "    \n",
    "    # Replace the sampler in the training dataloader\n",
    "    new_dls.train.dl.sampler = sampler\n",
    "    \n",
    "    return new_dls\n",
    "\n",
    "# Try a simpler approach using class weights again but with a better metric\n",
    "weights = torch.FloatTensor([1, 20])  # Try an even higher weight for minority class\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train with the new weights\n",
    "learn.fit_one_cycle(5, 1e-2)\n",
    "```\n",
    "\n",
    "This will fix the PR-AUC metric and use an even higher class weight (1:20) to see if we can improve the model's performance on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998bf71d",
   "metadata": {
    "input_tokens": 712,
    "output_tokens": 22000,
    "time_run": "9:44:46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r",
      "epoch     train_loss  valid_loss  accuracy  f1_score  precision_score  roc_auc_score  prauc     time    \n",
      "█\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.16% [1/625 00:00<00:31]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.32% [2/625 00:00<00:23 0.7495]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.48% [3/625 00:00<00:20 0.8200]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.64% [4/625 00:00<00:18 0.8505]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.80% [5/625 00:00<00:17 0.8040]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.92% [12/625 00:00<00:13 0.7878]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 3.36% [21/625 00:00<00:11 0.7397]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 4.96% [31/625 00:00<00:11 0.7169]\r",
      "\r",
      "Epoch 1/5 : |██--------------------------------------| 6.56% [41/625 00:00<00:10 0.7045]\r",
      "\r",
      "Epoch 1/5 : |███-------------------------------------| 8.32% [52/625 00:00<00:10 0.7115]\r",
      "\r",
      "Epoch 1/5 : |████------------------------------------| 10.08% [63/625 00:01<00:09 0.6904]\r",
      "\r",
      "Epoch 1/5 : |████------------------------------------| 11.84% [74/625 00:01<00:09 0.6686]\r",
      "\r",
      "Epoch 1/5 : |█████-----------------------------------| 13.60% [85/625 00:01<00:09 0.6615]\r",
      "\r",
      "Epoch 1/5 : |██████----------------------------------| 15.36% [96/625 00:01<00:09 0.6535]\r",
      "\r",
      "Epoch 1/5 : |██████----------------------------------| 17.12% [107/625 00:01<00:08 0.6585]\r",
      "\r",
      "Epoch 1/5 : |███████---------------------------------| 18.88% [118/625 00:02<00:08 0.6582]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 20.64% [129/625 00:02<00:08 0.6621]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 22.40% [140/625 00:02<00:08 0.6635]\r",
      "\r",
      "Epoch 1/5 : |█████████-------------------------------| 24.16% [151/625 00:02<00:08 0.6596]\r",
      "\r",
      "Epoch 1/5 : |██████████------------------------------| 25.92% [162/625 00:02<00:07 0.6518]\r",
      "\r",
      "Epoch 1/5 : |███████████-----------------------------| 27.68% [173/625 00:02<00:07 0.6533]\r",
      "\r",
      "Epoch 1/5 : |███████████-----------------------------| 29.44% [184/625 00:03<00:07 0.6375]\r",
      "\r",
      "Epoch 1/5 : |████████████----------------------------| 31.20% [195/625 00:03<00:07 0.6283]\r",
      "\r",
      "Epoch 1/5 : |█████████████---------------------------| 32.96% [206/625 00:03<00:07 0.6377]\r",
      "\r",
      "Epoch 1/5 : |█████████████---------------------------| 34.72% [217/625 00:03<00:06 0.6532]\r",
      "\r",
      "Epoch 1/5 : |██████████████--------------------------| 36.48% [228/625 00:03<00:06 0.6529]\r",
      "\r",
      "Epoch 1/5 : |███████████████-------------------------| 38.24% [239/625 00:04<00:06 0.6559]\r",
      "\r",
      "Epoch 1/5 : |████████████████------------------------| 40.00% [250/625 00:04<00:06 0.6588]\r",
      "\r",
      "Epoch 1/5 : |████████████████------------------------| 41.76% [261/625 00:04<00:06 0.6516]\r",
      "\r",
      "Epoch 1/5 : |█████████████████-----------------------| 43.52% [272/625 00:04<00:05 0.6469]\r",
      "\r",
      "Epoch 1/5 : |██████████████████----------------------| 45.28% [283/625 00:04<00:05 0.6632]\r",
      "\r",
      "Epoch 1/5 : |██████████████████----------------------| 47.04% [294/625 00:04<00:05 0.6704]\r",
      "\r",
      "Epoch 1/5 : |███████████████████---------------------| 48.80% [305/625 00:05<00:05 0.6585]\r",
      "\r",
      "Epoch 1/5 : |████████████████████--------------------| 50.56% [316/625 00:05<00:05 0.6552]\r",
      "\r",
      "Epoch 1/5 : |████████████████████--------------------| 52.32% [327/625 00:05<00:05 0.6505]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████-------------------| 54.08% [338/625 00:05<00:04 0.6598]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████------------------| 55.84% [349/625 00:05<00:04 0.6574]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 57.60% [360/625 00:06<00:04 0.6349]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 59.36% [371/625 00:06<00:04 0.6402]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████----------------| 61.12% [382/625 00:06<00:04 0.6484]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████---------------| 62.88% [393/625 00:06<00:03 0.6470]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████---------------| 64.64% [404/625 00:06<00:03 0.6456]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████--------------| 66.40% [415/625 00:06<00:03 0.6456]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████-------------| 68.16% [426/625 00:07<00:03 0.6474]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████-------------| 69.92% [437/625 00:07<00:03 0.6444]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████------------| 71.68% [448/625 00:07<00:02 0.6544]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████-----------| 73.44% [459/625 00:07<00:02 0.6506]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 75.20% [470/625 00:07<00:02 0.6498]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 76.96% [481/625 00:08<00:02 0.6495]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████---------| 78.72% [492/625 00:08<00:02 0.6505]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████--------| 80.48% [503/625 00:08<00:02 0.6455]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████--------| 82.24% [514/625 00:08<00:01 0.6393]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████-------| 84.00% [525/625 00:08<00:01 0.6287]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████████------| 85.76% [536/625 00:08<00:01 0.6325]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████-----| 87.52% [547/625 00:09<00:01 0.6383]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████-----| 89.28% [558/625 00:09<00:01 0.6468]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████----| 91.04% [569/625 00:09<00:00 0.6492]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 92.80% [580/625 00:09<00:00 0.6492]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 94.56% [591/625 00:09<00:00 0.6466]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████████████--| 96.32% [602/625 00:10<00:00 0.6429]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████████-| 98.08% [613/625 00:10<00:00 0.6467]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████████-| 99.84% [624/625 00:10<00:00 0.6385]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6365]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6356]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6356]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6356]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6356]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.6356]\r",
      "\r",
      "Epoch 1/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.6356]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.6356]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.6356]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.6356]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6356]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "0         0.635585    0.722673    0.569800  0.180259  0.103411         0.690304       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b668946650>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.16% [1/625 00:00<00:16]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.6378]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.6409]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.6367]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.6354]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6399]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.6586]\r",
      "\r",
      "Epoch 2/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.6458]\r",
      "\r",
      "Epoch 2/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.6350]\r",
      "\r",
      "Epoch 2/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.6285]\r",
      "\r",
      "Epoch 2/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.6327]\r",
      "\r",
      "Epoch 2/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.6295]\r",
      "\r",
      "Epoch 2/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:08 0.6358]\r",
      "\r",
      "Epoch 2/5 : |██████----------------------------------| 16.48% [103/625 00:01<00:08 0.6191]\r",
      "\r",
      "Epoch 2/5 : |███████---------------------------------| 18.24% [114/625 00:01<00:08 0.6211]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 20.16% [126/625 00:02<00:08 0.6686]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 22.08% [138/625 00:02<00:08 0.6654]\r",
      "\r",
      "Epoch 2/5 : |█████████-------------------------------| 24.00% [150/625 00:02<00:07 0.6645]\r",
      "\r",
      "Epoch 2/5 : |██████████------------------------------| 25.92% [162/625 00:02<00:07 0.6690]\r",
      "\r",
      "Epoch 2/5 : |███████████-----------------------------| 27.84% [174/625 00:02<00:07 0.6568]\r",
      "\r",
      "Epoch 2/5 : |███████████-----------------------------| 29.76% [186/625 00:03<00:07 0.6583]\r",
      "\r",
      "Epoch 2/5 : |████████████----------------------------| 31.68% [198/625 00:03<00:07 0.6411]\r",
      "\r",
      "Epoch 2/5 : |█████████████---------------------------| 33.60% [210/625 00:03<00:06 0.6420]\r",
      "\r",
      "Epoch 2/5 : |██████████████--------------------------| 35.52% [222/625 00:03<00:06 0.6369]\r",
      "\r",
      "Epoch 2/5 : |██████████████--------------------------| 37.44% [234/625 00:03<00:06 0.6318]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 39.36% [246/625 00:04<00:06 0.6321]\r",
      "\r",
      "Epoch 2/5 : |████████████████------------------------| 41.28% [258/625 00:04<00:06 0.6300]\r",
      "\r",
      "Epoch 2/5 : |█████████████████-----------------------| 43.20% [270/625 00:04<00:05 0.6337]\r",
      "\r",
      "Epoch 2/5 : |██████████████████----------------------| 45.12% [282/625 00:04<00:05 0.6256]\r",
      "\r",
      "Epoch 2/5 : |██████████████████----------------------| 47.04% [294/625 00:04<00:05 0.6154]\r",
      "\r",
      "Epoch 2/5 : |███████████████████---------------------| 48.96% [306/625 00:05<00:05 0.6180]\r",
      "\r",
      "Epoch 2/5 : |████████████████████--------------------| 50.88% [318/625 00:05<00:05 0.6100]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████-------------------| 52.80% [330/625 00:05<00:04 0.6079]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████-------------------| 54.72% [342/625 00:05<00:04 0.5964]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████------------------| 56.64% [354/625 00:05<00:04 0.5881]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████-----------------| 58.56% [366/625 00:06<00:04 0.5966]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████----------------| 60.48% [378/625 00:06<00:04 0.5957]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████----------------| 62.40% [390/625 00:06<00:03 0.5975]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████---------------| 64.32% [402/625 00:06<00:03 0.6028]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████--------------| 66.24% [414/625 00:06<00:03 0.5984]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████-------------| 68.16% [426/625 00:07<00:03 0.5908]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████------------| 70.08% [438/625 00:07<00:03 0.5964]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████------------| 72.00% [450/625 00:07<00:02 0.6103]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████-----------| 73.92% [462/625 00:07<00:02 0.6164]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████----------| 75.84% [474/625 00:07<00:02 0.6108]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████---------| 77.76% [486/625 00:08<00:02 0.6088]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████---------| 79.68% [498/625 00:08<00:02 0.6109]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████--------| 81.60% [510/625 00:08<00:01 0.6110]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████-------| 83.52% [522/625 00:08<00:01 0.6031]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████------| 85.44% [534/625 00:08<00:01 0.6154]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████------| 87.36% [546/625 00:09<00:01 0.6181]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████-----| 89.28% [558/625 00:09<00:01 0.6083]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████----| 91.20% [570/625 00:09<00:00 0.6085]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████████---| 93.12% [582/625 00:09<00:00 0.6070]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████████--| 95.04% [594/625 00:09<00:00 0.6012]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████████--| 96.96% [606/625 00:10<00:00 0.5915]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████████-| 98.88% [618/625 00:10<00:00 0.5976]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5931]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5914]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5914]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5914]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5914]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5914]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5914]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5914]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5914]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5914]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5914]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "1         0.591386    0.655083    0.606900  0.189317  0.109940         0.700810       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b668946650>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.5887]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.5911]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.5919]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.5938]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6002]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.6035]\r",
      "\r",
      "Epoch 3/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.5987]\r",
      "\r",
      "Epoch 3/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5942]\r",
      "\r",
      "Epoch 3/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.6047]\r",
      "\r",
      "Epoch 3/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.5934]\r",
      "\r",
      "Epoch 3/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.5900]\r",
      "\r",
      "Epoch 3/5 : |█████-----------------------------------| 14.88% [93/625 00:01<00:08 0.5848]\r",
      "\r",
      "Epoch 3/5 : |██████----------------------------------| 16.80% [105/625 00:01<00:08 0.5957]\r",
      "\r",
      "Epoch 3/5 : |███████---------------------------------| 18.72% [117/625 00:01<00:08 0.5919]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 20.64% [129/625 00:02<00:08 0.5956]\r",
      "\r",
      "Epoch 3/5 : |█████████-------------------------------| 22.56% [141/625 00:02<00:08 0.5950]\r",
      "\r",
      "Epoch 3/5 : |█████████-------------------------------| 24.48% [153/625 00:02<00:07 0.6027]\r",
      "\r",
      "Epoch 3/5 : |██████████------------------------------| 26.40% [165/625 00:02<00:07 0.6022]\r",
      "\r",
      "Epoch 3/5 : |███████████-----------------------------| 28.32% [177/625 00:02<00:07 0.5964]\r",
      "\r",
      "Epoch 3/5 : |████████████----------------------------| 30.24% [189/625 00:03<00:07 0.5950]\r",
      "\r",
      "Epoch 3/5 : |████████████----------------------------| 32.16% [201/625 00:03<00:07 0.6005]\r",
      "\r",
      "Epoch 3/5 : |█████████████---------------------------| 34.08% [213/625 00:03<00:06 0.5916]\r",
      "\r",
      "Epoch 3/5 : |██████████████--------------------------| 36.00% [225/625 00:03<00:06 0.5936]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 37.92% [237/625 00:03<00:06 0.5954]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 39.84% [249/625 00:04<00:06 0.6014]\r",
      "\r",
      "Epoch 3/5 : |████████████████------------------------| 41.76% [261/625 00:04<00:06 0.5888]\r",
      "\r",
      "Epoch 3/5 : |█████████████████-----------------------| 43.68% [273/625 00:04<00:05 0.5992]\r",
      "\r",
      "Epoch 3/5 : |██████████████████----------------------| 45.60% [285/625 00:04<00:05 0.6007]\r",
      "\r",
      "Epoch 3/5 : |███████████████████---------------------| 47.52% [297/625 00:04<00:05 0.5931]\r",
      "\r",
      "Epoch 3/5 : |███████████████████---------------------| 49.44% [309/625 00:05<00:05 0.5892]\r",
      "\r",
      "Epoch 3/5 : |████████████████████--------------------| 51.36% [321/625 00:05<00:05 0.5868]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████-------------------| 53.28% [333/625 00:05<00:04 0.5970]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████------------------| 55.20% [345/625 00:05<00:04 0.5955]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████------------------| 57.12% [357/625 00:05<00:04 0.5939]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████-----------------| 59.04% [369/625 00:06<00:04 0.6055]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████----------------| 60.96% [381/625 00:06<00:04 0.6158]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████---------------| 62.88% [393/625 00:06<00:03 0.6153]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████---------------| 64.80% [405/625 00:06<00:03 0.6025]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████--------------| 66.72% [417/625 00:06<00:03 0.5903]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████-------------| 68.64% [429/625 00:07<00:03 0.5944]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████------------| 70.56% [441/625 00:07<00:03 0.6070]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████------------| 72.48% [453/625 00:07<00:02 0.6110]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████-----------| 74.40% [465/625 00:07<00:02 0.6031]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 76.32% [477/625 00:07<00:02 0.6133]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████---------| 78.24% [489/625 00:08<00:02 0.6013]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████--------| 80.16% [501/625 00:08<00:02 0.5953]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████--------| 82.08% [513/625 00:08<00:01 0.5945]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████-------| 84.00% [525/625 00:08<00:01 0.5984]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████------| 85.92% [537/625 00:08<00:01 0.5956]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████-----| 87.84% [549/625 00:09<00:01 0.5906]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████-----| 89.76% [561/625 00:09<00:01 0.5886]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████----| 91.68% [573/625 00:09<00:00 0.5820]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 93.60% [585/625 00:09<00:00 0.5887]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████████--| 95.52% [597/625 00:09<00:00 0.6044]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████████--| 97.44% [609/625 00:10<00:00 0.5907]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████████-| 99.36% [621/625 00:10<00:00 0.5932]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5901]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5886]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5886]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5886]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5886]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5886]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5886]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5886]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5886]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5886]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5886]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "2         0.588624    0.640042    0.441500  0.170996  0.095002         0.708928       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b668946650>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.5896]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.5904]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.5902]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.5879]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.5804]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.5796]\r",
      "\r",
      "Epoch 4/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.5898]\r",
      "\r",
      "Epoch 4/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5913]\r",
      "\r",
      "Epoch 4/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.5992]\r",
      "\r",
      "Epoch 4/5 : |████------------------------------------| 11.36% [71/625 00:01<00:09 0.5965]\r",
      "\r",
      "Epoch 4/5 : |█████-----------------------------------| 13.28% [83/625 00:01<00:09 0.5912]\r",
      "\r",
      "Epoch 4/5 : |██████----------------------------------| 15.20% [95/625 00:01<00:08 0.5887]\r",
      "\r",
      "Epoch 4/5 : |██████----------------------------------| 17.12% [107/625 00:01<00:08 0.5927]\r",
      "\r",
      "Epoch 4/5 : |███████---------------------------------| 19.04% [119/625 00:01<00:08 0.5918]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 20.96% [131/625 00:02<00:08 0.5888]\r",
      "\r",
      "Epoch 4/5 : |█████████-------------------------------| 22.88% [143/625 00:02<00:07 0.5875]\r",
      "\r",
      "Epoch 4/5 : |█████████-------------------------------| 24.80% [155/625 00:02<00:07 0.5887]\r",
      "\r",
      "Epoch 4/5 : |██████████------------------------------| 26.72% [167/625 00:02<00:07 0.5879]\r",
      "\r",
      "Epoch 4/5 : |███████████-----------------------------| 28.64% [179/625 00:02<00:07 0.5865]\r",
      "\r",
      "Epoch 4/5 : |████████████----------------------------| 30.56% [191/625 00:03<00:07 0.5703]\r",
      "\r",
      "Epoch 4/5 : |████████████----------------------------| 32.48% [203/625 00:03<00:06 0.5588]\r",
      "\r",
      "Epoch 4/5 : |█████████████---------------------------| 34.40% [215/625 00:03<00:06 0.5739]\r",
      "\r",
      "Epoch 4/5 : |██████████████--------------------------| 36.32% [227/625 00:03<00:06 0.5868]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 38.24% [239/625 00:03<00:06 0.5986]\r",
      "\r",
      "Epoch 4/5 : |████████████████------------------------| 40.16% [251/625 00:04<00:06 0.6018]\r",
      "\r",
      "Epoch 4/5 : |████████████████------------------------| 42.08% [263/625 00:04<00:05 0.5996]\r",
      "\r",
      "Epoch 4/5 : |█████████████████-----------------------| 44.00% [275/625 00:04<00:05 0.6036]\r",
      "\r",
      "Epoch 4/5 : |██████████████████----------------------| 45.92% [287/625 00:04<00:05 0.5966]\r",
      "\r",
      "Epoch 4/5 : |███████████████████---------------------| 47.84% [299/625 00:04<00:05 0.5936]\r",
      "\r",
      "Epoch 4/5 : |███████████████████---------------------| 49.76% [311/625 00:05<00:05 0.5885]\r",
      "\r",
      "Epoch 4/5 : |████████████████████--------------------| 51.68% [323/625 00:05<00:05 0.5836]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████-------------------| 53.60% [335/625 00:05<00:04 0.5800]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████------------------| 55.52% [347/625 00:05<00:04 0.5723]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████------------------| 57.44% [359/625 00:05<00:04 0.5712]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████-----------------| 59.36% [371/625 00:06<00:04 0.5797]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████----------------| 61.28% [383/625 00:06<00:04 0.5820]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████---------------| 63.20% [395/625 00:06<00:03 0.5714]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████--------------| 65.12% [407/625 00:06<00:03 0.5788]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████--------------| 67.04% [419/625 00:06<00:03 0.5727]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████-------------| 68.96% [431/625 00:07<00:03 0.5701]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████------------| 70.88% [443/625 00:07<00:03 0.5764]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████-----------| 72.80% [455/625 00:07<00:02 0.5862]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████-----------| 74.72% [467/625 00:07<00:02 0.5892]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████----------| 76.64% [479/625 00:07<00:02 0.5897]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████---------| 78.56% [491/625 00:08<00:02 0.5829]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████--------| 80.48% [503/625 00:08<00:02 0.5734]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████--------| 82.40% [515/625 00:08<00:01 0.5602]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████-------| 84.32% [527/625 00:08<00:01 0.5651]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████------| 86.24% [539/625 00:08<00:01 0.5794]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████-----| 88.16% [551/625 00:09<00:01 0.5787]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████----| 90.08% [563/625 00:09<00:01 0.5882]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████----| 92.00% [575/625 00:09<00:00 0.5834]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████████---| 93.92% [587/625 00:09<00:00 0.5789]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████████--| 95.84% [599/625 00:09<00:00 0.5727]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████████-| 97.76% [611/625 00:10<00:00 0.5867]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████████-| 99.68% [623/625 00:10<00:00 0.5828]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5841]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5852]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5852]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5852]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5852]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5852]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5852]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5852]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5852]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5852]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5852]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "3         0.585208    0.678095    0.551300  0.184627  0.105198         0.704699       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b668946650>>00:11     \n",
      "█\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.32% [2/625 00:00<00:12 0.5855]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.5836]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.5818]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.5814]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.5765]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.5717]\r",
      "\r",
      "Epoch 5/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.5689]\r",
      "\r",
      "Epoch 5/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5653]\r",
      "\r",
      "Epoch 5/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.5875]\r",
      "\r",
      "Epoch 5/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.5794]\r",
      "\r",
      "Epoch 5/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.5888]\r",
      "\r",
      "Epoch 5/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:08 0.5893]\r",
      "\r",
      "Epoch 5/5 : |██████----------------------------------| 16.48% [103/625 00:01<00:08 0.5874]\r",
      "\r",
      "Epoch 5/5 : |███████---------------------------------| 18.40% [115/625 00:01<00:08 0.5873]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 20.32% [127/625 00:02<00:08 0.5844]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 22.24% [139/625 00:02<00:08 0.5942]\r",
      "\r",
      "Epoch 5/5 : |█████████-------------------------------| 24.16% [151/625 00:02<00:07 0.5934]\r",
      "\r",
      "Epoch 5/5 : |██████████------------------------------| 26.08% [163/625 00:02<00:07 0.5824]\r",
      "\r",
      "Epoch 5/5 : |███████████-----------------------------| 28.00% [175/625 00:02<00:07 0.5891]\r",
      "\r",
      "Epoch 5/5 : |███████████-----------------------------| 29.92% [187/625 00:03<00:07 0.5795]\r",
      "\r",
      "Epoch 5/5 : |████████████----------------------------| 31.84% [199/625 00:03<00:07 0.5870]\r",
      "\r",
      "Epoch 5/5 : |█████████████---------------------------| 33.76% [211/625 00:03<00:06 0.5847]\r",
      "\r",
      "Epoch 5/5 : |██████████████--------------------------| 35.68% [223/625 00:03<00:06 0.5893]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 37.60% [235/625 00:03<00:06 0.5781]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 39.52% [247/625 00:04<00:06 0.5810]\r",
      "\r",
      "Epoch 5/5 : |████████████████------------------------| 41.44% [259/625 00:04<00:06 0.5890]\r",
      "\r",
      "Epoch 5/5 : |█████████████████-----------------------| 43.36% [271/625 00:04<00:05 0.5743]\r",
      "\r",
      "Epoch 5/5 : |██████████████████----------------------| 45.28% [283/625 00:04<00:05 0.5771]\r",
      "\r",
      "Epoch 5/5 : |██████████████████----------------------| 47.20% [295/625 00:04<00:05 0.5770]\r",
      "\r",
      "Epoch 5/5 : |███████████████████---------------------| 49.12% [307/625 00:05<00:05 0.5695]\r",
      "\r",
      "Epoch 5/5 : |████████████████████--------------------| 51.04% [319/625 00:05<00:05 0.5669]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████-------------------| 52.96% [331/625 00:05<00:04 0.5680]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████-------------------| 54.88% [343/625 00:05<00:04 0.5682]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████------------------| 56.80% [355/625 00:05<00:04 0.5716]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████-----------------| 58.72% [367/625 00:06<00:04 0.5578]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████----------------| 60.64% [379/625 00:06<00:04 0.5604]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████---------------| 62.56% [391/625 00:06<00:03 0.5742]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████---------------| 64.48% [403/625 00:06<00:03 0.5773]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████--------------| 66.40% [415/625 00:06<00:03 0.5860]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████-------------| 68.32% [427/625 00:07<00:03 0.5856]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████------------| 70.24% [439/625 00:07<00:03 0.5901]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████------------| 72.16% [451/625 00:07<00:02 0.5795]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████-----------| 74.08% [463/625 00:07<00:02 0.5725]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████----------| 76.00% [475/625 00:07<00:02 0.5857]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████---------| 77.92% [487/625 00:08<00:02 0.5779]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████---------| 79.84% [499/625 00:08<00:02 0.5839]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████--------| 81.76% [511/625 00:08<00:01 0.5910]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████-------| 83.68% [523/625 00:08<00:01 0.5788]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████------| 85.60% [535/625 00:08<00:01 0.5663]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████-----| 87.52% [547/625 00:09<00:01 0.5620]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████-----| 89.44% [559/625 00:09<00:01 0.5621]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████----| 91.36% [571/625 00:09<00:00 0.5642]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████████---| 93.28% [583/625 00:09<00:00 0.5536]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████████--| 95.20% [595/625 00:09<00:00 0.5612]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████████--| 97.12% [607/625 00:10<00:00 0.5553]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████████-| 99.04% [619/625 00:10<00:00 0.5512]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5550]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5524]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5524]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5524]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5524]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5524]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 38.85% [61/157 00:00<00:00 0.5524]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████------------------| 57.32% [90/157 00:00<00:00 0.5524]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████----------| 75.16% [118/157 00:00<00:00 0.5524]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████████---| 92.99% [146/157 00:01<00:00 0.5524]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5524]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "4         0.552404    0.757290    0.554300  0.185936  0.106020         0.704332       <bound method PRAUCScore.value of <__main__.PRAUCScore object at 0x76b668946650>>00:11     \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "# Fix the PR-AUC metric first\n",
    "class PRAUCScore(Metric):\n",
    "    @property\n",
    "    def name(self): return \"prauc\"\n",
    "    \n",
    "    def reset(self): self.preds, self.targs = [], []\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[:,1]\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        precision, recall, _ = precision_recall_curve(targs, preds)\n",
    "        return torch.tensor(auc(recall, precision), dtype=torch.float32)\n",
    "\n",
    "# Create a balanced dataloader\n",
    "def create_balanced_dataloader(dls):\n",
    "    # Get training indices\n",
    "    train_idx = dls.train_ds.indices\n",
    "    \n",
    "    # Get labels for training data\n",
    "    train_labels = [dls.train_ds.dataset.y[i] for i in train_idx]\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    \n",
    "    # Calculate class weights (inverse of class frequency)\n",
    "    class_counts = torch.bincount(train_labels)\n",
    "    class_weights = 1. / class_counts.float()\n",
    "    \n",
    "    # Assign weight to each sample\n",
    "    weights = class_weights[train_labels]\n",
    "    \n",
    "    # Create sampler\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "    \n",
    "    # Create new dataloader with sampler\n",
    "    new_dls = dls.new(after_item=dls.after_item, \n",
    "                      after_batch=dls.after_batch, \n",
    "                      train_bs=dls.train_bs,\n",
    "                      valid_bs=dls.valid_bs)\n",
    "    \n",
    "    # Replace the sampler in the training dataloader\n",
    "    new_dls.train.dl.sampler = sampler\n",
    "    \n",
    "    return new_dls\n",
    "\n",
    "# Try a simpler approach using class weights again but with a better metric\n",
    "weights = torch.FloatTensor([1, 20])  # Try an even higher weight for minority class\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary(), PRAUCScore()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "\n",
    "# Train with the new weights\n",
    "learn.fit_one_cycle(5, 1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576b64b",
   "metadata": {
    "input_tokens": 57,
    "output_tokens": 999,
    "solveit_ai": true
   },
   "source": [
    "Please analyze the matrix and give me a recommendation. For the precision-recall curve, I think we should use the native SKlearn, not the customized fastAI version. Please implement that.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the metrics from your 5-epoch training with the higher class weights (1:20), here's my analysis:\n",
    "\n",
    "### Metrics Analysis\n",
    "\n",
    "1. **Accuracy**: Stabilized around 0.55, which is more balanced than the initial 0.93.\n",
    "2. **F1 Score**: Improved to ~0.186, better than our initial 0.011 but still low.\n",
    "3. **Precision**: Around 0.106, indicating only ~10.6% of positive predictions are correct.\n",
    "4. **ROC AUC**: Consistently around 0.70, which is moderate discrimination ability.\n",
    "5. **PR-AUC**: Still showing as a method reference rather than a value.\n",
    "\n",
    "### Observations\n",
    "\n",
    "The model is still struggling with the imbalanced classification task. Despite using higher class weights (1:20), the precision and F1 scores remain low, suggesting the model has difficulty correctly identifying the minority class.\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "Let's implement a proper evaluation using scikit-learn's precision-recall curve and AUC calculation directly, rather than trying to integrate it into fastai's metrics system:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model with the existing setup\n",
    "weights = torch.FloatTensor([1, 20])\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "learn.fit_one_cycle(5, 1e-2)\n",
    "\n",
    "# Get predictions on validation set\n",
    "preds, targets = learn.get_preds()\n",
    "probs = preds[:, 1].numpy()  # Probability of positive class\n",
    "actual = targets.numpy()\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(actual, probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "ap = average_precision_score(actual, probs)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.3f}, AP = {ap:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
    "print(f\"Average Precision: {ap:.4f}\")\n",
    "\n",
    "# Get confusion matrix at default threshold (0.5)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred = (probs >= 0.5).astype(int)\n",
    "cm = confusion_matrix(actual, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(actual, y_pred))\n",
    "```\n",
    "\n",
    "This will give you a more comprehensive evaluation of the model's performance on the imbalanced dataset, including the precision-recall curve, average precision, confusion matrix, and a detailed classification report.\n",
    "\n",
    "For further improvement, you might want to try:\n",
    "1. Using SMOTE or other advanced resampling techniques\n",
    "2. Trying different architectures or preprocessing\n",
    "3. Using a different threshold (not necessarily 0.5) for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9a49b",
   "metadata": {
    "input_tokens": 517,
    "output_tokens": 23242,
    "time_run": "9:48:43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r",
      "epoch     train_loss  valid_loss  accuracy  f1_score  precision_score  roc_auc_score  time    \n",
      "█\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.16% [1/625 00:00<00:27]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.32% [2/625 00:00<00:21 0.7799]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.48% [3/625 00:00<00:18 0.6952]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.64% [4/625 00:00<00:17 0.7122]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.80% [5/625 00:00<00:16 0.7351]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.92% [12/625 00:00<00:12 0.7590]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 3.36% [21/625 00:00<00:11 0.7708]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 4.96% [31/625 00:00<00:10 0.7244]\r",
      "\r",
      "Epoch 1/5 : |██--------------------------------------| 6.56% [41/625 00:00<00:10 0.7304]\r",
      "\r",
      "Epoch 1/5 : |███-------------------------------------| 8.32% [52/625 00:00<00:10 0.6993]\r",
      "\r",
      "Epoch 1/5 : |████------------------------------------| 10.08% [63/625 00:01<00:09 0.6861]\r",
      "\r",
      "Epoch 1/5 : |████------------------------------------| 11.84% [74/625 00:01<00:09 0.6707]\r",
      "\r",
      "Epoch 1/5 : |█████-----------------------------------| 13.60% [85/625 00:01<00:09 0.6547]\r",
      "\r",
      "Epoch 1/5 : |██████----------------------------------| 15.36% [96/625 00:01<00:09 0.6651]\r",
      "\r",
      "Epoch 1/5 : |██████----------------------------------| 17.12% [107/625 00:01<00:08 0.6585]\r",
      "\r",
      "Epoch 1/5 : |███████---------------------------------| 18.88% [118/625 00:02<00:08 0.6633]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 20.64% [129/625 00:02<00:08 0.6557]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 22.40% [140/625 00:02<00:08 0.6482]\r",
      "\r",
      "Epoch 1/5 : |█████████-------------------------------| 24.16% [151/625 00:02<00:08 0.6538]\r",
      "\r",
      "Epoch 1/5 : |██████████------------------------------| 25.92% [162/625 00:02<00:07 0.6585]\r",
      "\r",
      "Epoch 1/5 : |███████████-----------------------------| 27.68% [173/625 00:02<00:07 0.6596]\r",
      "\r",
      "Epoch 1/5 : |███████████-----------------------------| 29.44% [184/625 00:03<00:07 0.6572]\r",
      "\r",
      "Epoch 1/5 : |████████████----------------------------| 31.20% [195/625 00:03<00:07 0.6509]\r",
      "\r",
      "Epoch 1/5 : |█████████████---------------------------| 32.96% [206/625 00:03<00:07 0.6528]\r",
      "\r",
      "Epoch 1/5 : |█████████████---------------------------| 34.72% [217/625 00:03<00:06 0.6521]\r",
      "\r",
      "Epoch 1/5 : |██████████████--------------------------| 36.48% [228/625 00:03<00:06 0.6503]\r",
      "\r",
      "Epoch 1/5 : |███████████████-------------------------| 38.24% [239/625 00:04<00:06 0.6418]\r",
      "\r",
      "Epoch 1/5 : |████████████████------------------------| 40.00% [250/625 00:04<00:06 0.6388]\r",
      "\r",
      "Epoch 1/5 : |████████████████------------------------| 41.76% [261/625 00:04<00:06 0.6271]\r",
      "\r",
      "Epoch 1/5 : |█████████████████-----------------------| 43.52% [272/625 00:04<00:05 0.6277]\r",
      "\r",
      "Epoch 1/5 : |██████████████████----------------------| 45.28% [283/625 00:04<00:05 0.6258]\r",
      "\r",
      "Epoch 1/5 : |██████████████████----------------------| 47.04% [294/625 00:04<00:05 0.6183]\r",
      "\r",
      "Epoch 1/5 : |███████████████████---------------------| 48.80% [305/625 00:05<00:05 0.6122]\r",
      "\r",
      "Epoch 1/5 : |████████████████████--------------------| 50.56% [316/625 00:05<00:05 0.6080]\r",
      "\r",
      "Epoch 1/5 : |████████████████████--------------------| 52.32% [327/625 00:05<00:05 0.6189]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████-------------------| 54.08% [338/625 00:05<00:04 0.6271]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████------------------| 55.84% [349/625 00:05<00:04 0.6323]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 57.60% [360/625 00:06<00:04 0.6299]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 59.36% [371/625 00:06<00:04 0.6295]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████----------------| 61.12% [382/625 00:06<00:04 0.6312]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████---------------| 62.88% [393/625 00:06<00:03 0.6314]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████---------------| 64.64% [404/625 00:06<00:03 0.6175]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████--------------| 66.40% [415/625 00:06<00:03 0.6143]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████-------------| 68.16% [426/625 00:07<00:03 0.6282]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████-------------| 69.92% [437/625 00:07<00:03 0.6171]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████------------| 71.68% [448/625 00:07<00:02 0.6334]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████-----------| 73.44% [459/625 00:07<00:02 0.6301]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 75.20% [470/625 00:07<00:02 0.6333]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 76.96% [481/625 00:08<00:02 0.6309]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████---------| 78.72% [492/625 00:08<00:02 0.6299]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████--------| 80.48% [503/625 00:08<00:02 0.6264]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████--------| 82.24% [514/625 00:08<00:01 0.6375]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████-------| 84.00% [525/625 00:08<00:01 0.6350]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████████------| 85.76% [536/625 00:08<00:01 0.6292]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████-----| 87.52% [547/625 00:09<00:01 0.6289]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████-----| 89.28% [558/625 00:09<00:01 0.6439]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████----| 91.04% [569/625 00:09<00:00 0.6479]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 92.80% [580/625 00:09<00:00 0.6469]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 94.56% [591/625 00:09<00:00 0.6454]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████████████--| 96.32% [602/625 00:10<00:00 0.6461]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████████-| 98.08% [613/625 00:10<00:00 0.6334]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████████████████████-| 99.84% [624/625 00:10<00:00 0.6340]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6315]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6291]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6291]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6291]\r",
      "\r",
      "Epoch 1/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6291]\r",
      "\r",
      "Epoch 1/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.6291]\r",
      "\r",
      "Epoch 1/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.6291]\r",
      "\r",
      "Epoch 1/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.6291]\r",
      "\r",
      "Epoch 1/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.6291]\r",
      "\r",
      "Epoch 1/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.6291]\r",
      "\r",
      "Epoch 1/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6291]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "0         0.629062    0.666455    0.600400  0.175743  0.102060         0.657996       00:11     \n",
      "█\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.32% [2/625 00:00<00:12 0.6277]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.48% [3/625 00:00<00:11 0.6250]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.6252]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.6231]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 2.56% [16/625 00:00<00:10 0.6415]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 4.32% [27/625 00:00<00:10 0.6566]\r",
      "\r",
      "Epoch 2/5 : |██--------------------------------------| 6.08% [38/625 00:00<00:09 0.6599]\r",
      "\r",
      "Epoch 2/5 : |███-------------------------------------| 7.84% [49/625 00:00<00:09 0.6530]\r",
      "\r",
      "Epoch 2/5 : |███-------------------------------------| 9.60% [60/625 00:01<00:09 0.6413]\r",
      "\r",
      "Epoch 2/5 : |████------------------------------------| 11.36% [71/625 00:01<00:09 0.6385]\r",
      "\r",
      "Epoch 2/5 : |█████-----------------------------------| 13.12% [82/625 00:01<00:09 0.6451]\r",
      "\r",
      "Epoch 2/5 : |█████-----------------------------------| 14.88% [93/625 00:01<00:08 0.6264]\r",
      "\r",
      "Epoch 2/5 : |██████----------------------------------| 16.64% [104/625 00:01<00:08 0.6158]\r",
      "\r",
      "Epoch 2/5 : |███████---------------------------------| 18.40% [115/625 00:01<00:08 0.6328]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 20.32% [127/625 00:02<00:08 0.6173]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 22.24% [139/625 00:02<00:08 0.6243]\r",
      "\r",
      "Epoch 2/5 : |█████████-------------------------------| 24.16% [151/625 00:02<00:07 0.6197]\r",
      "\r",
      "Epoch 2/5 : |██████████------------------------------| 26.08% [163/625 00:02<00:07 0.6197]\r",
      "\r",
      "Epoch 2/5 : |███████████-----------------------------| 28.00% [175/625 00:02<00:07 0.6224]\r",
      "\r",
      "Epoch 2/5 : |███████████-----------------------------| 29.92% [187/625 00:03<00:07 0.6503]\r",
      "\r",
      "Epoch 2/5 : |████████████----------------------------| 31.84% [199/625 00:03<00:07 0.6492]\r",
      "\r",
      "Epoch 2/5 : |█████████████---------------------------| 33.76% [211/625 00:03<00:06 0.6505]\r",
      "\r",
      "Epoch 2/5 : |██████████████--------------------------| 35.68% [223/625 00:03<00:06 0.6351]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 37.60% [235/625 00:03<00:06 0.6446]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 39.52% [247/625 00:04<00:06 0.6282]\r",
      "\r",
      "Epoch 2/5 : |████████████████------------------------| 41.44% [259/625 00:04<00:06 0.6387]\r",
      "\r",
      "Epoch 2/5 : |█████████████████-----------------------| 43.36% [271/625 00:04<00:05 0.6351]\r",
      "\r",
      "Epoch 2/5 : |██████████████████----------------------| 45.28% [283/625 00:04<00:05 0.6350]\r",
      "\r",
      "Epoch 2/5 : |██████████████████----------------------| 47.20% [295/625 00:04<00:05 0.6258]\r",
      "\r",
      "Epoch 2/5 : |███████████████████---------------------| 49.12% [307/625 00:05<00:05 0.6412]\r",
      "\r",
      "Epoch 2/5 : |████████████████████--------------------| 51.04% [319/625 00:05<00:05 0.6328]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████-------------------| 52.96% [331/625 00:05<00:04 0.6320]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████-------------------| 54.88% [343/625 00:05<00:04 0.6235]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████------------------| 56.80% [355/625 00:05<00:04 0.6248]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████-----------------| 58.72% [367/625 00:06<00:04 0.6349]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████----------------| 60.64% [379/625 00:06<00:04 0.6490]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████---------------| 62.56% [391/625 00:06<00:03 0.6484]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████---------------| 64.48% [403/625 00:06<00:03 0.6399]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████--------------| 66.40% [415/625 00:06<00:03 0.6395]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████-------------| 68.32% [427/625 00:07<00:03 0.6380]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████------------| 70.24% [439/625 00:07<00:03 0.6328]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████------------| 72.16% [451/625 00:07<00:02 0.6271]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████-----------| 74.08% [463/625 00:07<00:02 0.6252]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████----------| 76.00% [475/625 00:07<00:02 0.6294]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████---------| 77.92% [487/625 00:08<00:02 0.6282]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████---------| 79.84% [499/625 00:08<00:02 0.6282]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████--------| 81.76% [511/625 00:08<00:01 0.6287]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████-------| 83.68% [523/625 00:08<00:01 0.6143]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████------| 85.60% [535/625 00:08<00:01 0.6140]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████-----| 87.52% [547/625 00:09<00:01 0.6135]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████-----| 89.44% [559/625 00:09<00:01 0.6069]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████----| 91.36% [571/625 00:09<00:00 0.6021]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████████---| 93.28% [583/625 00:09<00:00 0.6067]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████████--| 95.20% [595/625 00:09<00:00 0.6082]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████████████--| 97.12% [607/625 00:10<00:00 0.6079]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████████████████████-| 99.04% [619/625 00:10<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.6179]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.6168]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.6168]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.6168]\r",
      "\r",
      "Epoch 2/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.6168]\r",
      "\r",
      "Epoch 2/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.6168]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "1         0.616822    0.636830    0.380800  0.163469  0.089923         0.714268       00:11     \n",
      "█\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.6127]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.6138]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.6114]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.6116]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6116]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.6167]\r",
      "\r",
      "Epoch 3/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.6164]\r",
      "\r",
      "Epoch 3/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.6149]\r",
      "\r",
      "Epoch 3/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.6134]\r",
      "\r",
      "Epoch 3/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.6054]\r",
      "\r",
      "Epoch 3/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.5937]\r",
      "\r",
      "Epoch 3/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:08 0.5945]\r",
      "\r",
      "Epoch 3/5 : |██████----------------------------------| 16.48% [103/625 00:01<00:08 0.5877]\r",
      "\r",
      "Epoch 3/5 : |███████---------------------------------| 18.24% [114/625 00:01<00:08 0.5892]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 20.00% [125/625 00:02<00:08 0.6054]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 21.76% [136/625 00:02<00:08 0.5983]\r",
      "\r",
      "Epoch 3/5 : |█████████-------------------------------| 23.68% [148/625 00:02<00:07 0.5965]\r",
      "\r",
      "Epoch 3/5 : |██████████------------------------------| 25.60% [160/625 00:02<00:07 0.5964]\r",
      "\r",
      "Epoch 3/5 : |███████████-----------------------------| 27.52% [172/625 00:02<00:07 0.5952]\r",
      "\r",
      "Epoch 3/5 : |███████████-----------------------------| 29.44% [184/625 00:03<00:07 0.5988]\r",
      "\r",
      "Epoch 3/5 : |████████████----------------------------| 31.36% [196/625 00:03<00:07 0.5864]\r",
      "\r",
      "Epoch 3/5 : |█████████████---------------------------| 33.28% [208/625 00:03<00:06 0.5925]\r",
      "\r",
      "Epoch 3/5 : |██████████████--------------------------| 35.20% [220/625 00:03<00:06 0.5947]\r",
      "\r",
      "Epoch 3/5 : |██████████████--------------------------| 37.12% [232/625 00:03<00:06 0.5900]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 39.04% [244/625 00:04<00:06 0.5914]\r",
      "\r",
      "Epoch 3/5 : |████████████████------------------------| 40.96% [256/625 00:04<00:06 0.6010]\r",
      "\r",
      "Epoch 3/5 : |█████████████████-----------------------| 42.88% [268/625 00:04<00:05 0.6003]\r",
      "\r",
      "Epoch 3/5 : |█████████████████-----------------------| 44.80% [280/625 00:04<00:05 0.5993]\r",
      "\r",
      "Epoch 3/5 : |██████████████████----------------------| 46.72% [292/625 00:04<00:05 0.5908]\r",
      "\r",
      "Epoch 3/5 : |███████████████████---------------------| 48.64% [304/625 00:05<00:05 0.5848]\r",
      "\r",
      "Epoch 3/5 : |████████████████████--------------------| 50.56% [316/625 00:05<00:05 0.5911]\r",
      "\r",
      "Epoch 3/5 : |████████████████████--------------------| 52.48% [328/625 00:05<00:04 0.5944]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████-------------------| 54.40% [340/625 00:05<00:04 0.5856]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████------------------| 56.32% [352/625 00:05<00:04 0.5830]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████-----------------| 58.24% [364/625 00:06<00:04 0.5966]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████----------------| 60.16% [376/625 00:06<00:04 0.5944]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████----------------| 62.08% [388/625 00:06<00:03 0.6024]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████---------------| 64.00% [400/625 00:06<00:03 0.6042]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████--------------| 65.92% [412/625 00:06<00:03 0.6083]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████-------------| 67.84% [424/625 00:07<00:03 0.5979]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████-------------| 69.76% [436/625 00:07<00:03 0.5966]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████------------| 71.68% [448/625 00:07<00:02 0.6003]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████-----------| 73.60% [460/625 00:07<00:02 0.5856]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 75.52% [472/625 00:07<00:02 0.5780]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 77.44% [484/625 00:08<00:02 0.5817]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████---------| 79.36% [496/625 00:08<00:02 0.5875]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████--------| 81.28% [508/625 00:08<00:01 0.5835]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████-------| 83.20% [520/625 00:08<00:01 0.5843]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████------| 85.12% [532/625 00:08<00:01 0.5891]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████------| 87.04% [544/625 00:09<00:01 0.5898]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████-----| 88.96% [556/625 00:09<00:01 0.5932]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████----| 90.88% [568/625 00:09<00:00 0.5989]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 92.80% [580/625 00:09<00:00 0.5941]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 94.72% [592/625 00:09<00:00 0.6090]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████████████--| 96.64% [604/625 00:10<00:00 0.6009]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████████████████████-| 98.56% [616/625 00:10<00:00 0.5930]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5930]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5926]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5926]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5926]\r",
      "\r",
      "Epoch 3/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5926]\r",
      "\r",
      "Epoch 3/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5926]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "2         0.592572    0.625832    0.566200  0.189765  0.108547         0.716097       00:11     \n",
      "█\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.5910]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.5943]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.5937]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.5950]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.6009]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.6002]\r",
      "\r",
      "Epoch 4/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:09 0.5946]\r",
      "\r",
      "Epoch 4/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5922]\r",
      "\r",
      "Epoch 4/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.5830]\r",
      "\r",
      "Epoch 4/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.5814]\r",
      "\r",
      "Epoch 4/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.5718]\r",
      "\r",
      "Epoch 4/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:08 0.5741]\r",
      "\r",
      "Epoch 4/5 : |██████----------------------------------| 16.48% [103/625 00:01<00:08 0.5746]\r",
      "\r",
      "Epoch 4/5 : |███████---------------------------------| 18.24% [114/625 00:01<00:08 0.5693]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 20.00% [125/625 00:02<00:08 0.5670]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 21.76% [136/625 00:02<00:08 0.5781]\r",
      "\r",
      "Epoch 4/5 : |█████████-------------------------------| 23.52% [147/625 00:02<00:08 0.5811]\r",
      "\r",
      "Epoch 4/5 : |██████████------------------------------| 25.28% [158/625 00:02<00:07 0.5750]\r",
      "\r",
      "Epoch 4/5 : |██████████------------------------------| 27.04% [169/625 00:02<00:07 0.5770]\r",
      "\r",
      "Epoch 4/5 : |███████████-----------------------------| 28.80% [180/625 00:03<00:07 0.5730]\r",
      "\r",
      "Epoch 4/5 : |████████████----------------------------| 30.56% [191/625 00:03<00:07 0.5768]\r",
      "\r",
      "Epoch 4/5 : |████████████----------------------------| 32.32% [202/625 00:03<00:07 0.5645]\r",
      "\r",
      "Epoch 4/5 : |█████████████---------------------------| 34.08% [213/625 00:03<00:06 0.5845]\r",
      "\r",
      "Epoch 4/5 : |██████████████--------------------------| 35.84% [224/625 00:03<00:06 0.5818]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 37.60% [235/625 00:03<00:06 0.5803]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 39.36% [246/625 00:04<00:06 0.5926]\r",
      "\r",
      "Epoch 4/5 : |████████████████------------------------| 41.12% [257/625 00:04<00:06 0.5844]\r",
      "\r",
      "Epoch 4/5 : |█████████████████-----------------------| 42.88% [268/625 00:04<00:05 0.5867]\r",
      "\r",
      "Epoch 4/5 : |█████████████████-----------------------| 44.64% [279/625 00:04<00:05 0.5796]\r",
      "\r",
      "Epoch 4/5 : |██████████████████----------------------| 46.40% [290/625 00:04<00:05 0.5788]\r",
      "\r",
      "Epoch 4/5 : |███████████████████---------------------| 48.16% [301/625 00:05<00:05 0.5685]\r",
      "\r",
      "Epoch 4/5 : |███████████████████---------------------| 49.92% [312/625 00:05<00:05 0.5689]\r",
      "\r",
      "Epoch 4/5 : |████████████████████--------------------| 51.68% [323/625 00:05<00:05 0.5751]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████-------------------| 53.44% [334/625 00:05<00:04 0.5765]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████------------------| 55.20% [345/625 00:05<00:04 0.5758]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████------------------| 56.96% [356/625 00:05<00:04 0.5756]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████-----------------| 58.72% [367/625 00:06<00:04 0.5706]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████----------------| 60.48% [378/625 00:06<00:04 0.5636]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████----------------| 62.24% [389/625 00:06<00:03 0.5658]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████---------------| 64.00% [400/625 00:06<00:03 0.5618]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████--------------| 65.76% [411/625 00:06<00:03 0.5557]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████-------------| 67.52% [422/625 00:07<00:03 0.5678]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████-------------| 69.28% [433/625 00:07<00:03 0.5810]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████------------| 71.04% [444/625 00:07<00:03 0.5790]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████-----------| 72.80% [455/625 00:07<00:02 0.5734]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████-----------| 74.56% [466/625 00:07<00:02 0.5711]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████----------| 76.32% [477/625 00:07<00:02 0.5730]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████---------| 78.08% [488/625 00:08<00:02 0.5670]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████---------| 79.84% [499/625 00:08<00:02 0.5672]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████--------| 81.60% [510/625 00:08<00:01 0.5701]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████-------| 83.36% [521/625 00:08<00:01 0.5821]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████------| 85.12% [532/625 00:08<00:01 0.5827]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████------| 86.88% [543/625 00:09<00:01 0.5817]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████-----| 88.64% [554/625 00:09<00:01 0.5747]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████----| 90.40% [565/625 00:09<00:01 0.5763]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████----| 92.16% [576/625 00:09<00:00 0.5681]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████████---| 93.92% [587/625 00:09<00:00 0.5617]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████████--| 95.68% [598/625 00:09<00:00 0.5560]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████████████--| 97.44% [609/625 00:10<00:00 0.5602]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████████████████████-| 99.20% [620/625 00:10<00:00 0.5594]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5608]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5645]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5645]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5645]\r",
      "\r",
      "Epoch 4/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5645]\r",
      "\r",
      "Epoch 4/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5645]\r",
      "\r",
      "Epoch 4/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5645]\r",
      "\r",
      "Epoch 4/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5645]\r",
      "\r",
      "Epoch 4/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5645]\r",
      "\r",
      "Epoch 4/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5645]\r",
      "\r",
      "Epoch 4/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5645]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "3         0.564505    0.633167    0.546800  0.184012  0.104713         0.712424       00:11     \n",
      "█\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/625 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.16% [1/625 00:00<00:15]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.32% [2/625 00:00<00:13 0.5638]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.48% [3/625 00:00<00:12 0.5690]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.64% [4/625 00:00<00:11 0.5701]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.80% [5/625 00:00<00:11 0.5725]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 2.40% [15/625 00:00<00:10 0.5790]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 4.16% [26/625 00:00<00:10 0.5894]\r",
      "\r",
      "Epoch 5/5 : |██--------------------------------------| 5.92% [37/625 00:00<00:10 0.5831]\r",
      "\r",
      "Epoch 5/5 : |███-------------------------------------| 7.68% [48/625 00:00<00:09 0.5805]\r",
      "\r",
      "Epoch 5/5 : |███-------------------------------------| 9.44% [59/625 00:00<00:09 0.5817]\r",
      "\r",
      "Epoch 5/5 : |████------------------------------------| 11.20% [70/625 00:01<00:09 0.5744]\r",
      "\r",
      "Epoch 5/5 : |█████-----------------------------------| 12.96% [81/625 00:01<00:09 0.5731]\r",
      "\r",
      "Epoch 5/5 : |█████-----------------------------------| 14.72% [92/625 00:01<00:09 0.5697]\r",
      "\r",
      "Epoch 5/5 : |██████----------------------------------| 16.48% [103/625 00:01<00:08 0.5622]\r",
      "\r",
      "Epoch 5/5 : |███████---------------------------------| 18.24% [114/625 00:01<00:08 0.5534]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 20.00% [125/625 00:02<00:08 0.5535]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 21.76% [136/625 00:02<00:08 0.5502]\r",
      "\r",
      "Epoch 5/5 : |█████████-------------------------------| 23.52% [147/625 00:02<00:08 0.5551]\r",
      "\r",
      "Epoch 5/5 : |██████████------------------------------| 25.28% [158/625 00:02<00:07 0.5493]\r",
      "\r",
      "Epoch 5/5 : |██████████------------------------------| 27.04% [169/625 00:02<00:07 0.5497]\r",
      "\r",
      "Epoch 5/5 : |███████████-----------------------------| 28.80% [180/625 00:03<00:07 0.5518]\r",
      "\r",
      "Epoch 5/5 : |████████████----------------------------| 30.56% [191/625 00:03<00:07 0.5511]\r",
      "\r",
      "Epoch 5/5 : |████████████----------------------------| 32.32% [202/625 00:03<00:07 0.5496]\r",
      "\r",
      "Epoch 5/5 : |█████████████---------------------------| 34.08% [213/625 00:03<00:06 0.5622]\r",
      "\r",
      "Epoch 5/5 : |██████████████--------------------------| 35.84% [224/625 00:03<00:06 0.5540]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 37.60% [235/625 00:03<00:06 0.5679]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 39.36% [246/625 00:04<00:06 0.5700]\r",
      "\r",
      "Epoch 5/5 : |████████████████------------------------| 41.12% [257/625 00:04<00:06 0.5661]\r",
      "\r",
      "Epoch 5/5 : |█████████████████-----------------------| 42.88% [268/625 00:04<00:05 0.5690]\r",
      "\r",
      "Epoch 5/5 : |█████████████████-----------------------| 44.64% [279/625 00:04<00:05 0.5743]\r",
      "\r",
      "Epoch 5/5 : |██████████████████----------------------| 46.40% [290/625 00:04<00:05 0.5610]\r",
      "\r",
      "Epoch 5/5 : |███████████████████---------------------| 48.16% [301/625 00:05<00:05 0.5540]\r",
      "\r",
      "Epoch 5/5 : |███████████████████---------------------| 49.92% [312/625 00:05<00:05 0.5481]\r",
      "\r",
      "Epoch 5/5 : |████████████████████--------------------| 51.68% [323/625 00:05<00:05 0.5529]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████-------------------| 53.44% [334/625 00:05<00:04 0.5527]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████------------------| 55.20% [345/625 00:05<00:04 0.5444]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████------------------| 56.96% [356/625 00:05<00:04 0.5526]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████-----------------| 58.72% [367/625 00:06<00:04 0.5557]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████----------------| 60.48% [378/625 00:06<00:04 0.5534]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████----------------| 62.24% [389/625 00:06<00:03 0.5508]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████---------------| 64.00% [400/625 00:06<00:03 0.5522]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████--------------| 65.76% [411/625 00:06<00:03 0.5475]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████-------------| 67.52% [422/625 00:07<00:03 0.5457]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████-------------| 69.28% [433/625 00:07<00:03 0.5648]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████------------| 71.04% [444/625 00:07<00:03 0.5677]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████-----------| 72.80% [455/625 00:07<00:02 0.5836]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████-----------| 74.56% [466/625 00:07<00:02 0.5765]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████----------| 76.32% [477/625 00:07<00:02 0.5763]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████---------| 78.08% [488/625 00:08<00:02 0.5828]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████---------| 79.84% [499/625 00:08<00:02 0.5836]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████--------| 81.60% [510/625 00:08<00:01 0.5814]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████-------| 83.36% [521/625 00:08<00:01 0.5760]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████------| 85.12% [532/625 00:08<00:01 0.5710]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████------| 86.88% [543/625 00:09<00:01 0.5649]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████-----| 88.64% [554/625 00:09<00:01 0.5618]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████----| 90.40% [565/625 00:09<00:01 0.5591]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████----| 92.16% [576/625 00:09<00:00 0.5657]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████████---| 93.92% [587/625 00:09<00:00 0.5520]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████████--| 95.68% [598/625 00:10<00:00 0.5493]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████████████--| 97.44% [609/625 00:10<00:00 0.5554]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████████████████████-| 99.20% [620/625 00:10<00:00 0.5698]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████████| 100.00% [625/625 00:10<00:00 0.5704]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "█\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5696]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5696]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5696]\r",
      "\r",
      "Epoch 5/5 : |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5696]\r",
      "\r",
      "Epoch 5/5 : |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5696]\r",
      "\r",
      "Epoch 5/5 : |███████████████-------------------------| 39.49% [62/157 00:00<00:00 0.5696]\r",
      "\r",
      "Epoch 5/5 : |███████████████████████-----------------| 57.96% [91/157 00:00<00:00 0.5696]\r",
      "\r",
      "Epoch 5/5 : |██████████████████████████████----------| 76.43% [120/157 00:00<00:00 0.5696]\r",
      "\r",
      "Epoch 5/5 : |█████████████████████████████████████---| 94.90% [149/157 00:01<00:00 0.5696]\r",
      "\r",
      "Epoch 5/5 : |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5696]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "4         0.569629    0.630285    0.585200  0.192368  0.110713         0.715740       00:11     \n",
      "█\r",
      "\r",
      " |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      " |----------------------------------------| 0.64% [1/157 00:00<00:01]\r",
      "\r",
      " |----------------------------------------| 1.27% [2/157 00:00<00:01 0.5696]\r",
      "\r",
      " |----------------------------------------| 1.91% [3/157 00:00<00:01 0.5696]\r",
      "\r",
      " |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5696]\r",
      "\r",
      " |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5696]\r",
      "\r",
      " |████████--------------------------------| 21.02% [33/157 00:00<00:00 0.5696]\r",
      "\r",
      " |███████████████-------------------------| 38.85% [61/157 00:00<00:00 0.5696]\r",
      "\r",
      " |██████████████████████------------------| 56.69% [89/157 00:01<00:00 0.5696]\r",
      "\r",
      " |██████████████████████████--------------| 65.61% [103/157 00:01<00:00 0.5696]\r",
      "\r",
      " |██████████████████████████████----------| 75.16% [118/157 00:01<00:00 0.5696]\r",
      "\r",
      " |██████████████████████████████████------| 85.35% [134/157 00:01<00:00 0.5696]\r",
      "\r",
      " |██████████████████████████████████████--| 96.18% [151/157 00:01<00:00 0.5696]\r",
      "\r",
      " |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5696]\r",
      "\r",
      "                                                                                \r",
      "\r",
      "                                                                                \r",
      "Precision-Recall AUC: 0.1676\n",
      "Average Precision: 0.1679\n",
      "Confusion Matrix:\n",
      "[[5358 3968]\n",
      " [ 180  494]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.57      0.72      9326\n",
      "           1       0.11      0.73      0.19       674\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.54      0.65      0.46     10000\n",
      "weighted avg       0.91      0.59      0.69     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 273,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model with the existing setup\n",
    "weights = torch.FloatTensor([1, 20])\n",
    "learn = tabular_learner(dls, metrics=[accuracy, F1Score(), Precision(), RocAucBinary()], \n",
    "                      loss_func=CrossEntropyLossFlat(weight=weights))\n",
    "learn.fit_one_cycle(5, 1e-2)\n",
    "\n",
    "# Get predictions on validation set\n",
    "preds, targets = learn.get_preds()\n",
    "probs = preds[:, 1].numpy()  # Probability of positive class\n",
    "actual = targets.numpy()\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(actual, probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "ap = average_precision_score(actual, probs)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.3f}, AP = {ap:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
    "print(f\"Average Precision: {ap:.4f}\")\n",
    "\n",
    "# Get confusion matrix at default threshold (0.5)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred = (probs >= 0.5).astype(int)\n",
    "cm = confusion_matrix(actual, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(actual, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b208445",
   "metadata": {
    "input_tokens": 40,
    "output_tokens": 877,
    "solveit_ai": true
   },
   "source": [
    "Let's try to make sense of this matrix and compare it to the one we're pulling from sklean too. Add your observation as well.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at both the precision-recall curve and the confusion matrix, I can provide a comprehensive analysis of your model's performance:\n",
    "\n",
    "### Precision-Recall Curve Analysis\n",
    "\n",
    "The PR curve shows a PR-AUC of 0.168, which is quite low. In an imbalanced classification problem like yours, PR-AUC is a more informative metric than ROC-AUC because it focuses on the positive class performance.\n",
    "\n",
    "The curve drops steeply at the beginning and then gradually declines, indicating that:\n",
    "1. The model struggles to maintain precision as recall increases\n",
    "2. There's a significant trade-off between precision and recall\n",
    "3. The model has difficulty consistently identifying the positive class\n",
    "\n",
    "### Confusion Matrix Analysis\n",
    "\n",
    "```\n",
    "Confusion Matrix:\n",
    "[[5358 3968]\n",
    " [ 180  494]]\n",
    "```\n",
    "\n",
    "Breaking this down:\n",
    "- True Negatives: 5,358 (correctly identified negative cases)\n",
    "- False Positives: 3,968 (negative cases incorrectly classified as positive)\n",
    "- False Negatives: 180 (positive cases incorrectly classified as negative)\n",
    "- True Positives: 494 (correctly identified positive cases)\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **High False Positive Rate**: The model is generating a large number of false positives (3,968), which explains the low precision (0.11).\n",
    "\n",
    "2. **Good Recall but Poor Precision**: The model achieves a reasonable recall of 0.73 for the positive class, but at the cost of extremely low precision (0.11). This means it's finding most of the positive cases but also incorrectly labeling many negative cases as positive.\n",
    "\n",
    "3. **Class Imbalance Impact**: Despite using class weights (1:20), the model still struggles with the fundamental imbalance challenge.\n",
    "\n",
    "4. **Overall Accuracy is Misleading**: The 0.59 accuracy doesn't tell the full story given the imbalance.\n",
    "\n",
    "### Comparison with Previous Metrics\n",
    "\n",
    "The scikit-learn evaluation provides a clearer picture than the fastai metrics we were looking at before. The fastai metrics showed improving F1 scores (up to ~0.19) and precision (~0.11), which align with what we're seeing in the sklearn report.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Adjust the Classification Threshold**: Instead of using the default 0.5 threshold, you could try different thresholds to better balance precision and recall.\n",
    "\n",
    "2. **Try Different Sampling Approaches**: Consider SMOTE or other advanced resampling techniques to better handle the imbalance.\n",
    "\n",
    "3. **Feature Engineering**: The high false positive rate suggests the model might benefit from more discriminative features.\n",
    "\n",
    "4. **Ensemble Methods**: Consider using ensemble methods specifically designed for imbalanced data, such as balanced random forests.\n",
    "\n",
    "5. **Different Evaluation Metric**: Focus on F1-score or PR-AUC as your primary optimization metric rather than accuracy.\n",
    "\n",
    "Would you like me to implement any of these recommendations next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2cf461",
   "metadata": {
    "input_tokens": 49,
    "output_tokens": 858,
    "solveit_ai": true
   },
   "source": [
    "let timpalement this Adjust the Classification Threshold: Instead of using the default 0.5 threshold, you could try different thresholds to better balance precision and recall.\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's implement threshold adjustment to find the optimal balance between precision and recall:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions on validation set again (if needed)\n",
    "preds, targets = learn.get_preds()\n",
    "probs = preds[:, 1].numpy()\n",
    "actual = targets.numpy()\n",
    "\n",
    "# Calculate precision, recall and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(actual, probs)\n",
    "\n",
    "# Calculate F1 score for each threshold\n",
    "f1_scores = []\n",
    "for p, r in zip(precision[:-1], recall[:-1]):  # Last element has no threshold\n",
    "    f1 = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Find threshold with best F1 score\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "best_precision = precision[best_idx]\n",
    "best_recall = recall[best_idx]\n",
    "\n",
    "# Plot precision, recall, and F1 score vs threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precision[:-1], 'b-', label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], 'g-', label='Recall')\n",
    "plt.plot(thresholds, f1_scores, 'r-', label='F1 Score')\n",
    "plt.axvline(x=best_threshold, color='k', linestyle='--', \n",
    "           label=f'Best Threshold = {best_threshold:.3f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall, and F1 Score vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Apply the best threshold and calculate new confusion matrix\n",
    "y_pred_best = (probs >= best_threshold).astype(int)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm_best = confusion_matrix(actual, y_pred_best)\n",
    "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Precision at best threshold: {best_precision:.4f}\")\n",
    "print(f\"Recall at best threshold: {best_recall:.4f}\")\n",
    "print(\"\\nConfusion Matrix with Best Threshold:\")\n",
    "print(cm_best)\n",
    "print(\"\\nClassification Report with Best Threshold:\")\n",
    "print(classification_report(actual, y_pred_best))\n",
    "```\n",
    "\n",
    "This code will:\n",
    "1. Calculate precision, recall, and F1 scores across different thresholds\n",
    "2. Find the threshold that maximizes the F1 score\n",
    "3. Plot how precision, recall, and F1 score change with different thresholds\n",
    "4. Apply the optimal threshold and show the new confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab932bdf",
   "metadata": {
    "input_tokens": 733,
    "output_tokens": 1005,
    "time_run": "9:52:56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r",
      "\r",
      " |----------------------------------------| 0.00% [0/157 00:00<?]\r",
      "\r",
      " |----------------------------------------| 0.64% [1/157 00:00<00:03]\r",
      "\r",
      " |----------------------------------------| 1.27% [2/157 00:00<00:02 0.5696]\r",
      "\r",
      " |----------------------------------------| 1.91% [3/157 00:00<00:02 0.5696]\r",
      "\r",
      " |█---------------------------------------| 2.55% [4/157 00:00<00:01 0.5696]\r",
      "\r",
      " |█---------------------------------------| 3.18% [5/157 00:00<00:01 0.5696]\r",
      "\r",
      " |█████-----------------------------------| 13.38% [21/157 00:00<00:01 0.5696]\r",
      "\r",
      " |██████████------------------------------| 26.75% [42/157 00:00<00:01 0.5696]\r",
      "\r",
      " |████████████████------------------------| 40.76% [64/157 00:00<00:00 0.5696]\r",
      "\r",
      " |██████████████████████------------------| 55.41% [87/157 00:00<00:00 0.5696]\r",
      "\r",
      " |████████████████████████████------------| 70.70% [111/157 00:00<00:00 0.5696]\r",
      "\r",
      " |██████████████████████████████████------| 86.62% [136/157 00:01<00:00 0.5696]\r",
      "\r",
      " |████████████████████████████████████████| 100.00% [157/157 00:01<00:00 0.5696]\r",
      "\r",
      "                                                                                \r",
      "\r",
      "                                                                                \r",
      "Best Threshold: 0.7207\n",
      "Best F1 Score: 0.2433\n",
      "Precision at best threshold: 0.1878\n",
      "Recall at best threshold: 0.3457\n",
      "\n",
      "Confusion Matrix with Best Threshold:\n",
      "[[8318 1008]\n",
      " [ 441  233]]\n",
      "\n",
      "Classification Report with Best Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      9326\n",
      "           1       0.19      0.35      0.24       674\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.57      0.62      0.58     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 273,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions on validation set again (if needed)\n",
    "preds, targets = learn.get_preds()\n",
    "probs = preds[:, 1].numpy()\n",
    "actual = targets.numpy()\n",
    "\n",
    "# Calculate precision, recall and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(actual, probs)\n",
    "\n",
    "# Calculate F1 score for each threshold\n",
    "f1_scores = []\n",
    "for p, r in zip(precision[:-1], recall[:-1]):  # Last element has no threshold\n",
    "    f1 = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Find threshold with best F1 score\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "best_precision = precision[best_idx]\n",
    "best_recall = recall[best_idx]\n",
    "\n",
    "# Plot precision, recall, and F1 score vs threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precision[:-1], 'b-', label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], 'g-', label='Recall')\n",
    "plt.plot(thresholds, f1_scores, 'r-', label='F1 Score')\n",
    "plt.axvline(x=best_threshold, color='k', linestyle='--', \n",
    "           label=f'Best Threshold = {best_threshold:.3f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall, and F1 Score vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Apply the best threshold and calculate new confusion matrix\n",
    "y_pred_best = (probs >= best_threshold).astype(int)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm_best = confusion_matrix(actual, y_pred_best)\n",
    "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Precision at best threshold: {best_precision:.4f}\")\n",
    "print(f\"Recall at best threshold: {best_recall:.4f}\")\n",
    "print(\"\\nConfusion Matrix with Best Threshold:\")\n",
    "print(cm_best)\n",
    "print(\"\\nClassification Report with Best Threshold:\")\n",
    "print(classification_report(actual, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d752c",
   "metadata": {
    "input_tokens": 16,
    "output_tokens": 910,
    "solveit_ai": true
   },
   "source": [
    "Can you analyze the matrix and give me your observations?\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the threshold optimization results and the new confusion matrix, I can provide the following analysis:\n",
    "\n",
    "### Threshold Optimization Analysis\n",
    "\n",
    "The plot shows how precision, recall, and F1 score vary with different thresholds. The optimal threshold was found to be 0.721, which maximizes the F1 score at 0.243.\n",
    "\n",
    "### Confusion Matrix Comparison\n",
    "\n",
    "**Original Confusion Matrix (0.5 threshold):**\n",
    "```\n",
    "[[5358 3968]\n",
    " [ 180  494]]\n",
    "```\n",
    "\n",
    "**New Confusion Matrix (0.721 threshold):**\n",
    "```\n",
    "[[8318 1008]\n",
    " [ 441  233]]\n",
    "```\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **Significantly Reduced False Positives**: False positives decreased dramatically from 3,968 to 1,008. This is a 75% reduction, which means much fewer negative cases are being incorrectly classified as positive.\n",
    "\n",
    "2. **Higher Precision**: Precision improved from 0.11 to 0.19 (about 73% improvement). This means that when the model predicts the positive class, it's more likely to be correct.\n",
    "\n",
    "3. **Lower Recall**: Recall decreased from 0.73 to 0.35 (a 52% reduction). The model is now detecting fewer of the actual positive cases.\n",
    "\n",
    "4. **Better Overall Accuracy**: Accuracy improved from 0.59 to 0.86, which is a substantial improvement.\n",
    "\n",
    "5. **F1 Score Improvement**: The F1 score improved from 0.19 to 0.24, which represents a better balance between precision and recall.\n",
    "\n",
    "6. **Better Class Balance Handling**: The model is now more conservative in predicting the positive class, which is appropriate given the high imbalance.\n",
    "\n",
    "### Business Implications\n",
    "\n",
    "1. **Trade-off Analysis**: By increasing the threshold, we've made a conscious decision to trade recall for precision. This makes sense in scenarios where false positives are more costly than false negatives.\n",
    "\n",
    "2. **Higher Confidence Predictions**: The higher threshold means we're only predicting the positive class when the model is more confident, which could be valuable in decision-making contexts.\n",
    "\n",
    "3. **Improved Resource Allocation**: With fewer false positives, resources can be allocated more efficiently to investigate true positive cases.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Consider the Business Context**: The optimal threshold depends on the specific business cost of false positives versus false negatives. If missing positive cases is very costly, you might want a lower threshold.\n",
    "\n",
    "2. **Explore Other Thresholds**: Different points on the precision-recall curve might be more appropriate depending on your specific needs.\n",
    "\n",
    "3. **Combine with Other Approaches**: While threshold optimization helps, combining it with better sampling techniques or model architectures could yield further improvements.\n",
    "\n",
    "4. **Feature Engineering**: The model still struggles with distinguishing between classes, suggesting that better features might help.\n",
    "\n",
    "Would you like to try another approach to further improve the model, such as implementing a sampling technique like SMOTE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf8eb6",
   "metadata": {
    "input_tokens": 79,
    "output_tokens": 463,
    "solveit_ai": true
   },
   "source": [
    "Given the experiments we've run, and the task expectations outlined earlier, can you summarize our progress with simple, non-technical commentary? I don't need a full doc format yet, just concise and straightforward observations that make sense in light of what we've done. Avoid jargon.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "## Progress Summary\n",
    "\n",
    "We started with a model that was highly imbalanced - it was good at predicting the majority class but terrible at identifying the minority class. This is like having a security system that's great at letting authorized people in but also lets in many unauthorized people.\n",
    "\n",
    "Here's what we've learned:\n",
    "\n",
    "1. Our initial model was misleading - it showed high accuracy (93%) but was actually performing poorly at finding the important minority cases.\n",
    "\n",
    "2. We tried two main approaches to fix this:\n",
    "   - Giving more weight to the minority class during training\n",
    "   - Finding a better decision threshold instead of using the default 0.5\n",
    "\n",
    "3. The results improved significantly:\n",
    "   - We can now correctly identify 89% of the majority class\n",
    "   - We can identify 35% of the minority class (up from basically none)\n",
    "   - False alarms dropped dramatically - we're much less likely to misclassify majority cases\n",
    "\n",
    "4. The trade-off we made:\n",
    "   - We're more selective about what we call a \"positive\" case\n",
    "   - This means we miss more positive cases but have fewer false alarms\n",
    "   - In many real-world situations, this is preferable - quality over quantity\n",
    "\n",
    "5. Next steps could include:\n",
    "   - Better data balancing techniques\n",
    "   - Exploring different models\n",
    "   - Adding more informative features\n",
    "\n",
    "Overall, we've turned a misleading model into one that's much more useful and trustworthy, even though there's still room for improvement. The key insight was that a high accuracy number can hide poor performance on the cases we care most about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba0a804",
   "metadata": {
    "input_tokens": 463
   },
   "source": [
    "## Progress Summary\n",
    "\n",
    "We started with a model that was highly imbalanced - it was good at predicting the majority class but terrible at identifying the minority class. This is like having a security system that's great at letting authorized people in but also lets in many unauthorized people.\n",
    "\n",
    "Here's what we've learned:\n",
    "\n",
    "1. Our initial model was misleading - it showed high accuracy (93%) but was actually performing poorly at finding the important minority cases.\n",
    "\n",
    "2. We tried two main approaches to fix this:\n",
    "   - Giving more weight to the minority class during training\n",
    "   - Finding a better decision threshold instead of using the default 0.5\n",
    "\n",
    "3. The results improved significantly:\n",
    "   - We can now correctly identify 89% of the majority class\n",
    "   - We can identify 35% of the minority class (up from basically none)\n",
    "   - False alarms dropped dramatically - we're much less likely to misclassify majority cases\n",
    "\n",
    "4. The trade-off we made:\n",
    "   - We're more selective about what we call a \"positive\" case\n",
    "   - This means we miss more positive cases but have fewer false alarms\n",
    "   - In many real-world situations, this is preferable - quality over quantity\n",
    "\n",
    "5. Next steps could include:\n",
    "   - Better data balancing techniques\n",
    "   - Exploring different models\n",
    "   - Adding more informative features\n",
    "\n",
    "Overall, we've turned a misleading model into one that's much more useful and trustworthy, even though there's still room for improvement. The key insight was that a high accuracy number can hide poor performance on the cases we care most about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f482a",
   "metadata": {
    "input_tokens": 42,
    "output_tokens": 564,
    "solveit_ai": true
   },
   "source": [
    "Can you add some commentary on the metrics we've used? Keep it simple, no jargon, and be precise. Back it up with data.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "## Metrics Commentary\n",
    "\n",
    "When evaluating our model, we used several different measurements. Here's what they told us:\n",
    "\n",
    "**Accuracy (86%)**: This tells us the overall percentage of correct predictions. While it improved from 59% to 86%, this number alone doesn't tell the full story with imbalanced data.\n",
    "\n",
    "**Precision (19%)**: This measures \"when we predict something is positive, how often are we right?\" Initially, only 11% of our positive predictions were correct. We improved this to 19%, meaning fewer false alarms.\n",
    "\n",
    "**Recall (35%)**: This shows \"what percentage of actual positive cases do we catch?\" Our original model caught 73% but with many false alarms. Our improved model catches 35% but with much higher confidence.\n",
    "\n",
    "**F1 Score (24%)**: This combines precision and recall into one number. It improved from 19% to 24%, showing better overall performance despite the recall trade-off.\n",
    "\n",
    "**Confusion Matrix Data**:\n",
    "- False positives dropped from 3,968 to 1,008 (75% reduction)\n",
    "- True negatives increased from 5,358 to 8,318 (55% increase)\n",
    "- True positives decreased from 494 to 233 (53% decrease)\n",
    "- False negatives increased from 180 to 441 (145% increase)\n",
    "\n",
    "These numbers confirm our trade-off: we're missing more positive cases but drastically reducing false alarms.\n",
    "\n",
    "**Threshold (0.72)**: By raising our decision threshold from 0.5 to 0.72, we're only calling something \"positive\" when the model is more confident. This is like raising the bar for evidence before making an important decision.\n",
    "\n",
    "The key takeaway: Different metrics tell different parts of the story. By looking at all of them together, we get a complete picture of how our model actually performs in real-world conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b978510",
   "metadata": {
    "input_tokens": 564,
    "time_run": "10:02:58a"
   },
   "source": [
    "## Metrics Commentary\n",
    "\n",
    "When evaluating our model, we used several different measurements. Here's what they told us:\n",
    "\n",
    "**Accuracy (86%)**: This tells us the overall percentage of correct predictions. While it improved from 59% to 86%, this number alone doesn't tell the full story with imbalanced data.\n",
    "\n",
    "**Precision (19%)**: This measures \"when we predict something is positive, how often are we right?\" Initially, only 11% of our positive predictions were correct. We improved this to 19%, meaning fewer false alarms.\n",
    "\n",
    "**Recall (35%)**: This shows \"what percentage of actual positive cases do we catch?\" Our original model caught 73% but with many false alarms. Our improved model catches 35% but with much higher confidence.\n",
    "\n",
    "**F1 Score (24%)**: This combines precision and recall into one number. It improved from 19% to 24%, showing better overall performance despite the recall trade-off.\n",
    "\n",
    "**Confusion Matrix Data**:\n",
    "- False positives dropped from 3,968 to 1,008 (75% reduction)\n",
    "- True negatives increased from 5,358 to 8,318 (55% increase)\n",
    "- True positives decreased from 494 to 233 (53% decrease)\n",
    "- False negatives increased from 180 to 441 (145% increase)\n",
    "\n",
    "These numbers confirm our trade-off: we're missing more positive cases but drastically reducing false alarms.\n",
    "\n",
    "**Threshold (0.72)**: By raising our decision threshold from 0.5 to 0.72, we're only calling something \"positive\" when the model is more confident. This is like raising the bar for evidence before making an important decision.\n",
    "\n",
    "The key takeaway: Different metrics tell different parts of the story. By looking at all of them together, we get a complete picture of how our model actually performs in real-world conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8353da",
   "metadata": {
    "input_tokens": 276,
    "output_tokens": 939,
    "solveit_ai": true
   },
   "source": [
    "Based on the Task & Expectations outlined, ptoved  the following comments provides a clear, data-driven assessment, addressing each question without overstating the conclusions.\n",
    "\n",
    "\n",
    "Task & Expectations:\n",
    "```\n",
    "Attached is a training dataset and corresponding label file for a classification problem.\n",
    "Your task is to propose a solution approach, documenting the steps, ideas, observations, data\n",
    "analysis, and feature engineering (if any). There’s no need to code the solution, but feel free to\n",
    "provide as much detail as you'd like.\n",
    "Please include the success criteria and performance metrics you would use for model\n",
    "evaluation, along with the reasoning behind your choices. All decisions should be supported by\n",
    "data observations or sound reasoning.\n",
    "We will assess the quality of your response based on the submitted document (Word or\n",
    "PowerPoint). Feel free to share other support documents like notebooks, excels etc. which can\n",
    "give us more confidence around the work done.\n",
    "```\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "# Classification Problem Solution Approach\n",
    "\n",
    "## 1. Data Understanding and Analysis\n",
    "\n",
    "Based on our exploratory analysis, we observed a significant class imbalance in the dataset, with approximately 93% majority class and 7% minority class samples. This imbalance presented our primary challenge, as standard modeling approaches tend to favor the majority class.\n",
    "\n",
    "Key observations:\n",
    "- The dataset contains a mix of categorical and numerical features\n",
    "- Several features contained missing values denoted as \"#na#\"\n",
    "- Features showed varying distributions across the target classes\n",
    "\n",
    "## 2. Solution Approach\n",
    "\n",
    "Our approach followed these steps:\n",
    "\n",
    "1. **Data Preprocessing**\n",
    "   - Handled missing values by creating indicator variables\n",
    "   - Encoded categorical variables appropriately\n",
    "   - Normalized numerical features to ensure consistent scale\n",
    "\n",
    "2. **Model Development**\n",
    "   - Used a tabular model with appropriate class weights to address imbalance\n",
    "   - Trained for multiple epochs to allow the model to learn complex patterns\n",
    "   - Experimented with different class weights to find optimal balance\n",
    "\n",
    "3. **Threshold Optimization**\n",
    "   - Identified that the default classification threshold (0.5) was suboptimal\n",
    "   - Used precision-recall analysis to determine the optimal threshold (0.72)\n",
    "   - Applied this threshold to maximize F1 score\n",
    "\n",
    "## 3. Performance Metrics and Evaluation\n",
    "\n",
    "We selected metrics specifically suited for imbalanced classification:\n",
    "\n",
    "**Primary Metrics:**\n",
    "- **F1 Score**: Improved from 0.19 to 0.24 with threshold optimization\n",
    "- **Precision**: Increased from 0.11 to 0.19, reducing false positives by 75%\n",
    "- **Recall**: Adjusted from 0.73 to 0.35, focusing on higher confidence predictions\n",
    "\n",
    "**Supporting Metrics:**\n",
    "- **Confusion Matrix**: Provided detailed breakdown of prediction types\n",
    "- **Precision-Recall Curve**: Helped identify optimal operating point (threshold)\n",
    "- **ROC-AUC**: Remained around 0.71, indicating reasonable discriminative ability\n",
    "\n",
    "## 4. Results and Trade-offs\n",
    "\n",
    "Our solution demonstrates a clear trade-off between precision and recall:\n",
    "- Initial model: High recall (0.73) but very low precision (0.11)\n",
    "- Optimized model: Moderate recall (0.35) with improved precision (0.19)\n",
    "\n",
    "This trade-off represents a business decision: we've chosen to reduce false alarms at the cost of missing some positive cases.\n",
    "\n",
    "## 5. Recommendations for Further Improvement\n",
    "\n",
    "Based on our findings, we recommend:\n",
    "\n",
    "1. **Advanced Sampling Techniques**: Implement SMOTE or similar approaches to create more balanced training data\n",
    "2. **Feature Engineering**: Develop more discriminative features based on domain knowledge\n",
    "3. **Model Exploration**: Test different model architectures beyond the current approach\n",
    "4. **Ensemble Methods**: Combine multiple models to improve overall performance\n",
    "5. **Cost-sensitive Learning**: Adjust the model based on the specific business costs of false positives vs. false negatives\n",
    "\n",
    "The success of this approach ultimately depends on the specific business context and the relative importance of precision versus recall in the application domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef46a0e",
   "metadata": {
    "input_tokens": 39,
    "output_tokens": 1015,
    "solveit_ai": true
   },
   "source": [
    "whats is Precision-Recall Curve help me understand it intuitively with simple example first and the explain the above metric score too...\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "# Understanding Precision-Recall Curves\n",
    "\n",
    "## Simple Intuitive Example\n",
    "\n",
    "Imagine you're a doctor screening patients for a rare disease:\n",
    "\n",
    "- **Precision** is: \"When I tell someone they have the disease, how often am I right?\"\n",
    "- **Recall** is: \"Out of all the people who actually have the disease, how many did I correctly identify?\"\n",
    "\n",
    "Let's say you have 100 patients:\n",
    "- 10 actually have the disease\n",
    "- 90 are healthy\n",
    "\n",
    "### Scenario 1: Very Strict Test (High Threshold)\n",
    "You only diagnose someone if you're very confident.\n",
    "- You identify 3 people as having the disease, and all 3 actually have it\n",
    "- You miss 7 people who have the disease\n",
    "- **Precision**: 3/3 = 100% (all your positive diagnoses were correct)\n",
    "- **Recall**: 3/10 = 30% (you only found 30% of the disease cases)\n",
    "\n",
    "### Scenario 2: Very Lenient Test (Low Threshold)\n",
    "You diagnose someone even with minimal suspicion.\n",
    "- You identify 20 people as having the disease\n",
    "- 8 of them actually have the disease, 12 are false alarms\n",
    "- **Precision**: 8/20 = 40% (only 40% of your positive diagnoses were correct)\n",
    "- **Recall**: 8/10 = 80% (you found 80% of the disease cases)\n",
    "\n",
    "## What is a Precision-Recall Curve?\n",
    "\n",
    "A precision-recall curve shows how precision and recall change as you adjust your threshold (how confident you need to be to make a positive prediction).\n",
    "\n",
    "- **Left side of curve**: High precision, low recall (strict threshold - few false positives but miss many positives)\n",
    "- **Right side of curve**: Low precision, high recall (lenient threshold - catch most positives but many false alarms)\n",
    "\n",
    "## Explaining Our Metrics\n",
    "\n",
    "In our case:\n",
    "\n",
    "- **PR-AUC (0.168)**: This is the area under the precision-recall curve. A perfect model would have a score of 1.0. Our score of 0.168 is relatively low, indicating the model struggles to balance precision and recall effectively.\n",
    "\n",
    "- **Best Threshold (0.72)**: We found that using a threshold of 0.72 (rather than the default 0.5) gives us the best F1 score. This is like saying \"only diagnose the disease if you're 72% confident\" instead of \"diagnose if you're 50% confident.\"\n",
    "\n",
    "- **Precision (0.19)**: When our model predicts the positive class, it's right about 19% of the time. This means about 81% of our positive predictions are false alarms.\n",
    "\n",
    "- **Recall (0.35)**: Our model identifies about 35% of the actual positive cases. This means we're missing about 65% of the positive cases.\n",
    "\n",
    "- **F1 Score (0.24)**: This is the harmonic mean of precision and recall. It gives us a single number that balances both concerns.\n",
    "\n",
    "The key insight is that we've chosen a threshold that gives us fewer false alarms (improved precision) at the cost of missing more positive cases (reduced recall). This is often a reasonable trade-off in many real-world scenarios, especially when false positives are costly or resource-intensive to investigate."
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
