{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accac63",
   "metadata": {
    "input_tokens": 9
   },
   "outputs": [],
   "source": [
    "import contextkit.read as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886426f",
   "metadata": {
    "input_tokens": 33
   },
   "outputs": [],
   "source": [
    "pdf= rd.read_pdf('FU-Technical Assessment - Applied Data Scientist-250425-033739.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e51f7e",
   "metadata": {
    "collapsed": true,
    "input_tokens": 1,
    "output_tokens": 1540
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technical Assessment - Applied Data Scientist\\nData Science Take-Home Challenge: Credit Risk Challenger Model Development\\nIntroduction\\nThank you for your interest in our data science position. This take-home challenge is designed to assess your abilities in developing and  \\nvalidating credit risk models, specifically focusing on probability of default (PD) prediction. The challenge simulates a real-world scenario  \\nwhere an existing model (Champion) needs improvement through the development of a new model (Challenger).\\nIn the financial industry , having robust and accurate credit risk models is critical for making sound lending decisions and meeting  \\nregulatory requirements. Your task is to build a challenger model that outperforms our current champion model in predicting the probability  \\nof default for a loan portfolio.\\nContext \\nImagine a lender called AssetEase, a specialist in providing personal loans tailored for individuals looking to purchase significant assets  \\nsuch as cars, boats, motorcycles, and other registrable vehicles. AssetEase of fers flexible finance solutions, allowing borrowers to secure  \\nfunding for both new and used assets, with options to suit a range of credit profiles and financial circumstances.\\nDatasets\\nThe attached zip file contains the training dataset and the test dataset for the exercise. \\nDataset Description\\nWe will provide you with the following datasets:\\n1. Training Dataset : Historical loan data containing borrower information, loan characteristics, and default indicators (target variable).  \\nThis dataset spans multiple origination vintages.\\nFeatures will include demographic information, credit history metrics, loan characteristics, and macroeconomic indicators\\nDefault indicator (0 = non-default, 1 = default) will be provided as the target variable\\nDefault means 90+ DPD in 18 months \\nOrigination date will be included to help with vintage analysis\\n2. Test Dataset : The final evaluation dataset on which your model and the champion model will be compared. The default indicators will  \\nbe withheld, and you will need to submit predictions for this dataset.\\n3. Champion Model Predictions : Probability of default predictions from our existing champion model on both the validation and test  \\ndatasets.\\nassessment_datas\\n23 Apr 2025, 05:13 AMets.zip 4. Score scaling : Incumbents models predictions are then scaled to scores using the below scaling factor - \\nThe PD for the log odds are taken from the PD model. Scoring parameter implies that a score of 200 is equal to log odds of 50%, i.e 1  \\nin 2 chance of default, and this probability halves every 100 points as per the table:\\n \\n \\nChallenge Requirements\\nYour task consists of the following components:\\n1. Data Exploration and Preprocessing :\\nAnalyze the provided data to understand the distribution of features and target variable\\nHandle missing values, outliers, and feature engineering as appropriate\\nDocument your data preprocessing approach with clear justification\\n2. Challenger Model Development :\\nDevelop a model that predicts the probability of default\\nYour approach should aim to outperform the champion model on the Gini coef ficient metric\\nYou have freedom to choose any modeling technique (statistical, machine learning, ensemble, etc.)\\nDocument your methodology , feature selection, and hyperparameter tuning process\\n3. Model V alidation :\\nImplement comprehensive validation tests focusing on:0 0.25:1\\n100 0.5:1\\n200 1:1\\n300 2:1\\n400 4:1\\n500 8:1\\n600 16:1\\n700 32:1\\n800 64:1\\n900 128:1\\n1000 256:1\\n1100 512:1\\n1200 1024:1\\n1300 2048:1\\n1400 4096:1Calibrated Score G: B Odds\\n Discrimination : Calculate and visualise Gini coef ficient, ROC curve, AUC, and other relevant discrimination metrics\\nCalibration : Assess how well predicted probabilities align with observed default rates (\\nStability : Evaluate model performance across dif ferent vintages to ensure consistent performance over time\\n4. Model Comparison :\\nCompare your challenger model to the champion model on all validation metrics\\nClearly identify the reduction in ODR, keeping the Approval Rate as constant\\nClearly demonstrate where and why your model outperforms the champion\\n \\nSubmission File\\nFor each APP_ID  in the test set, you must predict a probability for the TARGET  variable. The file should contain a header and have the  \\nfollowing format:\\n \\nPresentation\\n45 minutes presentation of the insights and resultsand then 15-minute Q&A\\n1APP_ID,TARGET, SCORES\\n2100001,0.1,450\\n3100005,0.9,950\\n4100013,0.2,1050\\n5etc.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd71cff",
   "metadata": {
    "input_tokens": 6
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48b092",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 130
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note to solveit: Hi, I am Gaurav, and I am working with you today! When writing code for me, please follow fast.ai coding style: avoid comments; place single line if/loop/etc constructs on the same line; use concise variable names where appropriate. Follow the style you will see in my messages. As we work on this dialogue together.\n"
     ]
    }
   ],
   "source": [
    "intro()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43bd206",
   "metadata": {
    "input_tokens": 120
   },
   "source": [
    "Note to solveit: Hi, I am Gaurav, and I am working with you today! to solve this assessment  When writing code for me, please follow fast.ai coding style: avoid comments; place single line if/loop/etc constructs on the same line; use concise variable names where appropriate. Follow the style you will see in my messages. As we work on this dialogue together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af26050",
   "metadata": {
    "collapsed": true,
    "input_tokens": 52,
    "output_tokens": 714,
    "solveit_ai": true
   },
   "source": [
    "Now, can you walk me through assessment modeling Assessment Modeling Dataset.csv ? I want to understand what we're looking at and how we can use this dataset to challenge the champion model.\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the Assessment Modeling Dataset, I can see it contains loan application data with various features and a target variable. Let's break it down:\n",
    "\n",
    "The dataset contains information about loan applicants including:\n",
    "\n",
    "1. **Borrower Information**:\n",
    "   - `APP_ID`: Unique identifier for each application\n",
    "   - `emp_title`: Employer name\n",
    "   - `emp_length`: Years at current employer\n",
    "   - `home_ownership`: Housing status (RENT, MORTGAGE, etc.)\n",
    "   - `annual_inc`: Annual income\n",
    "   - `addr_state`: State of residence\n",
    "   - `zip_code`: ZIP code (partially masked)\n",
    "\n",
    "2. **Loan Details**:\n",
    "   - `purpose_cat` and `purpose`: Categorized and specific loan purpose\n",
    "   - `Notes`: Text description provided by borrower\n",
    "   - `verification_status`: Whether income was verified\n",
    "   - `pymnt_plan`: Payment plan indicator\n",
    "\n",
    "3. **Credit History**:\n",
    "   - `debt_to_income`: Debt-to-income ratio\n",
    "   - `delinq_2yrs`: Number of delinquencies in past 2 years\n",
    "   - `earliest_cr_line`: Date of earliest credit line\n",
    "   - `inq_last_6mths`: Number of inquiries in last 6 months\n",
    "   - `open_acc`: Number of open credit accounts\n",
    "   - `revol_bal`: Revolving balance\n",
    "   - `revol_util`: Revolving line utilization rate\n",
    "   - Various other credit metrics\n",
    "\n",
    "4. **Target Variable**:\n",
    "   - `TARGET`: Binary indicator (0 = no default, 1 = default)\n",
    "\n",
    "This dataset will be used to:\n",
    "1. Train your challenger model to predict the probability of default\n",
    "2. Identify patterns and relationships between features and default outcomes\n",
    "3. Create feature engineering strategies to improve prediction accuracy\n",
    "4. Validate your model's performance before testing on the holdout set\n",
    "\n",
    "To challenge the champion model effectively, you'll need to:\n",
    "- Perform thorough exploratory data analysis to understand feature distributions\n",
    "- Handle missing values (I can see some `nan` values in the data)\n",
    "- Engineer new features that might better predict defaults\n",
    "- Select appropriate algorithms and tune hyperparameters\n",
    "- Validate using the Gini coefficient and other metrics mentioned in the assessment\n",
    "\n",
    "Would you like me to help you start with some exploratory data analysis on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327611c",
   "metadata": {
    "input_tokens": 16
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Assessment Modeling Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801c0b3",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 3333
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2f953 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2f953 td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_2f953 tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_2f953 tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2f953\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2f953_level0_col0\" class=\"col_heading level0 col0\" >emp_title</th>\n",
       "      <th id=\"T_2f953_level0_col1\" class=\"col_heading level0 col1\" >emp_length</th>\n",
       "      <th id=\"T_2f953_level0_col2\" class=\"col_heading level0 col2\" >home_ownership</th>\n",
       "      <th id=\"T_2f953_level0_col3\" class=\"col_heading level0 col3\" >verification_status</th>\n",
       "      <th id=\"T_2f953_level0_col4\" class=\"col_heading level0 col4\" >pymnt_plan</th>\n",
       "      <th id=\"T_2f953_level0_col5\" class=\"col_heading level0 col5\" >Notes</th>\n",
       "      <th id=\"T_2f953_level0_col6\" class=\"col_heading level0 col6\" >purpose_cat</th>\n",
       "      <th id=\"T_2f953_level0_col7\" class=\"col_heading level0 col7\" >purpose</th>\n",
       "      <th id=\"T_2f953_level0_col8\" class=\"col_heading level0 col8\" >zip_code</th>\n",
       "      <th id=\"T_2f953_level0_col9\" class=\"col_heading level0 col9\" >addr_state</th>\n",
       "      <th id=\"T_2f953_level0_col10\" class=\"col_heading level0 col10\" >earliest_cr_line</th>\n",
       "      <th id=\"T_2f953_level0_col11\" class=\"col_heading level0 col11\" >initial_list_status</th>\n",
       "      <th id=\"T_2f953_level0_col12\" class=\"col_heading level0 col12\" >policy_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2f953_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_2f953_row0_col0\" class=\"data row0 col0\" >7535</td>\n",
       "      <td id=\"T_2f953_row0_col1\" class=\"data row0 col1\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col2\" class=\"data row0 col2\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col3\" class=\"data row0 col3\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col4\" class=\"data row0 col4\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col5\" class=\"data row0 col5\" >5468</td>\n",
       "      <td id=\"T_2f953_row0_col6\" class=\"data row0 col6\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col7\" class=\"data row0 col7\" >7996</td>\n",
       "      <td id=\"T_2f953_row0_col8\" class=\"data row0 col8\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col9\" class=\"data row0 col9\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col10\" class=\"data row0 col10\" >7995</td>\n",
       "      <td id=\"T_2f953_row0_col11\" class=\"data row0 col11\" >8000</td>\n",
       "      <td id=\"T_2f953_row0_col12\" class=\"data row0 col12\" >8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f953_level0_row1\" class=\"row_heading level0 row1\" >unique</th>\n",
       "      <td id=\"T_2f953_row1_col0\" class=\"data row1 col0\" >6688</td>\n",
       "      <td id=\"T_2f953_row1_col1\" class=\"data row1 col1\" >14</td>\n",
       "      <td id=\"T_2f953_row1_col2\" class=\"data row1 col2\" >5</td>\n",
       "      <td id=\"T_2f953_row1_col3\" class=\"data row1 col3\" >3</td>\n",
       "      <td id=\"T_2f953_row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "      <td id=\"T_2f953_row1_col5\" class=\"data row1 col5\" >5410</td>\n",
       "      <td id=\"T_2f953_row1_col6\" class=\"data row1 col6\" >27</td>\n",
       "      <td id=\"T_2f953_row1_col7\" class=\"data row1 col7\" >4678</td>\n",
       "      <td id=\"T_2f953_row1_col8\" class=\"data row1 col8\" >688</td>\n",
       "      <td id=\"T_2f953_row1_col9\" class=\"data row1 col9\" >49</td>\n",
       "      <td id=\"T_2f953_row1_col10\" class=\"data row1 col10\" >447</td>\n",
       "      <td id=\"T_2f953_row1_col11\" class=\"data row1 col11\" >2</td>\n",
       "      <td id=\"T_2f953_row1_col12\" class=\"data row1 col12\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f953_level0_row2\" class=\"row_heading level0 row2\" >top</th>\n",
       "      <td id=\"T_2f953_row2_col0\" class=\"data row2 col0\" >US Army</td>\n",
       "      <td id=\"T_2f953_row2_col1\" class=\"data row2 col1\" >10</td>\n",
       "      <td id=\"T_2f953_row2_col2\" class=\"data row2 col2\" >RENT</td>\n",
       "      <td id=\"T_2f953_row2_col3\" class=\"data row2 col3\" >not verified</td>\n",
       "      <td id=\"T_2f953_row2_col4\" class=\"data row2 col4\" >n</td>\n",
       "      <td id=\"T_2f953_row2_col5\" class=\"data row2 col5\" > </td>\n",
       "      <td id=\"T_2f953_row2_col6\" class=\"data row2 col6\" >debt consolidation</td>\n",
       "      <td id=\"T_2f953_row2_col7\" class=\"data row2 col7\" >Debt Consolidation</td>\n",
       "      <td id=\"T_2f953_row2_col8\" class=\"data row2 col8\" >100xx</td>\n",
       "      <td id=\"T_2f953_row2_col9\" class=\"data row2 col9\" >CA</td>\n",
       "      <td id=\"T_2f953_row2_col10\" class=\"data row2 col10\" >11/1/1998</td>\n",
       "      <td id=\"T_2f953_row2_col11\" class=\"data row2 col11\" >f</td>\n",
       "      <td id=\"T_2f953_row2_col12\" class=\"data row2 col12\" >PC3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f953_level0_row3\" class=\"row_heading level0 row3\" >freq</th>\n",
       "      <td id=\"T_2f953_row3_col0\" class=\"data row3 col0\" >29</td>\n",
       "      <td id=\"T_2f953_row3_col1\" class=\"data row3 col1\" >1717</td>\n",
       "      <td id=\"T_2f953_row3_col2\" class=\"data row3 col2\" >3826</td>\n",
       "      <td id=\"T_2f953_row3_col3\" class=\"data row3 col3\" >3492</td>\n",
       "      <td id=\"T_2f953_row3_col4\" class=\"data row3 col4\" >7998</td>\n",
       "      <td id=\"T_2f953_row3_col5\" class=\"data row3 col5\" >55</td>\n",
       "      <td id=\"T_2f953_row3_col6\" class=\"data row3 col6\" >3546</td>\n",
       "      <td id=\"T_2f953_row3_col7\" class=\"data row3 col7\" >421</td>\n",
       "      <td id=\"T_2f953_row3_col8\" class=\"data row3 col8\" >127</td>\n",
       "      <td id=\"T_2f953_row3_col9\" class=\"data row3 col9\" >1396</td>\n",
       "      <td id=\"T_2f953_row3_col10\" class=\"data row3 col10\" >81</td>\n",
       "      <td id=\"T_2f953_row3_col11\" class=\"data row3 col11\" >7985</td>\n",
       "      <td id=\"T_2f953_row3_col12\" class=\"data row3 col12\" >1666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "       emp_title emp_length  ... initial_list_status policy_code\n",
       "count       7535       8000  ...                8000        8000\n",
       "unique      6688         14  ...                   2           5\n",
       "top      US Army         10  ...                   f         PC3\n",
       "freq          29       1717  ...                7985        1666\n",
       "\n",
       "[4 rows x 13 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44008e",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 6891
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_496e7 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_496e7 td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_496e7 tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_496e7 tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_496e7\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_496e7_level0_col0\" class=\"col_heading level0 col0\" >APP_ID</th>\n",
       "      <th id=\"T_496e7_level0_col1\" class=\"col_heading level0 col1\" >annual_inc</th>\n",
       "      <th id=\"T_496e7_level0_col2\" class=\"col_heading level0 col2\" >debt_to_income</th>\n",
       "      <th id=\"T_496e7_level0_col3\" class=\"col_heading level0 col3\" >delinq_2yrs</th>\n",
       "      <th id=\"T_496e7_level0_col4\" class=\"col_heading level0 col4\" >inq_last_6mths</th>\n",
       "      <th id=\"T_496e7_level0_col5\" class=\"col_heading level0 col5\" >mths_since_last_delinq</th>\n",
       "      <th id=\"T_496e7_level0_col6\" class=\"col_heading level0 col6\" >mths_since_last_record</th>\n",
       "      <th id=\"T_496e7_level0_col7\" class=\"col_heading level0 col7\" >open_acc</th>\n",
       "      <th id=\"T_496e7_level0_col8\" class=\"col_heading level0 col8\" >pub_rec</th>\n",
       "      <th id=\"T_496e7_level0_col9\" class=\"col_heading level0 col9\" >revol_bal</th>\n",
       "      <th id=\"T_496e7_level0_col10\" class=\"col_heading level0 col10\" >revol_util</th>\n",
       "      <th id=\"T_496e7_level0_col11\" class=\"col_heading level0 col11\" >total_acc</th>\n",
       "      <th id=\"T_496e7_level0_col12\" class=\"col_heading level0 col12\" >collections_12_mths_ex_med</th>\n",
       "      <th id=\"T_496e7_level0_col13\" class=\"col_heading level0 col13\" >mths_since_last_major_derog</th>\n",
       "      <th id=\"T_496e7_level0_col14\" class=\"col_heading level0 col14\" >TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_496e7_row0_col0\" class=\"data row0 col0\" >8000.000</td>\n",
       "      <td id=\"T_496e7_row0_col1\" class=\"data row0 col1\" >7999.000</td>\n",
       "      <td id=\"T_496e7_row0_col2\" class=\"data row0 col2\" >8000.000</td>\n",
       "      <td id=\"T_496e7_row0_col3\" class=\"data row0 col3\" >7995.000</td>\n",
       "      <td id=\"T_496e7_row0_col4\" class=\"data row0 col4\" >7995.000</td>\n",
       "      <td id=\"T_496e7_row0_col5\" class=\"data row0 col5\" >2925.000</td>\n",
       "      <td id=\"T_496e7_row0_col6\" class=\"data row0 col6\" >656.000</td>\n",
       "      <td id=\"T_496e7_row0_col7\" class=\"data row0 col7\" >7995.000</td>\n",
       "      <td id=\"T_496e7_row0_col8\" class=\"data row0 col8\" >7995.000</td>\n",
       "      <td id=\"T_496e7_row0_col9\" class=\"data row0 col9\" >8000.000</td>\n",
       "      <td id=\"T_496e7_row0_col10\" class=\"data row0 col10\" >7977.000</td>\n",
       "      <td id=\"T_496e7_row0_col11\" class=\"data row0 col11\" >7995.000</td>\n",
       "      <td id=\"T_496e7_row0_col12\" class=\"data row0 col12\" >7971.000</td>\n",
       "      <td id=\"T_496e7_row0_col13\" class=\"data row0 col13\" >8000.000</td>\n",
       "      <td id=\"T_496e7_row0_col14\" class=\"data row0 col14\" >8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_496e7_row1_col0\" class=\"data row1 col0\" >5012.507</td>\n",
       "      <td id=\"T_496e7_row1_col1\" class=\"data row1 col1\" >68496.262</td>\n",
       "      <td id=\"T_496e7_row1_col2\" class=\"data row1 col2\" >13.339</td>\n",
       "      <td id=\"T_496e7_row1_col3\" class=\"data row1 col3\" >0.151</td>\n",
       "      <td id=\"T_496e7_row1_col4\" class=\"data row1 col4\" >1.071</td>\n",
       "      <td id=\"T_496e7_row1_col5\" class=\"data row1 col5\" >35.511</td>\n",
       "      <td id=\"T_496e7_row1_col6\" class=\"data row1 col6\" >60.113</td>\n",
       "      <td id=\"T_496e7_row1_col7\" class=\"data row1 col7\" >9.345</td>\n",
       "      <td id=\"T_496e7_row1_col8\" class=\"data row1 col8\" >0.058</td>\n",
       "      <td id=\"T_496e7_row1_col9\" class=\"data row1 col9\" >14289.763</td>\n",
       "      <td id=\"T_496e7_row1_col10\" class=\"data row1 col10\" >48.331</td>\n",
       "      <td id=\"T_496e7_row1_col11\" class=\"data row1 col11\" >22.071</td>\n",
       "      <td id=\"T_496e7_row1_col12\" class=\"data row1 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row1_col13\" class=\"data row1 col13\" >2.004</td>\n",
       "      <td id=\"T_496e7_row1_col14\" class=\"data row1 col14\" >0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_496e7_row2_col0\" class=\"data row2 col0\" >2887.649</td>\n",
       "      <td id=\"T_496e7_row2_col1\" class=\"data row2 col1\" >49335.288</td>\n",
       "      <td id=\"T_496e7_row2_col2\" class=\"data row2 col2\" >6.733</td>\n",
       "      <td id=\"T_496e7_row2_col3\" class=\"data row2 col3\" >0.518</td>\n",
       "      <td id=\"T_496e7_row2_col4\" class=\"data row2 col4\" >1.490</td>\n",
       "      <td id=\"T_496e7_row2_col5\" class=\"data row2 col5\" >22.388</td>\n",
       "      <td id=\"T_496e7_row2_col6\" class=\"data row2 col6\" >46.388</td>\n",
       "      <td id=\"T_496e7_row2_col7\" class=\"data row2 col7\" >4.511</td>\n",
       "      <td id=\"T_496e7_row2_col8\" class=\"data row2 col8\" >0.248</td>\n",
       "      <td id=\"T_496e7_row2_col9\" class=\"data row2 col9\" >25672.028</td>\n",
       "      <td id=\"T_496e7_row2_col10\" class=\"data row2 col10\" >28.291</td>\n",
       "      <td id=\"T_496e7_row2_col11\" class=\"data row2 col11\" >11.723</td>\n",
       "      <td id=\"T_496e7_row2_col12\" class=\"data row2 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row2_col13\" class=\"data row2 col13\" >0.811</td>\n",
       "      <td id=\"T_496e7_row2_col14\" class=\"data row2 col14\" >0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_496e7_row3_col0\" class=\"data row3 col0\" >2.000</td>\n",
       "      <td id=\"T_496e7_row3_col1\" class=\"data row3 col1\" >2000.000</td>\n",
       "      <td id=\"T_496e7_row3_col2\" class=\"data row3 col2\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col3\" class=\"data row3 col3\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col4\" class=\"data row3 col4\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col5\" class=\"data row3 col5\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col6\" class=\"data row3 col6\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col7\" class=\"data row3 col7\" >1.000</td>\n",
       "      <td id=\"T_496e7_row3_col8\" class=\"data row3 col8\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col9\" class=\"data row3 col9\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col10\" class=\"data row3 col10\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col11\" class=\"data row3 col11\" >1.000</td>\n",
       "      <td id=\"T_496e7_row3_col12\" class=\"data row3 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row3_col13\" class=\"data row3 col13\" >1.000</td>\n",
       "      <td id=\"T_496e7_row3_col14\" class=\"data row3 col14\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_496e7_row4_col0\" class=\"data row4 col0\" >2512.750</td>\n",
       "      <td id=\"T_496e7_row4_col1\" class=\"data row4 col1\" >40000.000</td>\n",
       "      <td id=\"T_496e7_row4_col2\" class=\"data row4 col2\" >8.158</td>\n",
       "      <td id=\"T_496e7_row4_col3\" class=\"data row4 col3\" >0.000</td>\n",
       "      <td id=\"T_496e7_row4_col4\" class=\"data row4 col4\" >0.000</td>\n",
       "      <td id=\"T_496e7_row4_col5\" class=\"data row4 col5\" >17.000</td>\n",
       "      <td id=\"T_496e7_row4_col6\" class=\"data row4 col6\" >0.000</td>\n",
       "      <td id=\"T_496e7_row4_col7\" class=\"data row4 col7\" >6.000</td>\n",
       "      <td id=\"T_496e7_row4_col8\" class=\"data row4 col8\" >0.000</td>\n",
       "      <td id=\"T_496e7_row4_col9\" class=\"data row4 col9\" >3519.750</td>\n",
       "      <td id=\"T_496e7_row4_col10\" class=\"data row4 col10\" >24.600</td>\n",
       "      <td id=\"T_496e7_row4_col11\" class=\"data row4 col11\" >13.000</td>\n",
       "      <td id=\"T_496e7_row4_col12\" class=\"data row4 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row4_col13\" class=\"data row4 col13\" >1.000</td>\n",
       "      <td id=\"T_496e7_row4_col14\" class=\"data row4 col14\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_496e7_row5_col0\" class=\"data row5 col0\" >5014.500</td>\n",
       "      <td id=\"T_496e7_row5_col1\" class=\"data row5 col1\" >58344.000</td>\n",
       "      <td id=\"T_496e7_row5_col2\" class=\"data row5 col2\" >13.440</td>\n",
       "      <td id=\"T_496e7_row5_col3\" class=\"data row5 col3\" >0.000</td>\n",
       "      <td id=\"T_496e7_row5_col4\" class=\"data row5 col4\" >1.000</td>\n",
       "      <td id=\"T_496e7_row5_col5\" class=\"data row5 col5\" >33.000</td>\n",
       "      <td id=\"T_496e7_row5_col6\" class=\"data row5 col6\" >85.000</td>\n",
       "      <td id=\"T_496e7_row5_col7\" class=\"data row5 col7\" >9.000</td>\n",
       "      <td id=\"T_496e7_row5_col8\" class=\"data row5 col8\" >0.000</td>\n",
       "      <td id=\"T_496e7_row5_col9\" class=\"data row5 col9\" >8668.500</td>\n",
       "      <td id=\"T_496e7_row5_col10\" class=\"data row5 col10\" >48.200</td>\n",
       "      <td id=\"T_496e7_row5_col11\" class=\"data row5 col11\" >20.000</td>\n",
       "      <td id=\"T_496e7_row5_col12\" class=\"data row5 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row5_col13\" class=\"data row5 col13\" >2.000</td>\n",
       "      <td id=\"T_496e7_row5_col14\" class=\"data row5 col14\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_496e7_row6_col0\" class=\"data row6 col0\" >7505.250</td>\n",
       "      <td id=\"T_496e7_row6_col1\" class=\"data row6 col1\" >82000.000</td>\n",
       "      <td id=\"T_496e7_row6_col2\" class=\"data row6 col2\" >18.620</td>\n",
       "      <td id=\"T_496e7_row6_col3\" class=\"data row6 col3\" >0.000</td>\n",
       "      <td id=\"T_496e7_row6_col4\" class=\"data row6 col4\" >2.000</td>\n",
       "      <td id=\"T_496e7_row6_col5\" class=\"data row6 col5\" >52.000</td>\n",
       "      <td id=\"T_496e7_row6_col6\" class=\"data row6 col6\" >101.000</td>\n",
       "      <td id=\"T_496e7_row6_col7\" class=\"data row6 col7\" >12.000</td>\n",
       "      <td id=\"T_496e7_row6_col8\" class=\"data row6 col8\" >0.000</td>\n",
       "      <td id=\"T_496e7_row6_col9\" class=\"data row6 col9\" >16902.000</td>\n",
       "      <td id=\"T_496e7_row6_col10\" class=\"data row6 col10\" >71.700</td>\n",
       "      <td id=\"T_496e7_row6_col11\" class=\"data row6 col11\" >29.000</td>\n",
       "      <td id=\"T_496e7_row6_col12\" class=\"data row6 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row6_col13\" class=\"data row6 col13\" >3.000</td>\n",
       "      <td id=\"T_496e7_row6_col14\" class=\"data row6 col14\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496e7_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_496e7_row7_col0\" class=\"data row7 col0\" >10000.000</td>\n",
       "      <td id=\"T_496e7_row7_col1\" class=\"data row7 col1\" >900000.000</td>\n",
       "      <td id=\"T_496e7_row7_col2\" class=\"data row7 col2\" >29.990</td>\n",
       "      <td id=\"T_496e7_row7_col3\" class=\"data row7 col3\" >11.000</td>\n",
       "      <td id=\"T_496e7_row7_col4\" class=\"data row7 col4\" >25.000</td>\n",
       "      <td id=\"T_496e7_row7_col5\" class=\"data row7 col5\" >120.000</td>\n",
       "      <td id=\"T_496e7_row7_col6\" class=\"data row7 col6\" >119.000</td>\n",
       "      <td id=\"T_496e7_row7_col7\" class=\"data row7 col7\" >36.000</td>\n",
       "      <td id=\"T_496e7_row7_col8\" class=\"data row7 col8\" >3.000</td>\n",
       "      <td id=\"T_496e7_row7_col9\" class=\"data row7 col9\" >1207359.000</td>\n",
       "      <td id=\"T_496e7_row7_col10\" class=\"data row7 col10\" >100.000</td>\n",
       "      <td id=\"T_496e7_row7_col11\" class=\"data row7 col11\" >81.000</td>\n",
       "      <td id=\"T_496e7_row7_col12\" class=\"data row7 col12\" >0.000</td>\n",
       "      <td id=\"T_496e7_row7_col13\" class=\"data row7 col13\" >3.000</td>\n",
       "      <td id=\"T_496e7_row7_col14\" class=\"data row7 col14\" >1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "             APP_ID     annual_inc  ...  mths_since_last_major_derog       TARGET\n",
       "count   8000.000000    7999.000000  ...                  8000.000000  8000.000000\n",
       "mean    5012.506875   68496.262437  ...                     2.004125     0.127750\n",
       "std     2887.649416   49335.288010  ...                     0.811289     0.333832\n",
       "min        2.000000    2000.000000  ...                     1.000000     0.000000\n",
       "25%     2512.750000   40000.000000  ...                     1.000000     0.000000\n",
       "50%     5014.500000   58344.000000  ...                     2.000000     0.000000\n",
       "75%     7505.250000   82000.000000  ...                     3.000000     0.000000\n",
       "max    10000.000000  900000.000000  ...                     3.000000     1.000000\n",
       "\n",
       "[8 rows x 15 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a24dcf",
   "metadata": {
    "input_tokens": 802
   },
   "source": [
    "Based on your dataset exploration, I can see several columns with missing values. Here's a strategy for handling them:\n",
    "\n",
    "1. **Low Missing Rate Columns (< 1%)**:\n",
    "   - `annual_inc`, `delinq_2yrs`, `earliest_cr_line`, `inq_last_6mths`, `open_acc`, `pub_rec`, `total_acc`, `revol_util`, `collections_12_mths_ex_med`, `purpose`\n",
    "   - Strategy: Impute with median (for numeric) or mode (for categorical)\n",
    "\n",
    "2. **Medium Missing Rate Columns (1-40%)**:\n",
    "   - `emp_title` (5.8%)\n",
    "   - `Notes` (31.7%)\n",
    "   - Strategy: For `emp_title`, create a \"Unknown\" category. For `Notes`, either drop the column if it's not predictive or use NLP techniques if you want to extract value\n",
    "\n",
    "3. **High Missing Rate Columns (> 40%)**:\n",
    "   - `mths_since_last_delinq` (63.4%)\n",
    "   - `mths_since_last_record` (91.8%)\n",
    "   - Strategy: Create binary features indicating whether the value is missing (often missing means \"no delinquency\" or \"no record\"), then impute the non-missing values\n",
    "\n",
    "Here's code to implement this approach:\n",
    "\n",
    "```python\n",
    "# For low missing rate numeric columns\n",
    "num_cols = ['annual_inc', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', \n",
    "           'pub_rec', 'total_acc', 'revol_util', 'collections_12_mths_ex_med']\n",
    "for col in num_cols:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# For categorical columns with low missing rates\n",
    "cat_cols = ['purpose', 'earliest_cr_line']\n",
    "for col in cat_cols:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# For medium missing rate columns\n",
    "if df['emp_title'].isna().sum() > 0:\n",
    "    df['emp_title'] = df['emp_title'].fillna('Unknown')\n",
    "\n",
    "# For high missing rate columns, create indicator features\n",
    "for col in ['mths_since_last_delinq', 'mths_since_last_record']:\n",
    "    df[f'has_{col}'] = df[col].notna().astype(int)\n",
    "    df[col] = df[col].fillna(0)  # Missing often means \"no delinquency/record\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46389a5c",
   "metadata": {
    "input_tokens": 24,
    "output_tokens": 114
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m low_missing_cols = \u001b[43mmissing_cols\u001b[49m[missing_cols< \u001b[32m0.01\u001b[39m].index\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'missing_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'missing_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7c1c7d36d416>\", line 1, in <module>\n    low_missing_cols = missing_cols[missing_cols< 0.01].index\n                       ^^^^^^^^^^^^\n",
      "NameError: name 'missing_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "low_missing_cols = missing_cols[missing_cols< 0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc967a",
   "metadata": {
    "input_tokens": 39,
    "output_tokens": 136
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m low_missing_cols = \u001b[43mmissing_cols\u001b[49m[(missing_cols< \u001b[32m0.01\u001b[39m) & (missing_cols>\u001b[32m0\u001b[39m)]\n",
      "\u001b[32m      2\u001b[39m low_missing_cols\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'missing_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'missing_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-bce7c3d021bb>\", line 1, in <module>\n    low_missing_cols = missing_cols[(missing_cols< 0.01) & (missing_cols>0)]\n                       ^^^^^^^^^^^^\n",
      "NameError: name 'missing_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "low_missing_cols = missing_cols[(missing_cols< 0.01) & (missing_cols>0)]\n",
    "low_missing_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba7dfb",
   "metadata": {
    "input_tokens": 40,
    "output_tokens": 144
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m mode_values = {}\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlow_missing_cols\u001b[49m.index:\n",
      "\u001b[32m      3\u001b[39m     mode_values[col] = df[col].mode()[\u001b[32m0\u001b[39m]\n",
      "\u001b[32m      4\u001b[39m mode_values\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'low_missing_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'low_missing_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-b613fbd27d53>\", line 2, in <module>\n    for col in low_missing_cols.index:\n               ^^^^^^^^^^^^^^^^\n",
      "NameError: name 'low_missing_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "mode_values = {}\n",
    "for col in low_missing_cols.index:\n",
    "    mode_values[col] = df[col].mode()[0]\n",
    "mode_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42469566",
   "metadata": {
    "input_tokens": 21
   },
   "source": [
    "## replace wit with mode vaue for 0.01 missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aed172",
   "metadata": {
    "input_tokens": 33,
    "output_tokens": 126
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlow_missing_cols\u001b[49m.index:\n",
      "\u001b[32m      2\u001b[39m     df[col] = df[col].fillna(mode_values[col])\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'low_missing_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'low_missing_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-4e318d2b6f44>\", line 1, in <module>\n    for col in low_missing_cols.index:\n               ^^^^^^^^^^^^^^^^\n",
      "NameError: name 'low_missing_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "for col in low_missing_cols.index:\n",
    "    df[col] = df[col].fillna(mode_values[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9ff38",
   "metadata": {
    "input_tokens": 33,
    "output_tokens": 126
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m low_missing_cols = \u001b[43mmissing_cols\u001b[49m[(missing_cols< \u001b[32m0.01\u001b[39m) & (missing_cols>\u001b[32m0\u001b[39m)]\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'missing_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'missing_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-8e3ae25f27ab>\", line 1, in <module>\n    low_missing_cols = missing_cols[(missing_cols< 0.01) & (missing_cols>0)]\n                       ^^^^^^^^^^^^\n",
      "NameError: name 'missing_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "low_missing_cols = missing_cols[(missing_cols< 0.01) & (missing_cols>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024818ac",
   "metadata": {
    "input_tokens": 18,
    "output_tokens": 106
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mlow_missing_cols\u001b[49m.index].isna().sum()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'low_missing_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'low_missing_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-eef62ba32269>\", line 1, in <module>\n    df[low_missing_cols.index].isna().sum()\n       ^^^^^^^^^^^^^^^^\n",
      "NameError: name 'low_missing_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[low_missing_cols.index].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a7fcd",
   "metadata": {
    "input_tokens": 15
   },
   "source": [
    "## Medium Missing Rate Columns (1-40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ac6e8",
   "metadata": {
    "input_tokens": 84,
    "output_tokens": 46
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title    0.058125\n",
       "Notes        0.316500\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get the medium missing rate columns (1-40%)\n",
    "missing_cols=    df.isna().sum()/df.shape[0]\n",
    "medium_missing_cols = missing_cols[(missing_cols< 0.40) & (missing_cols>0.01)]\n",
    "medium_missing_cols\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab83f9e",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 46
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title    0.058125\n",
       "Notes        0.316500\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9885fb4",
   "metadata": {
    "input_tokens": 52,
    "output_tokens": 73
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emp_title': 'US Army', 'Notes': ' '}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[medium_missing_cols.index]\n",
    "mode_values = {}\n",
    "for col in medium_missing_cols.index:\n",
    "    mode_values[col] = df[col].mode()[0]\n",
    "mode_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d45950",
   "metadata": {
    "input_tokens": 18,
    "output_tokens": 39
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title     465\n",
       "Notes        2532\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[medium_missing_cols.index].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b375953",
   "metadata": {
    "input_tokens": 24
   },
   "outputs": [],
   "source": [
    "df['emp_title'] = df['emp_title'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211ad0e",
   "metadata": {
    "input_tokens": 22
   },
   "outputs": [],
   "source": [
    "df['Notes'] = df['Notes'].fillna('Not shared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fce2d",
   "metadata": {
    "input_tokens": 13
   },
   "source": [
    "## High Missing Rate Columns (> 40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bbbf2",
   "metadata": {
    "input_tokens": 64,
    "output_tokens": 58
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mths_since_last_delinq    0.634375\n",
       "mths_since_last_record    0.918000\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get more than 40 % columns \n",
    "missing_cols=    df.isna().sum()/df.shape[0]\n",
    "high_missing_cols = missing_cols[(missing_cols> 0.40)]\n",
    "high_missing_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebeb94",
   "metadata": {
    "input_tokens": 40,
    "output_tokens": 78
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mths_since_last_delinq': np.float64(0.0),\n",
       " 'mths_since_last_record': np.float64(0.0)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_values = {}\n",
    "for col in high_missing_cols.index:\n",
    "    mode_values[col] = df[col].mode()[0]\n",
    "mode_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987f608",
   "metadata": {
    "input_tokens": 10,
    "output_tokens": 1785
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7cc72 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7cc72 td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_7cc72 tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_7cc72 tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7cc72\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7cc72_level0_col0\" class=\"col_heading level0 col0\" >mths_since_last_delinq</th>\n",
       "      <th id=\"T_7cc72_level0_col1\" class=\"col_heading level0 col1\" >mths_since_last_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7cc72_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7cc72_row1_col0\" class=\"data row1 col0\" >44.000</td>\n",
       "      <td id=\"T_7cc72_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7cc72_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7cc72_row3_col0\" class=\"data row3 col0\" >46.000</td>\n",
       "      <td id=\"T_7cc72_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7cc72_row4_col0\" class=\"data row4 col0\" >22.000</td>\n",
       "      <td id=\"T_7cc72_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7cc72_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7cc72_row6_col0\" class=\"data row6 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row6_col1\" class=\"data row6 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7cc72_row7_col0\" class=\"data row7 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row7_col1\" class=\"data row7 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7cc72_row8_col0\" class=\"data row8 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row8_col1\" class=\"data row8 col1\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7cc72_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7cc72_row9_col0\" class=\"data row9 col0\" >nan</td>\n",
       "      <td id=\"T_7cc72_row9_col1\" class=\"data row9 col1\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "      mths_since_last_delinq  mths_since_last_record\n",
       "0                        NaN                     NaN\n",
       "1                       44.0                     NaN\n",
       "2                        NaN                     NaN\n",
       "3                       46.0                     NaN\n",
       "4                       22.0                     NaN\n",
       "...                      ...                     ...\n",
       "7995                     NaN                     NaN\n",
       "7996                     NaN                     NaN\n",
       "7997                    49.0                     NaN\n",
       "7998                    44.0                     NaN\n",
       "7999                     NaN                     NaN\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[high_missing_cols.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc9176",
   "metadata": {
    "input_tokens": 40
   },
   "outputs": [],
   "source": [
    "for col in high_missing_cols.index:\n",
    "    df[f'has_{col}'] = df[col].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0f9cf",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 553
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['APP_ID', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'pymnt_plan', 'Notes', 'purpose_cat',\n",
       "       'purpose', 'zip_code', 'addr_state', 'debt_to_income', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths',\n",
       "       'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
       "       'initial_list_status', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code', 'TARGET',\n",
       "       'has_mths_since_last_delinq', 'has_mths_since_last_record'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063335c4",
   "metadata": {
    "input_tokens": 28,
    "output_tokens": 1732
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c3294 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c3294 td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_c3294 tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_c3294 tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c3294\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c3294_level0_col0\" class=\"col_heading level0 col0\" >mths_since_last_delinq</th>\n",
       "      <th id=\"T_c3294_level0_col1\" class=\"col_heading level0 col1\" >has_mths_since_last_delinq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c3294_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c3294_row1_col0\" class=\"data row1 col0\" >44.000</td>\n",
       "      <td id=\"T_c3294_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c3294_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c3294_row3_col0\" class=\"data row3 col0\" >46.000</td>\n",
       "      <td id=\"T_c3294_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c3294_row4_col0\" class=\"data row4 col0\" >22.000</td>\n",
       "      <td id=\"T_c3294_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c3294_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c3294_row6_col0\" class=\"data row6 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c3294_row7_col0\" class=\"data row7 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c3294_row8_col0\" class=\"data row8 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3294_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c3294_row9_col0\" class=\"data row9 col0\" >nan</td>\n",
       "      <td id=\"T_c3294_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "      mths_since_last_delinq  has_mths_since_last_delinq\n",
       "0                        NaN                           0\n",
       "1                       44.0                           1\n",
       "2                        NaN                           0\n",
       "3                       46.0                           1\n",
       "4                       22.0                           1\n",
       "...                      ...                         ...\n",
       "7995                     NaN                           0\n",
       "7996                     NaN                           0\n",
       "7997                    49.0                           1\n",
       "7998                    44.0                           1\n",
       "7999                     NaN                           0\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['mths_since_last_delinq', 'has_mths_since_last_delinq']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114d9ee",
   "metadata": {
    "input_tokens": 31
   },
   "outputs": [],
   "source": [
    "for col in high_missing_cols.index:\n",
    "    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505afbb",
   "metadata": {
    "collapsed": true,
    "input_tokens": 60,
    "output_tokens": 2691
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_24967 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_24967 td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_24967 tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_24967 tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_24967\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_24967_level0_col0\" class=\"col_heading level0 col0\" >mths_since_last_delinq</th>\n",
       "      <th id=\"T_24967_level0_col1\" class=\"col_heading level0 col1\" >has_mths_since_last_delinq</th>\n",
       "      <th id=\"T_24967_level0_col2\" class=\"col_heading level0 col2\" >mths_since_last_record</th>\n",
       "      <th id=\"T_24967_level0_col3\" class=\"col_heading level0 col3\" >has_mths_since_last_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_24967_row0_col0\" class=\"data row0 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_24967_row0_col2\" class=\"data row0 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_24967_row1_col0\" class=\"data row1 col0\" >44.000</td>\n",
       "      <td id=\"T_24967_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_24967_row1_col2\" class=\"data row1 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_24967_row2_col0\" class=\"data row2 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_24967_row2_col2\" class=\"data row2 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_24967_row3_col0\" class=\"data row3 col0\" >46.000</td>\n",
       "      <td id=\"T_24967_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "      <td id=\"T_24967_row3_col2\" class=\"data row3 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_24967_row4_col0\" class=\"data row4 col0\" >22.000</td>\n",
       "      <td id=\"T_24967_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_24967_row4_col2\" class=\"data row4 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_24967_row5_col0\" class=\"data row5 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "      <td id=\"T_24967_row5_col2\" class=\"data row5 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_24967_row6_col0\" class=\"data row6 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_24967_row6_col2\" class=\"data row6 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_24967_row7_col0\" class=\"data row7 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_24967_row7_col2\" class=\"data row7 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_24967_row8_col0\" class=\"data row8 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_24967_row8_col2\" class=\"data row8 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24967_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_24967_row9_col0\" class=\"data row9 col0\" >0.000</td>\n",
       "      <td id=\"T_24967_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_24967_row9_col2\" class=\"data row9 col2\" >0.000</td>\n",
       "      <td id=\"T_24967_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "   mths_since_last_delinq  ...  has_mths_since_last_record\n",
       "0                     0.0  ...                           0\n",
       "1                    44.0  ...                           0\n",
       "2                     0.0  ...                           0\n",
       "3                    46.0  ...                           0\n",
       "4                    22.0  ...                           0\n",
       "5                     0.0  ...                           0\n",
       "6                     0.0  ...                           0\n",
       "7                     0.0  ...                           0\n",
       "8                     0.0  ...                           0\n",
       "9                     0.0  ...                           0\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['mths_since_last_delinq', 'has_mths_since_last_delinq', \n",
    "    'mths_since_last_record', 'has_mths_since_last_record']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b9a38",
   "metadata": {
    "input_tokens": 363
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"Preprocess loan application data with appropriate handling of missing values\"\n",
    "    # Make a copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate missing percentages\n",
    "    missing_pct = df.isna().sum()/df.shape[0]\n",
    "    \n",
    "    # Handle low missing rate columns (<1%)\n",
    "    low_missing = missing_pct[(missing_pct < 0.01) & (missing_pct > 0)].index\n",
    "    for col in low_missing:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_val)\n",
    "    \n",
    "    # Handle medium missing rate columns (1-40%)\n",
    "    df['emp_title'] = df['emp_title'].fillna('Unknown')\n",
    "    df['Notes'] = df['Notes'].fillna('Not shared')\n",
    "    \n",
    "    # Handle high missing rate columns (>40%)\n",
    "    high_missing = missing_pct[missing_pct > 0.40].index\n",
    "    for col in high_missing:\n",
    "        df[f'has_{col}'] = df[col].notna().astype(int)\n",
    "        df[col] = df[col].fillna(0)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09af06f",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 351
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APP_ID                          0\n",
       "emp_title                       0\n",
       "emp_length                      0\n",
       "home_ownership                  0\n",
       "annual_inc                      1\n",
       "verification_status             0\n",
       "pymnt_plan                      0\n",
       "Notes                           0\n",
       "purpose_cat                     0\n",
       "purpose                         4\n",
       "zip_code                        0\n",
       "addr_state                      0\n",
       "debt_to_income                  0\n",
       "delinq_2yrs                     5\n",
       "earliest_cr_line                5\n",
       "inq_last_6mths                  5\n",
       "mths_since_last_delinq          0\n",
       "mths_since_last_record          0\n",
       "open_acc                        5\n",
       "pub_rec                         5\n",
       "revol_bal                       0\n",
       "revol_util                     23\n",
       "total_acc                       5\n",
       "initial_list_status             0\n",
       "collections_12_mths_ex_med     29\n",
       "mths_since_last_major_derog     0\n",
       "policy_code                     0\n",
       "TARGET                          0\n",
       "has_mths_since_last_delinq      0\n",
       "has_mths_since_last_record      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc18285",
   "metadata": {
    "input_tokens": 9
   },
   "outputs": [],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349189c",
   "metadata": {
    "input_tokens": 6
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e4e1a",
   "metadata": {
    "input_tokens": 490
   },
   "source": [
    "# Faeture eng for ltr\n",
    "```python\n",
    "# Check target distribution\n",
    "df['TARGET'].value_counts(normalize=True)\n",
    "```\n",
    "\n",
    "Then let's create some useful features that might help predict defaults:\n",
    "\n",
    "```python\n",
    "# Extract credit history length\n",
    "df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "df['cr_history_length'] = (pd.to_datetime('now') - df['earliest_cr_line']).dt.days / 365.25\n",
    "\n",
    "# Create debt-to-income ratio buckets\n",
    "df['dti_buckets'] = pd.cut(df['debt_to_income'], bins=[0, 10, 15, 20, 30], labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Create utilization bands\n",
    "df['util_band'] = pd.cut(df['revol_util'], bins=[0, 30, 60, 80, 100], labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Create inquiry bands\n",
    "df['inq_band'] = pd.cut(df['inq_last_6mths'], bins=[-1, 0, 2, 5, 25], labels=['None', 'Low', 'Medium', 'High'])\n",
    "```\n",
    "\n",
    "Next, let's look at correlation with the target:\n",
    "\n",
    "```python\n",
    "# Calculate correlation with target for numeric features\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "correlations = df[num_cols].corrwith(df['TARGET']).sort_values(ascending=False)\n",
    "correlations\n",
    "```\n",
    "\n",
    "This will give us a good foundation for building our challenger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489226b9",
   "metadata": {
    "input_tokens": 13,
    "output_tokens": 54
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    0.87225\n",
       "1    0.12775\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TARGET.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a7e17",
   "metadata": {
    "input_tokens": 7,
    "output_tokens": 597,
    "solveit_ai": true
   },
   "source": [
    "lest go with class weight\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's implement the tabular model with class weights to handle the imbalance:\n",
    "\n",
    "```python\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_idx = np.random.permutation(len(df))[:int(0.8*len(df))]\n",
    "valid_idx = np.setdiff1d(np.arange(len(df)), train_idx)\n",
    "\n",
    "# Define categorical and continuous variables\n",
    "cat_names = ['home_ownership', 'verification_status', 'purpose_cat', 'addr_state', \n",
    "             'initial_list_status', 'policy_code', 'has_mths_since_last_delinq', \n",
    "             'has_mths_since_last_record']\n",
    "             \n",
    "cont_names = ['annual_inc', 'debt_to_income', 'delinq_2yrs', 'inq_last_6mths', \n",
    "              'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', \n",
    "              'pub_rec', 'revol_bal', 'revol_util', 'total_acc', \n",
    "              'mths_since_last_major_derog']\n",
    "\n",
    "# Create TabularPandas object\n",
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "                  cat_names=cat_names,\n",
    "                  cont_names=cont_names,\n",
    "                  y_names='TARGET',\n",
    "                  splits=(train_idx, valid_idx))\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = to.dataloaders(bs=64)\n",
    "\n",
    "# Calculate class weights (inverse of class frequencies)\n",
    "weights = 1/torch.Tensor([0.87225, 0.12775])\n",
    "weights = weights / weights.sum()\n",
    "class_weights = weights * 2  # Normalize and scale\n",
    "\n",
    "# Create and train the model with class weights\n",
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary()])\n",
    "learn.loss_func = CrossEntropyLossFlat(weight=class_weights)\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(5, 1e-2, wd=0.1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ce712",
   "metadata": {
    "input_tokens": 13,
    "output_tokens": 411,
    "solveit_ai": true
   },
   "source": [
    "what about the the Gini coefficient metric..\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're right, we should include the Gini coefficient since it's specifically mentioned in your assessment. Let's implement a custom Gini metric for fastai:\n",
    "\n",
    "```python\n",
    "class GiniCoefficient(Metric):\n",
    "    \"Computes Gini coefficient (2*AUC-1)\"\n",
    "    def __init__(self): self.reset()\n",
    "    \n",
    "    def reset(self): \n",
    "        self.preds,self.targs = [],[]\n",
    "        \n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred.sigmoid()\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(learn.y)\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        preds = torch.cat(self.preds).cpu().numpy()\n",
    "        targs = torch.cat(self.targs).cpu().numpy()\n",
    "        auc = roc_auc_score(targs, preds)\n",
    "        return 2 * auc - 1\n",
    "    \n",
    "    @property\n",
    "    def name(self): return \"gini\"\n",
    "```\n",
    "\n",
    "Now let's update our model to include this metric:\n",
    "\n",
    "```python\n",
    "# Create and train the model with class weights and Gini coefficient\n",
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary(), GiniCoefficient()])\n",
    "learn.loss_func = CrossEntropyLossFlat(weight=class_weights)\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(5, 1e-2, wd=0.1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e67ba",
   "metadata": {
    "input_tokens": 24,
    "output_tokens": 123
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cont_cols,cat_cols = \u001b[43mcont_cat_split\u001b[49m(df,dep_var=\u001b[33m'\u001b[39m\u001b[33mTARGET\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cat_split' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cat_split' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-c813cb97c04f>\", line 1, in <module>\n    cont_cols,cat_cols = cont_cat_split(df,dep_var='TARGET')\n                         ^^^^^^^^^^^^^^\n",
      "NameError: name 'cont_cat_split' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols,cat_cols = cont_cat_split(df,dep_var='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1cad0",
   "metadata": {
    "collapsed": true,
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcont_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7def3622cedc>\", line 1, in <module>\n    cont_cols\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb4432",
   "metadata": {
    "input_tokens": 10,
    "output_tokens": 97
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcont_cols\u001b[49m].head()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-63c97779fddd>\", line 1, in <module>\n    df[cont_cols].head()\n       ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cont_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c4e77",
   "metadata": {
    "collapsed": true,
    "input_tokens": 10,
    "output_tokens": 97
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcat_cols\u001b[49m].head()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-2768feb3c727>\", line 1, in <module>\n    df[cat_cols].head()\n       ^^^^^^^^\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ae855",
   "metadata": {
    "input_tokens": 52
   },
   "outputs": [],
   "source": [
    "#use RandomSplitter to get 80 train and 20 validation data\n",
    "splits = RandomSplitter(valid_pct=0.2, seed=42)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678cbbe2",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 448
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#6400) [np.int64(1449),np.int64(4488),np.int64(2985),np.int64(5470),np.int64(4407),np.int64(6658),np.int64(5757),np.int64(2280),np.int64(4869),np.int64(3909),np.int64(6662),np.int64(4173),np.int64(520),np.int64(1408),np.int64(3099),np.int64(936),np.int64(1613),np.int64(4317),np.int64(2253),np.int64(3210)...],\n",
       " (#1600) [np.int64(5542),np.int64(1762),np.int64(3954),np.int64(5968),np.int64(6758),np.int64(1615),np.int64(4484),np.int64(915),np.int64(5718),np.int64(1738),np.int64(5918),np.int64(4242),np.int64(1982),np.int64(5421),np.int64(7991),np.int64(7997),np.int64(7203),np.int64(3000),np.int64(6585),np.int64(7931)...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de9d82",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 99
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcat_cols\u001b[49m].nunique()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-61ca77afaaee>\", line 1, in <module>\n    df[cat_cols].nunique()\n       ^^^^^^^^\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59255651",
   "metadata": {
    "input_tokens": 445,
    "output_tokens": 156
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m\n",
      "\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Generate the summary\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m summary = cat_summary(df, \u001b[43mcat_cols\u001b[49m)\n",
      "\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Display in a more readable format\u001b[39;00m\n",
      "\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, data \u001b[38;5;129;01min\u001b[39;00m summary.items():\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-2282ad3211a1>\", line 32, in <module>\n    summary = cat_summary(df, cat_cols)\n                              ^^^^^^^^\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "def cat_summary(df, cat_cols, top_n=5):\n",
    "    \"Create a clean summary of categorical variables\"\n",
    "    results = {}\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        # Get value counts and calculate percentages\n",
    "        counts = df[col].value_counts()\n",
    "        total = len(df)\n",
    "        pcts = counts / total * 100\n",
    "        \n",
    "        # Store top N categories and their percentages\n",
    "        top_cats = list(counts.index[:top_n])\n",
    "        top_pcts = list(pcts.values[:top_n])\n",
    "        \n",
    "        # Format percentages with 2 decimal places\n",
    "        formatted_pcts = [f\"{p:.2f}%\" for p in top_pcts]\n",
    "        \n",
    "        # Create a dict of category:percentage pairs\n",
    "        cat_pct_pairs = dict(zip(top_cats, formatted_pcts))\n",
    "        \n",
    "        # Add number of unique values\n",
    "        n_unique = df[col].nunique()\n",
    "        \n",
    "        results[col] = {\n",
    "            'unique_values': n_unique,\n",
    "            'top_categories': cat_pct_pairs\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate the summary\n",
    "summary = cat_summary(df, cat_cols)\n",
    "\n",
    "# Display in a more readable format\n",
    "for col, data in summary.items():\n",
    "    print(f\"\\n{col} ({data['unique_values']} unique values)\")\n",
    "    print(\"-\" * 50)\n",
    "    for cat, pct in data['top_categories'].items():\n",
    "        print(f\"{cat:<30} {pct:>10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a55821",
   "metadata": {
    "input_tokens": 144,
    "output_tokens": 643,
    "solveit_ai": true
   },
   "source": [
    "what's the ideal strategy for handling high cardinality categorical values? Specifically, \"notes\" shouldn't be treated as categorical. \"Employee title\" has really high cardinality, so I think we should drop it and convert the  continuous col. Definitely drop \"notes\" and \"purpose.\" Also, \"zip code.\" And \"earliest credit line\" is a date format, so we need to pull that out of the categorical values and handle it properly. please share your opinions ...\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're absolutely right about handling these high cardinality features. Here's my recommended approach:\n",
    "\n",
    "For high cardinality categorical columns:\n",
    "\n",
    "1. **emp_title (6689 unique values)**: \n",
    "   - Drop this column as it has too many unique values to be useful as a categorical\n",
    "   - Alternatively, we could extract a binary feature like \"is_employed\" but since most applicants are employed, this likely adds little value\n",
    "\n",
    "2. **Notes (5411 unique values)** and **purpose (4678 unique values)**:\n",
    "   - Drop these columns as they're too granular\n",
    "   - Keep only `purpose_cat` which has a manageable 27 categories and captures the same information in a structured way\n",
    "\n",
    "3. **zip_code (688 unique values)**:\n",
    "   - Drop this as it's too granular\n",
    "   - We already have `addr_state` which provides geographic information at a more appropriate level\n",
    "\n",
    "4. **earliest_cr_line (447 unique values)**:\n",
    "   - Convert this date to useful numeric features:\n",
    "   - Credit history length in years\n",
    "   - Possibly extract month as seasonality feature\n",
    "\n",
    "Here's how I'd implement these changes:\n",
    "\n",
    "```python\n",
    "# Drop high cardinality and less useful columns\n",
    "cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Convert earliest_cr_line to credit history length\n",
    "df_clean['earliest_cr_line'] = pd.to_datetime(df_clean['earliest_cr_line'])\n",
    "today = pd.to_datetime('today')\n",
    "df_clean['credit_history_years'] = (today - df_clean['earliest_cr_line']).dt.days / 365.25\n",
    "\n",
    "# Drop the original date column after extracting features\n",
    "df_clean = df_clean.drop(columns=['earliest_cr_line'])\n",
    "\n",
    "# Update categorical columns list\n",
    "cat_cols = [col for col in cat_cols if col not in cols_to_drop + ['earliest_cr_line']]\n",
    "\n",
    "# Add the new numeric column to continuous columns\n",
    "cont_cols = cont_cols + ['credit_history_years']\n",
    "```\n",
    "\n",
    "This approach will significantly reduce dimensionality while preserving the most valuable information for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8073b1",
   "metadata": {
    "input_tokens": 79
   },
   "outputs": [],
   "source": [
    "# lets drop for now(we ll come back to this ltr)\n",
    "# Drop high cardinality and less useful columns\n",
    "cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code']\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e294157",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 493
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['APP_ID', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'pymnt_plan', 'purpose_cat', 'addr_state',\n",
       "       'debt_to_income', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record',\n",
       "       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'collections_12_mths_ex_med',\n",
       "       'mths_since_last_major_derog', 'policy_code', 'TARGET', 'has_mths_since_last_delinq', 'has_mths_since_last_record'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed1aeb",
   "metadata": {
    "input_tokens": 27
   },
   "outputs": [],
   "source": [
    "df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5772452",
   "metadata": {
    "input_tokens": 13,
    "output_tokens": 141
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1999\n",
       "1       1996\n",
       "2       1997\n",
       "3       2003\n",
       "4       2001\n",
       "        ... \n",
       "7995    2002\n",
       "7996    1982\n",
       "7997    2003\n",
       "7998    1996\n",
       "7999    1994\n",
       "Name: earliest_cr_line, Length: 8000, dtype: int32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['earliest_cr_line'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dba1f",
   "metadata": {
    "collapsed": true,
    "input_tokens": 18,
    "output_tokens": 484
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "earliest_cr_line\n",
       "2000    666\n",
       "1998    610\n",
       "1999    558\n",
       "2001    512\n",
       "1997    483\n",
       "1996    480\n",
       "1995    423\n",
       "1994    413\n",
       "2002    410\n",
       "2003    378\n",
       "2004    337\n",
       "2005    323\n",
       "1993    296\n",
       "2006    256\n",
       "1991    213\n",
       "1990    210\n",
       "1992    195\n",
       "1989    168\n",
       "2007    138\n",
       "1987    138\n",
       "1988    128\n",
       "1986     98\n",
       "1984     91\n",
       "1985     71\n",
       "1983     59\n",
       "1982     50\n",
       "1979     39\n",
       "1981     33\n",
       "1980     32\n",
       "1978     31\n",
       "2008     27\n",
       "1976     22\n",
       "1977     21\n",
       "1975     14\n",
       "1974     11\n",
       "1973     11\n",
       "1970     10\n",
       "1972      9\n",
       "1971      8\n",
       "1969      7\n",
       "1968      5\n",
       "1967      4\n",
       "1965      2\n",
       "1964      2\n",
       "1963      2\n",
       "1966      2\n",
       "1956      1\n",
       "1962      1\n",
       "1950      1\n",
       "1959      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['earliest_cr_line'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd9423",
   "metadata": {
    "input_tokens": 75,
    "output_tokens": 526,
    "solveit_ai": true
   },
   "source": [
    "how How should we handle this date column? The maximum year we have is 2000, so putting the current year, 2024, doesn't make sense. What's the best strategy to handle this column and get some meaningful information out of it?\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the distribution, the credit report years range from 1950 to 2008, with most concentrated in the 1990s and early 2000s. Since this appears to be historical data, we should calculate credit age relative to a reference date that makes sense for this dataset rather than using today's date.\n",
    "\n",
    "Here are better approaches:\n",
    "\n",
    "1. Calculate credit history length relative to a reference date in the dataset:\n",
    "\n",
    "```python\n",
    "# Use the maximum date in the dataset as reference point\n",
    "max_date = df_clean['earliest_cr_line'].max()\n",
    "print(f\"Maximum credit line date: {max_date}\")\n",
    "\n",
    "# Calculate credit history length relative to this date\n",
    "df_clean['credit_history_years'] = (max_date - df_clean['earliest_cr_line']).dt.days / 365.25\n",
    "```\n",
    "\n",
    "2. Create age buckets based on the distribution:\n",
    "\n",
    "```python\n",
    "# Create credit history age bins\n",
    "df_clean['cr_age_bucket'] = pd.cut(\n",
    "    df_clean['earliest_cr_line'].dt.year,\n",
    "    bins=[1950, 1980, 1990, 1995, 2000, 2005, 2010],\n",
    "    labels=['Pre-1980', '1980s', 'Early 90s', 'Late 90s', 'Early 00s', 'Mid 00s']\n",
    ")\n",
    "```\n",
    "\n",
    "3. Calculate years since first credit:\n",
    "\n",
    "```python\n",
    "# Simple years since first credit (relative to 2008)\n",
    "reference_year = 2008\n",
    "df_clean['years_since_first_cr'] = reference_year - df_clean['earliest_cr_line'].dt.year\n",
    "```\n",
    "\n",
    "These approaches will give you meaningful features about credit history length without using today's date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d179e01b",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 208,
    "solveit_ai": true
   },
   "source": [
    "I agree lets do that...\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's implement the credit history years calculation using the reference year approach:\n",
    "\n",
    "```python\n",
    "# Use 2008 as reference year (latest in dataset)\n",
    "reference_year = 2008\n",
    "df_clean['years_since_first_cr'] = reference_year - df_clean['earliest_cr_line'].dt.year\n",
    "\n",
    "# Drop the original datetime column since we've extracted what we need\n",
    "df_clean = df_clean.drop(columns=['earliest_cr_line'])\n",
    "\n",
    "# Add the new feature to continuous columns\n",
    "cont_cols = [c for c in cont_cols if c != 'earliest_cr_line'] + ['years_since_first_cr']\n",
    "\n",
    "# Quick check of the new feature\n",
    "df_clean['years_since_first_cr'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bad66",
   "metadata": {
    "input_tokens": 36,
    "output_tokens": 46
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum credit line date: 2008-11-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "max_date = df['earliest_cr_line'].max()\n",
    "print(f\"Maximum credit line date: {max_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde4ec5",
   "metadata": {
    "input_tokens": 31
   },
   "outputs": [],
   "source": [
    "df['years_since_first_cr'] = 2008 - df['earliest_cr_line'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcccbe",
   "metadata": {
    "input_tokens": 10,
    "output_tokens": 126
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       12\n",
       "2       11\n",
       "3        5\n",
       "4        7\n",
       "        ..\n",
       "7995     6\n",
       "7996    26\n",
       "7997     5\n",
       "7998    12\n",
       "7999    14\n",
       "Name: years_since_first_cr, Length: 8000, dtype: int32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['years_since_first_cr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3b7b4",
   "metadata": {
    "input_tokens": 39,
    "output_tokens": 148
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cont_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcont_cols\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m c != \u001b[33m'\u001b[39m\u001b[33mearliest_cr_line\u001b[39m\u001b[33m'\u001b[39m] + [\u001b[33m'\u001b[39m\u001b[33myears_since_first_cr\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-d027bafe9d22>\", line 1, in <module>\n    cont_cols = [c for c in cont_cols if c != 'earliest_cr_line'] + ['years_since_first_cr']\n                            ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols = [c for c in cont_cols if c != 'earliest_cr_line'] + ['years_since_first_cr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3c0b8",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcont_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7def3622cedc>\", line 1, in <module>\n    cont_cols\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e843fe",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcat_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-44d80dea175d>\", line 1, in <module>\n    cat_cols\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882205b4",
   "metadata": {
    "input_tokens": 37,
    "output_tokens": 91,
    "solveit_ai": true
   },
   "source": [
    "drop this from cat _cols (cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code'])\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's update the categorical columns list by removing the dropped columns:\n",
    "\n",
    "```python\n",
    "cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code', 'earliest_cr_line']\n",
    "cat_cols = [col for col in cat_cols if col not in cols_to_drop]\n",
    "cat_cols\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca033af",
   "metadata": {
    "input_tokens": 66,
    "output_tokens": 211
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m cols_to_drop = [\u001b[33m'\u001b[39m\u001b[33memp_title\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNotes\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpurpose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzip_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mearliest_cr_line\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cat_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcat_cols\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cols_to_drop]\n",
      "\u001b[32m      3\u001b[39m cat_cols\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-d5713a673db1>\", line 2, in <module>\n    cat_cols = [col for col in cat_cols if col not in cols_to_drop]\n                               ^^^^^^^^\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code', 'earliest_cr_line']\n",
    "cat_cols = [col for col in cat_cols if col not in cols_to_drop]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c6ad1",
   "metadata": {
    "input_tokens": 52,
    "output_tokens": 304,
    "solveit_ai": true
   },
   "source": [
    "let wrap above steps in concise function and keep preprocess_data as seprate function only do not combine that with new function i want to call them seprate on data..\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's a concise function to handle feature engineering separately from the preprocessing:\n",
    "\n",
    "```python\n",
    "def feature_engineering(df):\n",
    "    \"Engineer new features and clean up existing ones\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop high cardinality and less useful columns\n",
    "    cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code']\n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "    \n",
    "    # Convert earliest_cr_line to credit history years\n",
    "    if 'earliest_cr_line' in df.columns:\n",
    "        df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "        reference_year = 2008\n",
    "        df['years_since_first_cr'] = reference_year - df['earliest_cr_line'].dt.year\n",
    "        df = df.drop(columns=['earliest_cr_line'])\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "This keeps it separate from your existing `preprocess_data` function and focuses only on feature engineering steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6a640",
   "metadata": {
    "input_tokens": 39,
    "output_tokens": 10,
    "solveit_ai": true
   },
   "source": [
    "pefect Remember, I don't want to merge everything. Keep the functions concise and separate. What you've done right now is perfect.\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great, I will remember that...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afeb906",
   "metadata": {
    "input_tokens": 286
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"Engineer new features and clean up existing ones\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop high cardinality and less useful columns\n",
    "    cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code','APP_ID','collections_12_mths_ex_med'] # collections_12_mths_ex_med i unique value and APP_ID(all unique)\n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "    \n",
    "    # Convert earliest_cr_line to credit history years\n",
    "    if 'earliest_cr_line' in df.columns:\n",
    "        df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "        reference_year = 2008\n",
    "        df['years_since_first_cr'] = reference_year - df['earliest_cr_line'].dt.year\n",
    "        df = df.drop(columns=['earliest_cr_line'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ba364",
   "metadata": {
    "input_tokens": 10
   },
   "outputs": [],
   "source": [
    "df= feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36346647",
   "metadata": {
    "input_tokens": 1,
    "output_tokens": 12903
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4a48d th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4a48d td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_4a48d tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_4a48d tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4a48d\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4a48d_level0_col0\" class=\"col_heading level0 col0\" >emp_length</th>\n",
       "      <th id=\"T_4a48d_level0_col1\" class=\"col_heading level0 col1\" >home_ownership</th>\n",
       "      <th id=\"T_4a48d_level0_col2\" class=\"col_heading level0 col2\" >annual_inc</th>\n",
       "      <th id=\"T_4a48d_level0_col3\" class=\"col_heading level0 col3\" >verification_status</th>\n",
       "      <th id=\"T_4a48d_level0_col4\" class=\"col_heading level0 col4\" >pymnt_plan</th>\n",
       "      <th id=\"T_4a48d_level0_col5\" class=\"col_heading level0 col5\" >purpose_cat</th>\n",
       "      <th id=\"T_4a48d_level0_col6\" class=\"col_heading level0 col6\" >addr_state</th>\n",
       "      <th id=\"T_4a48d_level0_col7\" class=\"col_heading level0 col7\" >debt_to_income</th>\n",
       "      <th id=\"T_4a48d_level0_col8\" class=\"col_heading level0 col8\" >delinq_2yrs</th>\n",
       "      <th id=\"T_4a48d_level0_col9\" class=\"col_heading level0 col9\" >inq_last_6mths</th>\n",
       "      <th id=\"T_4a48d_level0_col10\" class=\"col_heading level0 col10\" >mths_since_last_delinq</th>\n",
       "      <th id=\"T_4a48d_level0_col11\" class=\"col_heading level0 col11\" >mths_since_last_record</th>\n",
       "      <th id=\"T_4a48d_level0_col12\" class=\"col_heading level0 col12\" >open_acc</th>\n",
       "      <th id=\"T_4a48d_level0_col13\" class=\"col_heading level0 col13\" >pub_rec</th>\n",
       "      <th id=\"T_4a48d_level0_col14\" class=\"col_heading level0 col14\" >revol_bal</th>\n",
       "      <th id=\"T_4a48d_level0_col15\" class=\"col_heading level0 col15\" >revol_util</th>\n",
       "      <th id=\"T_4a48d_level0_col16\" class=\"col_heading level0 col16\" >total_acc</th>\n",
       "      <th id=\"T_4a48d_level0_col17\" class=\"col_heading level0 col17\" >initial_list_status</th>\n",
       "      <th id=\"T_4a48d_level0_col18\" class=\"col_heading level0 col18\" >mths_since_last_major_derog</th>\n",
       "      <th id=\"T_4a48d_level0_col19\" class=\"col_heading level0 col19\" >policy_code</th>\n",
       "      <th id=\"T_4a48d_level0_col20\" class=\"col_heading level0 col20\" >TARGET</th>\n",
       "      <th id=\"T_4a48d_level0_col21\" class=\"col_heading level0 col21\" >has_mths_since_last_delinq</th>\n",
       "      <th id=\"T_4a48d_level0_col22\" class=\"col_heading level0 col22\" >has_mths_since_last_record</th>\n",
       "      <th id=\"T_4a48d_level0_col23\" class=\"col_heading level0 col23\" >years_since_first_cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4a48d_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "      <td id=\"T_4a48d_row0_col1\" class=\"data row0 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_4a48d_row0_col2\" class=\"data row0 col2\" >45000.000</td>\n",
       "      <td id=\"T_4a48d_row0_col3\" class=\"data row0 col3\" >not verified</td>\n",
       "      <td id=\"T_4a48d_row0_col4\" class=\"data row0 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row0_col5\" class=\"data row0 col5\" >credit card</td>\n",
       "      <td id=\"T_4a48d_row0_col6\" class=\"data row0 col6\" >IL</td>\n",
       "      <td id=\"T_4a48d_row0_col7\" class=\"data row0 col7\" >13.950</td>\n",
       "      <td id=\"T_4a48d_row0_col8\" class=\"data row0 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row0_col9\" class=\"data row0 col9\" >1.000</td>\n",
       "      <td id=\"T_4a48d_row0_col10\" class=\"data row0 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row0_col11\" class=\"data row0 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row0_col12\" class=\"data row0 col12\" >7.000</td>\n",
       "      <td id=\"T_4a48d_row0_col13\" class=\"data row0 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row0_col14\" class=\"data row0 col14\" >10891</td>\n",
       "      <td id=\"T_4a48d_row0_col15\" class=\"data row0 col15\" >26.900</td>\n",
       "      <td id=\"T_4a48d_row0_col16\" class=\"data row0 col16\" >17.000</td>\n",
       "      <td id=\"T_4a48d_row0_col17\" class=\"data row0 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row0_col18\" class=\"data row0 col18\" >1</td>\n",
       "      <td id=\"T_4a48d_row0_col19\" class=\"data row0 col19\" >PC2</td>\n",
       "      <td id=\"T_4a48d_row0_col20\" class=\"data row0 col20\" >0</td>\n",
       "      <td id=\"T_4a48d_row0_col21\" class=\"data row0 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row0_col22\" class=\"data row0 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row0_col23\" class=\"data row0 col23\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4a48d_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_4a48d_row1_col1\" class=\"data row1 col1\" >RENT</td>\n",
       "      <td id=\"T_4a48d_row1_col2\" class=\"data row1 col2\" >51000.000</td>\n",
       "      <td id=\"T_4a48d_row1_col3\" class=\"data row1 col3\" >VERIFIED - income source</td>\n",
       "      <td id=\"T_4a48d_row1_col4\" class=\"data row1 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row1_col5\" class=\"data row1 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_4a48d_row1_col6\" class=\"data row1 col6\" >WV</td>\n",
       "      <td id=\"T_4a48d_row1_col7\" class=\"data row1 col7\" >10.540</td>\n",
       "      <td id=\"T_4a48d_row1_col8\" class=\"data row1 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row1_col9\" class=\"data row1 col9\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row1_col10\" class=\"data row1 col10\" >44.000</td>\n",
       "      <td id=\"T_4a48d_row1_col11\" class=\"data row1 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row1_col12\" class=\"data row1 col12\" >6.000</td>\n",
       "      <td id=\"T_4a48d_row1_col13\" class=\"data row1 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row1_col14\" class=\"data row1 col14\" >6342</td>\n",
       "      <td id=\"T_4a48d_row1_col15\" class=\"data row1 col15\" >64.700</td>\n",
       "      <td id=\"T_4a48d_row1_col16\" class=\"data row1 col16\" >17.000</td>\n",
       "      <td id=\"T_4a48d_row1_col17\" class=\"data row1 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row1_col18\" class=\"data row1 col18\" >1</td>\n",
       "      <td id=\"T_4a48d_row1_col19\" class=\"data row1 col19\" >PC1</td>\n",
       "      <td id=\"T_4a48d_row1_col20\" class=\"data row1 col20\" >0</td>\n",
       "      <td id=\"T_4a48d_row1_col21\" class=\"data row1 col21\" >1</td>\n",
       "      <td id=\"T_4a48d_row1_col22\" class=\"data row1 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row1_col23\" class=\"data row1 col23\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4a48d_row2_col0\" class=\"data row2 col0\" >10</td>\n",
       "      <td id=\"T_4a48d_row2_col1\" class=\"data row2 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_4a48d_row2_col2\" class=\"data row2 col2\" >75000.000</td>\n",
       "      <td id=\"T_4a48d_row2_col3\" class=\"data row2 col3\" >VERIFIED - income</td>\n",
       "      <td id=\"T_4a48d_row2_col4\" class=\"data row2 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row2_col5\" class=\"data row2 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_4a48d_row2_col6\" class=\"data row2 col6\" >NY</td>\n",
       "      <td id=\"T_4a48d_row2_col7\" class=\"data row2 col7\" >9.380</td>\n",
       "      <td id=\"T_4a48d_row2_col8\" class=\"data row2 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row2_col9\" class=\"data row2 col9\" >2.000</td>\n",
       "      <td id=\"T_4a48d_row2_col10\" class=\"data row2 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row2_col11\" class=\"data row2 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row2_col12\" class=\"data row2 col12\" >16.000</td>\n",
       "      <td id=\"T_4a48d_row2_col13\" class=\"data row2 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row2_col14\" class=\"data row2 col14\" >69461</td>\n",
       "      <td id=\"T_4a48d_row2_col15\" class=\"data row2 col15\" >47.300</td>\n",
       "      <td id=\"T_4a48d_row2_col16\" class=\"data row2 col16\" >37.000</td>\n",
       "      <td id=\"T_4a48d_row2_col17\" class=\"data row2 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row2_col18\" class=\"data row2 col18\" >2</td>\n",
       "      <td id=\"T_4a48d_row2_col19\" class=\"data row2 col19\" >PC5</td>\n",
       "      <td id=\"T_4a48d_row2_col20\" class=\"data row2 col20\" >1</td>\n",
       "      <td id=\"T_4a48d_row2_col21\" class=\"data row2 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row2_col22\" class=\"data row2 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row2_col23\" class=\"data row2 col23\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4a48d_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_4a48d_row3_col1\" class=\"data row3 col1\" >RENT</td>\n",
       "      <td id=\"T_4a48d_row3_col2\" class=\"data row3 col2\" >84000.000</td>\n",
       "      <td id=\"T_4a48d_row3_col3\" class=\"data row3 col3\" >VERIFIED - income source</td>\n",
       "      <td id=\"T_4a48d_row3_col4\" class=\"data row3 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row3_col5\" class=\"data row3 col5\" >major purchase</td>\n",
       "      <td id=\"T_4a48d_row3_col6\" class=\"data row3 col6\" >CA</td>\n",
       "      <td id=\"T_4a48d_row3_col7\" class=\"data row3 col7\" >24.060</td>\n",
       "      <td id=\"T_4a48d_row3_col8\" class=\"data row3 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row3_col9\" class=\"data row3 col9\" >2.000</td>\n",
       "      <td id=\"T_4a48d_row3_col10\" class=\"data row3 col10\" >46.000</td>\n",
       "      <td id=\"T_4a48d_row3_col11\" class=\"data row3 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row3_col12\" class=\"data row3 col12\" >5.000</td>\n",
       "      <td id=\"T_4a48d_row3_col13\" class=\"data row3 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row3_col14\" class=\"data row3 col14\" >422</td>\n",
       "      <td id=\"T_4a48d_row3_col15\" class=\"data row3 col15\" >28.100</td>\n",
       "      <td id=\"T_4a48d_row3_col16\" class=\"data row3 col16\" >7.000</td>\n",
       "      <td id=\"T_4a48d_row3_col17\" class=\"data row3 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row3_col18\" class=\"data row3 col18\" >2</td>\n",
       "      <td id=\"T_4a48d_row3_col19\" class=\"data row3 col19\" >PC2</td>\n",
       "      <td id=\"T_4a48d_row3_col20\" class=\"data row3 col20\" >1</td>\n",
       "      <td id=\"T_4a48d_row3_col21\" class=\"data row3 col21\" >1</td>\n",
       "      <td id=\"T_4a48d_row3_col22\" class=\"data row3 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row3_col23\" class=\"data row3 col23\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4a48d_row4_col0\" class=\"data row4 col0\" >1</td>\n",
       "      <td id=\"T_4a48d_row4_col1\" class=\"data row4 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_4a48d_row4_col2\" class=\"data row4 col2\" >50000.000</td>\n",
       "      <td id=\"T_4a48d_row4_col3\" class=\"data row4 col3\" >not verified</td>\n",
       "      <td id=\"T_4a48d_row4_col4\" class=\"data row4 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row4_col5\" class=\"data row4 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_4a48d_row4_col6\" class=\"data row4 col6\" >CT</td>\n",
       "      <td id=\"T_4a48d_row4_col7\" class=\"data row4 col7\" >6.720</td>\n",
       "      <td id=\"T_4a48d_row4_col8\" class=\"data row4 col8\" >1.000</td>\n",
       "      <td id=\"T_4a48d_row4_col9\" class=\"data row4 col9\" >1.000</td>\n",
       "      <td id=\"T_4a48d_row4_col10\" class=\"data row4 col10\" >22.000</td>\n",
       "      <td id=\"T_4a48d_row4_col11\" class=\"data row4 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row4_col12\" class=\"data row4 col12\" >7.000</td>\n",
       "      <td id=\"T_4a48d_row4_col13\" class=\"data row4 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row4_col14\" class=\"data row4 col14\" >11992</td>\n",
       "      <td id=\"T_4a48d_row4_col15\" class=\"data row4 col15\" >48.900</td>\n",
       "      <td id=\"T_4a48d_row4_col16\" class=\"data row4 col16\" >28.000</td>\n",
       "      <td id=\"T_4a48d_row4_col17\" class=\"data row4 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row4_col18\" class=\"data row4 col18\" >3</td>\n",
       "      <td id=\"T_4a48d_row4_col19\" class=\"data row4 col19\" >PC2</td>\n",
       "      <td id=\"T_4a48d_row4_col20\" class=\"data row4 col20\" >0</td>\n",
       "      <td id=\"T_4a48d_row4_col21\" class=\"data row4 col21\" >1</td>\n",
       "      <td id=\"T_4a48d_row4_col22\" class=\"data row4 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row4_col23\" class=\"data row4 col23\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4a48d_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_4a48d_row5_col1\" class=\"data row5 col1\" >RENT</td>\n",
       "      <td id=\"T_4a48d_row5_col2\" class=\"data row5 col2\" >41900.000</td>\n",
       "      <td id=\"T_4a48d_row5_col3\" class=\"data row5 col3\" >not verified</td>\n",
       "      <td id=\"T_4a48d_row5_col4\" class=\"data row5 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row5_col5\" class=\"data row5 col5\" >credit card</td>\n",
       "      <td id=\"T_4a48d_row5_col6\" class=\"data row5 col6\" >NY</td>\n",
       "      <td id=\"T_4a48d_row5_col7\" class=\"data row5 col7\" >12.260</td>\n",
       "      <td id=\"T_4a48d_row5_col8\" class=\"data row5 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row5_col9\" class=\"data row5 col9\" >3.000</td>\n",
       "      <td id=\"T_4a48d_row5_col10\" class=\"data row5 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row5_col11\" class=\"data row5 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row5_col12\" class=\"data row5 col12\" >12.000</td>\n",
       "      <td id=\"T_4a48d_row5_col13\" class=\"data row5 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row5_col14\" class=\"data row5 col14\" >10044</td>\n",
       "      <td id=\"T_4a48d_row5_col15\" class=\"data row5 col15\" >42.600</td>\n",
       "      <td id=\"T_4a48d_row5_col16\" class=\"data row5 col16\" >15.000</td>\n",
       "      <td id=\"T_4a48d_row5_col17\" class=\"data row5 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row5_col18\" class=\"data row5 col18\" >2</td>\n",
       "      <td id=\"T_4a48d_row5_col19\" class=\"data row5 col19\" >PC4</td>\n",
       "      <td id=\"T_4a48d_row5_col20\" class=\"data row5 col20\" >1</td>\n",
       "      <td id=\"T_4a48d_row5_col21\" class=\"data row5 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row5_col22\" class=\"data row5 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row5_col23\" class=\"data row5 col23\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4a48d_row6_col0\" class=\"data row6 col0\" >10</td>\n",
       "      <td id=\"T_4a48d_row6_col1\" class=\"data row6 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_4a48d_row6_col2\" class=\"data row6 col2\" >99996.000</td>\n",
       "      <td id=\"T_4a48d_row6_col3\" class=\"data row6 col3\" >not verified</td>\n",
       "      <td id=\"T_4a48d_row6_col4\" class=\"data row6 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row6_col5\" class=\"data row6 col5\" >car small business</td>\n",
       "      <td id=\"T_4a48d_row6_col6\" class=\"data row6 col6\" >TX</td>\n",
       "      <td id=\"T_4a48d_row6_col7\" class=\"data row6 col7\" >12.840</td>\n",
       "      <td id=\"T_4a48d_row6_col8\" class=\"data row6 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row6_col9\" class=\"data row6 col9\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row6_col10\" class=\"data row6 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row6_col11\" class=\"data row6 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row6_col12\" class=\"data row6 col12\" >7.000</td>\n",
       "      <td id=\"T_4a48d_row6_col13\" class=\"data row6 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row6_col14\" class=\"data row6 col14\" >13742</td>\n",
       "      <td id=\"T_4a48d_row6_col15\" class=\"data row6 col15\" >96.500</td>\n",
       "      <td id=\"T_4a48d_row6_col16\" class=\"data row6 col16\" >15.000</td>\n",
       "      <td id=\"T_4a48d_row6_col17\" class=\"data row6 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row6_col18\" class=\"data row6 col18\" >1</td>\n",
       "      <td id=\"T_4a48d_row6_col19\" class=\"data row6 col19\" >PC5</td>\n",
       "      <td id=\"T_4a48d_row6_col20\" class=\"data row6 col20\" >1</td>\n",
       "      <td id=\"T_4a48d_row6_col21\" class=\"data row6 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row6_col22\" class=\"data row6 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row6_col23\" class=\"data row6 col23\" >24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4a48d_row7_col0\" class=\"data row7 col0\" >5</td>\n",
       "      <td id=\"T_4a48d_row7_col1\" class=\"data row7 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_4a48d_row7_col2\" class=\"data row7 col2\" >214992.000</td>\n",
       "      <td id=\"T_4a48d_row7_col3\" class=\"data row7 col3\" >VERIFIED - income</td>\n",
       "      <td id=\"T_4a48d_row7_col4\" class=\"data row7 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row7_col5\" class=\"data row7 col5\" >debt consolidation small business</td>\n",
       "      <td id=\"T_4a48d_row7_col6\" class=\"data row7 col6\" >IL</td>\n",
       "      <td id=\"T_4a48d_row7_col7\" class=\"data row7 col7\" >5.740</td>\n",
       "      <td id=\"T_4a48d_row7_col8\" class=\"data row7 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row7_col9\" class=\"data row7 col9\" >5.000</td>\n",
       "      <td id=\"T_4a48d_row7_col10\" class=\"data row7 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row7_col11\" class=\"data row7 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row7_col12\" class=\"data row7 col12\" >9.000</td>\n",
       "      <td id=\"T_4a48d_row7_col13\" class=\"data row7 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row7_col14\" class=\"data row7 col14\" >18880</td>\n",
       "      <td id=\"T_4a48d_row7_col15\" class=\"data row7 col15\" >23.200</td>\n",
       "      <td id=\"T_4a48d_row7_col16\" class=\"data row7 col16\" >28.000</td>\n",
       "      <td id=\"T_4a48d_row7_col17\" class=\"data row7 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row7_col18\" class=\"data row7 col18\" >1</td>\n",
       "      <td id=\"T_4a48d_row7_col19\" class=\"data row7 col19\" >PC4</td>\n",
       "      <td id=\"T_4a48d_row7_col20\" class=\"data row7 col20\" >1</td>\n",
       "      <td id=\"T_4a48d_row7_col21\" class=\"data row7 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row7_col22\" class=\"data row7 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row7_col23\" class=\"data row7 col23\" >15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4a48d_row8_col0\" class=\"data row8 col0\" >7</td>\n",
       "      <td id=\"T_4a48d_row8_col1\" class=\"data row8 col1\" >RENT</td>\n",
       "      <td id=\"T_4a48d_row8_col2\" class=\"data row8 col2\" >75000.000</td>\n",
       "      <td id=\"T_4a48d_row8_col3\" class=\"data row8 col3\" >not verified</td>\n",
       "      <td id=\"T_4a48d_row8_col4\" class=\"data row8 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row8_col5\" class=\"data row8 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_4a48d_row8_col6\" class=\"data row8 col6\" >TX</td>\n",
       "      <td id=\"T_4a48d_row8_col7\" class=\"data row8 col7\" >17.580</td>\n",
       "      <td id=\"T_4a48d_row8_col8\" class=\"data row8 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row8_col9\" class=\"data row8 col9\" >1.000</td>\n",
       "      <td id=\"T_4a48d_row8_col10\" class=\"data row8 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row8_col11\" class=\"data row8 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row8_col12\" class=\"data row8 col12\" >10.000</td>\n",
       "      <td id=\"T_4a48d_row8_col13\" class=\"data row8 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row8_col14\" class=\"data row8 col14\" >630</td>\n",
       "      <td id=\"T_4a48d_row8_col15\" class=\"data row8 col15\" >2.200</td>\n",
       "      <td id=\"T_4a48d_row8_col16\" class=\"data row8 col16\" >15.000</td>\n",
       "      <td id=\"T_4a48d_row8_col17\" class=\"data row8 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row8_col18\" class=\"data row8 col18\" >2</td>\n",
       "      <td id=\"T_4a48d_row8_col19\" class=\"data row8 col19\" >PC1</td>\n",
       "      <td id=\"T_4a48d_row8_col20\" class=\"data row8 col20\" >0</td>\n",
       "      <td id=\"T_4a48d_row8_col21\" class=\"data row8 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row8_col22\" class=\"data row8 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row8_col23\" class=\"data row8 col23\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a48d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4a48d_row9_col0\" class=\"data row9 col0\" >1</td>\n",
       "      <td id=\"T_4a48d_row9_col1\" class=\"data row9 col1\" >RENT</td>\n",
       "      <td id=\"T_4a48d_row9_col2\" class=\"data row9 col2\" >32400.000</td>\n",
       "      <td id=\"T_4a48d_row9_col3\" class=\"data row9 col3\" >VERIFIED - income source</td>\n",
       "      <td id=\"T_4a48d_row9_col4\" class=\"data row9 col4\" >n</td>\n",
       "      <td id=\"T_4a48d_row9_col5\" class=\"data row9 col5\" >small business</td>\n",
       "      <td id=\"T_4a48d_row9_col6\" class=\"data row9 col6\" >OH</td>\n",
       "      <td id=\"T_4a48d_row9_col7\" class=\"data row9 col7\" >13.410</td>\n",
       "      <td id=\"T_4a48d_row9_col8\" class=\"data row9 col8\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row9_col9\" class=\"data row9 col9\" >3.000</td>\n",
       "      <td id=\"T_4a48d_row9_col10\" class=\"data row9 col10\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row9_col11\" class=\"data row9 col11\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row9_col12\" class=\"data row9 col12\" >6.000</td>\n",
       "      <td id=\"T_4a48d_row9_col13\" class=\"data row9 col13\" >0.000</td>\n",
       "      <td id=\"T_4a48d_row9_col14\" class=\"data row9 col14\" >6514</td>\n",
       "      <td id=\"T_4a48d_row9_col15\" class=\"data row9 col15\" >57.100</td>\n",
       "      <td id=\"T_4a48d_row9_col16\" class=\"data row9 col16\" >10.000</td>\n",
       "      <td id=\"T_4a48d_row9_col17\" class=\"data row9 col17\" >f</td>\n",
       "      <td id=\"T_4a48d_row9_col18\" class=\"data row9 col18\" >3</td>\n",
       "      <td id=\"T_4a48d_row9_col19\" class=\"data row9 col19\" >PC5</td>\n",
       "      <td id=\"T_4a48d_row9_col20\" class=\"data row9 col20\" >0</td>\n",
       "      <td id=\"T_4a48d_row9_col21\" class=\"data row9 col21\" >0</td>\n",
       "      <td id=\"T_4a48d_row9_col22\" class=\"data row9 col22\" >0</td>\n",
       "      <td id=\"T_4a48d_row9_col23\" class=\"data row9 col23\" >11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "     emp_length  ... years_since_first_cr\n",
       "0             9  ...                    9\n",
       "1             2  ...                   12\n",
       "2            10  ...                   11\n",
       "3             3  ...                    5\n",
       "4             1  ...                    7\n",
       "...         ...  ...                  ...\n",
       "7995          1  ...                    6\n",
       "7996          5  ...                   26\n",
       "7997          5  ...                    5\n",
       "7998          5  ...                   12\n",
       "7999          6  ...                   14\n",
       "\n",
       "[8000 rows x 24 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a3a46",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `cont_cat_split` not found.\n"
     ]
    }
   ],
   "source": [
    "cont_cat_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609716e",
   "metadata": {
    "input_tokens": 24,
    "output_tokens": 123
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cont_cols,cat_cols = \u001b[43mcont_cat_split\u001b[49m(df,dep_var=\u001b[33m'\u001b[39m\u001b[33mTARGET\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cat_split' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cat_split' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-c813cb97c04f>\", line 1, in <module>\n    cont_cols,cat_cols = cont_cat_split(df,dep_var='TARGET')\n                         ^^^^^^^^^^^^^^\n",
      "NameError: name 'cont_cat_split' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols,cat_cols = cont_cat_split(df,dep_var='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf0ecc",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcont_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7def3622cedc>\", line 1, in <module>\n    cont_cols\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dec74",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcat_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-44d80dea175d>\", line 1, in <module>\n    cat_cols\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db137fe",
   "metadata": {
    "input_tokens": 7,
    "output_tokens": 94
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcont_cols\u001b[49m]\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7fdd6864603c>\", line 1, in <module>\n    df[cont_cols]\n       ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca41a72",
   "metadata": {
    "input_tokens": 15,
    "output_tokens": 102
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcont_cols\u001b[49m].isna().sum()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-a10fa2eb69bf>\", line 1, in <module>\n    df[cont_cols].isna().sum()\n       ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cont_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98ef8e",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 99
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcont_cols\u001b[49m].nunique()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7918a45abe66>\", line 1, in <module>\n    df[cont_cols].nunique()\n       ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cont_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa9c1e",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 97
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcont_cols\u001b[49m].describe()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-1e15979ca001>\", line 1, in <module>\n    df[cont_cols].describe()\n       ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df[cont_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c02705",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 814
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'APP_ID'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAPP_ID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.unique())\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n",
      "\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n",
      "\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n",
      "\u001b[32m   3810\u001b[39m     ):\n",
      "\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'APP_ID'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'APP_ID'",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'APP_ID'\n",
      "\nThe above exception was the direct cause of the following exception:\n\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-1840dc6c6c3e>\", line 1, in <module>\n    len(df['APP_ID'].unique())\n        ~~^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/frame.py\", line 4102, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\n",
      "KeyError: 'APP_ID'\n"
     ]
    }
   ],
   "source": [
    "len(df['APP_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8469cf",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 75
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pub_rec\n",
       "0.0    7562\n",
       "1.0     419\n",
       "2.0      14\n",
       "3.0       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pub_rec'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41310c3",
   "metadata": {
    "input_tokens": 172,
    "output_tokens": 526,
    "solveit_ai": true
   },
   "source": [
    "For columns like `delinq_2yrs`, `pub_rec`, `collections_12`, `open_acc_6m`, and `inq_last_6m`, the cardinality is too low. For example, `delinq_2yrs` represents delinquencies in the last two years, `pub_rec` is the number of public records, and `collections_12` is the number of collections in the last 12 months.\n",
    "\n",
    "Given the low cardinality, should we treat these as continuous or convert them to categorical features? What's the best strategy here?\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "For low cardinality numeric features like these, there are two reasonable approaches:\n",
    "\n",
    "1. Keep them as continuous features, which preserves their numerical relationships\n",
    "2. Convert them to categorical features, which can capture non-linear patterns\n",
    "\n",
    "Here's my recommendation for each column:\n",
    "\n",
    "**Convert to categorical:**\n",
    "- `pub_rec` (4 values): The difference between 0, 1, 2, and 3 public records may not be linear in terms of risk\n",
    "- `collections_12_mths_ex_med` (1 value): This has only one value (0) so it's not providing any information - consider dropping it\n",
    "\n",
    "**Keep as continuous:**\n",
    "- `delinq_2yrs` (10 values): While it has low cardinality, there's likely a continuous relationship between number of delinquencies and default risk\n",
    "- `inq_last_6mths` (18 values): The relationship between inquiries and risk is likely somewhat linear\n",
    "- `open_acc` (35 values): This has enough values to be treated as continuous\n",
    "\n",
    "For the ones we convert to categorical, we can do:\n",
    "\n",
    "```python\n",
    "# Convert selected low-cardinality features to categorical\n",
    "for col in ['pub_rec']:\n",
    "    df[f'{col}_cat'] = df[col].astype('category')\n",
    "    cat_cols.append(f'{col}_cat')\n",
    "\n",
    "# Drop collections_12_mths_ex_med since it has only one value\n",
    "if 'collections_12_mths_ex_med' in cont_cols:\n",
    "    cont_cols.remove('collections_12_mths_ex_med')\n",
    "```\n",
    "\n",
    "This balanced approach gives us the best of both worlds - preserving the numerical relationships where they make sense while allowing the model to learn non-linear patterns for features where the numerical relationship might not be strictly linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb6a51b",
   "metadata": {
    "input_tokens": 19,
    "output_tokens": 837
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'collections_12_mths_ex_med'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcollections_12_mths_ex_med\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n",
      "\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n",
      "\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n",
      "\u001b[32m   3810\u001b[39m     ):\n",
      "\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'collections_12_mths_ex_med'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'collections_12_mths_ex_med'",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'collections_12_mths_ex_med'\n",
      "\nThe above exception was the direct cause of the following exception:\n\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-084a13365268>\", line 1, in <module>\n    df['collections_12_mths_ex_med'].value_counts()\n    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/frame.py\", line 4102, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\n",
      "KeyError: 'collections_12_mths_ex_med'\n"
     ]
    }
   ],
   "source": [
    "df['collections_12_mths_ex_med'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188fea43",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 75
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pub_rec\n",
       "0.0    7562\n",
       "1.0     419\n",
       "2.0      14\n",
       "3.0       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pub_rec'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b861f",
   "metadata": {
    "input_tokens": 16,
    "output_tokens": 142
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delinq_2yrs\n",
       "0.0     7120\n",
       "1.0      666\n",
       "2.0      148\n",
       "3.0       42\n",
       "4.0       13\n",
       "5.0        5\n",
       "6.0        2\n",
       "7.0        2\n",
       "8.0        1\n",
       "11.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['delinq_2yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d51f1",
   "metadata": {
    "input_tokens": 18,
    "output_tokens": 231
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inq_last_6mths\n",
       "0.0     3690\n",
       "1.0     2143\n",
       "2.0     1134\n",
       "3.0      592\n",
       "4.0      181\n",
       "5.0      123\n",
       "6.0       60\n",
       "7.0       34\n",
       "8.0       22\n",
       "9.0       10\n",
       "18.0       2\n",
       "10.0       2\n",
       "11.0       2\n",
       "16.0       1\n",
       "25.0       1\n",
       "24.0       1\n",
       "14.0       1\n",
       "12.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inq_last_6mths'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a32339",
   "metadata": {
    "input_tokens": 13,
    "output_tokens": 399
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_acc\n",
       "7.0     830\n",
       "6.0     789\n",
       "8.0     745\n",
       "9.0     742\n",
       "10.0    633\n",
       "5.0     612\n",
       "11.0    554\n",
       "4.0     509\n",
       "12.0    474\n",
       "13.0    396\n",
       "3.0     294\n",
       "14.0    280\n",
       "15.0    252\n",
       "16.0    180\n",
       "17.0    144\n",
       "2.0     125\n",
       "18.0    107\n",
       "19.0     85\n",
       "20.0     61\n",
       "21.0     58\n",
       "22.0     29\n",
       "23.0     28\n",
       "25.0     19\n",
       "24.0     12\n",
       "26.0      7\n",
       "1.0       7\n",
       "27.0      6\n",
       "30.0      6\n",
       "28.0      5\n",
       "29.0      3\n",
       "31.0      2\n",
       "33.0      2\n",
       "36.0      2\n",
       "35.0      1\n",
       "32.0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['open_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e42687",
   "metadata": {
    "input_tokens": 49,
    "output_tokens": 190
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mpub_rec\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[32m      2\u001b[39m     df[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_cat\u001b[39m\u001b[33m'\u001b[39m] = df[col].astype(\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcat_cols\u001b[49m.append(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_cat\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-9ad56e947d0f>\", line 3, in <module>\n    cat_cols.append(f'{col}_cat')\n    ^^^^^^^^\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "for col in ['pub_rec']:\n",
    "    df[f'{col}_cat'] = df[col].astype('category')\n",
    "    cat_cols.append(f'{col}_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c1196",
   "metadata": {
    "input_tokens": 1,
    "output_tokens": 12981
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_faefc th {\n",
       "  font-weight: bold;\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "  padding: 10px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_faefc td {\n",
       "  padding: 8px;\n",
       "  border-bottom: 1px solid #ddd;\n",
       "}\n",
       "#T_faefc tr:nth-child(even) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_faefc tr:hover {\n",
       "  background-color: #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_faefc\" class=\"dataframe\" style=\"width:100%; border-collapse: collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_faefc_level0_col0\" class=\"col_heading level0 col0\" >emp_length</th>\n",
       "      <th id=\"T_faefc_level0_col1\" class=\"col_heading level0 col1\" >home_ownership</th>\n",
       "      <th id=\"T_faefc_level0_col2\" class=\"col_heading level0 col2\" >annual_inc</th>\n",
       "      <th id=\"T_faefc_level0_col3\" class=\"col_heading level0 col3\" >verification_status</th>\n",
       "      <th id=\"T_faefc_level0_col4\" class=\"col_heading level0 col4\" >pymnt_plan</th>\n",
       "      <th id=\"T_faefc_level0_col5\" class=\"col_heading level0 col5\" >purpose_cat</th>\n",
       "      <th id=\"T_faefc_level0_col6\" class=\"col_heading level0 col6\" >addr_state</th>\n",
       "      <th id=\"T_faefc_level0_col7\" class=\"col_heading level0 col7\" >debt_to_income</th>\n",
       "      <th id=\"T_faefc_level0_col8\" class=\"col_heading level0 col8\" >delinq_2yrs</th>\n",
       "      <th id=\"T_faefc_level0_col9\" class=\"col_heading level0 col9\" >inq_last_6mths</th>\n",
       "      <th id=\"T_faefc_level0_col10\" class=\"col_heading level0 col10\" >mths_since_last_delinq</th>\n",
       "      <th id=\"T_faefc_level0_col11\" class=\"col_heading level0 col11\" >mths_since_last_record</th>\n",
       "      <th id=\"T_faefc_level0_col12\" class=\"col_heading level0 col12\" >open_acc</th>\n",
       "      <th id=\"T_faefc_level0_col13\" class=\"col_heading level0 col13\" >pub_rec</th>\n",
       "      <th id=\"T_faefc_level0_col14\" class=\"col_heading level0 col14\" >revol_bal</th>\n",
       "      <th id=\"T_faefc_level0_col15\" class=\"col_heading level0 col15\" >revol_util</th>\n",
       "      <th id=\"T_faefc_level0_col16\" class=\"col_heading level0 col16\" >total_acc</th>\n",
       "      <th id=\"T_faefc_level0_col17\" class=\"col_heading level0 col17\" >initial_list_status</th>\n",
       "      <th id=\"T_faefc_level0_col18\" class=\"col_heading level0 col18\" >mths_since_last_major_derog</th>\n",
       "      <th id=\"T_faefc_level0_col19\" class=\"col_heading level0 col19\" >policy_code</th>\n",
       "      <th id=\"T_faefc_level0_col20\" class=\"col_heading level0 col20\" >TARGET</th>\n",
       "      <th id=\"T_faefc_level0_col21\" class=\"col_heading level0 col21\" >has_mths_since_last_delinq</th>\n",
       "      <th id=\"T_faefc_level0_col22\" class=\"col_heading level0 col22\" >has_mths_since_last_record</th>\n",
       "      <th id=\"T_faefc_level0_col23\" class=\"col_heading level0 col23\" >years_since_first_cr</th>\n",
       "      <th id=\"T_faefc_level0_col24\" class=\"col_heading level0 col24\" >pub_rec_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_faefc_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "      <td id=\"T_faefc_row0_col1\" class=\"data row0 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_faefc_row0_col2\" class=\"data row0 col2\" >45000.000</td>\n",
       "      <td id=\"T_faefc_row0_col3\" class=\"data row0 col3\" >not verified</td>\n",
       "      <td id=\"T_faefc_row0_col4\" class=\"data row0 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row0_col5\" class=\"data row0 col5\" >credit card</td>\n",
       "      <td id=\"T_faefc_row0_col6\" class=\"data row0 col6\" >IL</td>\n",
       "      <td id=\"T_faefc_row0_col7\" class=\"data row0 col7\" >13.950</td>\n",
       "      <td id=\"T_faefc_row0_col8\" class=\"data row0 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row0_col9\" class=\"data row0 col9\" >1.000</td>\n",
       "      <td id=\"T_faefc_row0_col10\" class=\"data row0 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row0_col11\" class=\"data row0 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row0_col12\" class=\"data row0 col12\" >7.000</td>\n",
       "      <td id=\"T_faefc_row0_col13\" class=\"data row0 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row0_col14\" class=\"data row0 col14\" >10891</td>\n",
       "      <td id=\"T_faefc_row0_col15\" class=\"data row0 col15\" >26.900</td>\n",
       "      <td id=\"T_faefc_row0_col16\" class=\"data row0 col16\" >17.000</td>\n",
       "      <td id=\"T_faefc_row0_col17\" class=\"data row0 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row0_col18\" class=\"data row0 col18\" >1</td>\n",
       "      <td id=\"T_faefc_row0_col19\" class=\"data row0 col19\" >PC2</td>\n",
       "      <td id=\"T_faefc_row0_col20\" class=\"data row0 col20\" >0</td>\n",
       "      <td id=\"T_faefc_row0_col21\" class=\"data row0 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row0_col22\" class=\"data row0 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row0_col23\" class=\"data row0 col23\" >9</td>\n",
       "      <td id=\"T_faefc_row0_col24\" class=\"data row0 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_faefc_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_faefc_row1_col1\" class=\"data row1 col1\" >RENT</td>\n",
       "      <td id=\"T_faefc_row1_col2\" class=\"data row1 col2\" >51000.000</td>\n",
       "      <td id=\"T_faefc_row1_col3\" class=\"data row1 col3\" >VERIFIED - income source</td>\n",
       "      <td id=\"T_faefc_row1_col4\" class=\"data row1 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row1_col5\" class=\"data row1 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_faefc_row1_col6\" class=\"data row1 col6\" >WV</td>\n",
       "      <td id=\"T_faefc_row1_col7\" class=\"data row1 col7\" >10.540</td>\n",
       "      <td id=\"T_faefc_row1_col8\" class=\"data row1 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row1_col9\" class=\"data row1 col9\" >0.000</td>\n",
       "      <td id=\"T_faefc_row1_col10\" class=\"data row1 col10\" >44.000</td>\n",
       "      <td id=\"T_faefc_row1_col11\" class=\"data row1 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row1_col12\" class=\"data row1 col12\" >6.000</td>\n",
       "      <td id=\"T_faefc_row1_col13\" class=\"data row1 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row1_col14\" class=\"data row1 col14\" >6342</td>\n",
       "      <td id=\"T_faefc_row1_col15\" class=\"data row1 col15\" >64.700</td>\n",
       "      <td id=\"T_faefc_row1_col16\" class=\"data row1 col16\" >17.000</td>\n",
       "      <td id=\"T_faefc_row1_col17\" class=\"data row1 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row1_col18\" class=\"data row1 col18\" >1</td>\n",
       "      <td id=\"T_faefc_row1_col19\" class=\"data row1 col19\" >PC1</td>\n",
       "      <td id=\"T_faefc_row1_col20\" class=\"data row1 col20\" >0</td>\n",
       "      <td id=\"T_faefc_row1_col21\" class=\"data row1 col21\" >1</td>\n",
       "      <td id=\"T_faefc_row1_col22\" class=\"data row1 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row1_col23\" class=\"data row1 col23\" >12</td>\n",
       "      <td id=\"T_faefc_row1_col24\" class=\"data row1 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_faefc_row2_col0\" class=\"data row2 col0\" >10</td>\n",
       "      <td id=\"T_faefc_row2_col1\" class=\"data row2 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_faefc_row2_col2\" class=\"data row2 col2\" >75000.000</td>\n",
       "      <td id=\"T_faefc_row2_col3\" class=\"data row2 col3\" >VERIFIED - income</td>\n",
       "      <td id=\"T_faefc_row2_col4\" class=\"data row2 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row2_col5\" class=\"data row2 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_faefc_row2_col6\" class=\"data row2 col6\" >NY</td>\n",
       "      <td id=\"T_faefc_row2_col7\" class=\"data row2 col7\" >9.380</td>\n",
       "      <td id=\"T_faefc_row2_col8\" class=\"data row2 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row2_col9\" class=\"data row2 col9\" >2.000</td>\n",
       "      <td id=\"T_faefc_row2_col10\" class=\"data row2 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row2_col11\" class=\"data row2 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row2_col12\" class=\"data row2 col12\" >16.000</td>\n",
       "      <td id=\"T_faefc_row2_col13\" class=\"data row2 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row2_col14\" class=\"data row2 col14\" >69461</td>\n",
       "      <td id=\"T_faefc_row2_col15\" class=\"data row2 col15\" >47.300</td>\n",
       "      <td id=\"T_faefc_row2_col16\" class=\"data row2 col16\" >37.000</td>\n",
       "      <td id=\"T_faefc_row2_col17\" class=\"data row2 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row2_col18\" class=\"data row2 col18\" >2</td>\n",
       "      <td id=\"T_faefc_row2_col19\" class=\"data row2 col19\" >PC5</td>\n",
       "      <td id=\"T_faefc_row2_col20\" class=\"data row2 col20\" >1</td>\n",
       "      <td id=\"T_faefc_row2_col21\" class=\"data row2 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row2_col22\" class=\"data row2 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row2_col23\" class=\"data row2 col23\" >11</td>\n",
       "      <td id=\"T_faefc_row2_col24\" class=\"data row2 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_faefc_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_faefc_row3_col1\" class=\"data row3 col1\" >RENT</td>\n",
       "      <td id=\"T_faefc_row3_col2\" class=\"data row3 col2\" >84000.000</td>\n",
       "      <td id=\"T_faefc_row3_col3\" class=\"data row3 col3\" >VERIFIED - income source</td>\n",
       "      <td id=\"T_faefc_row3_col4\" class=\"data row3 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row3_col5\" class=\"data row3 col5\" >major purchase</td>\n",
       "      <td id=\"T_faefc_row3_col6\" class=\"data row3 col6\" >CA</td>\n",
       "      <td id=\"T_faefc_row3_col7\" class=\"data row3 col7\" >24.060</td>\n",
       "      <td id=\"T_faefc_row3_col8\" class=\"data row3 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row3_col9\" class=\"data row3 col9\" >2.000</td>\n",
       "      <td id=\"T_faefc_row3_col10\" class=\"data row3 col10\" >46.000</td>\n",
       "      <td id=\"T_faefc_row3_col11\" class=\"data row3 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row3_col12\" class=\"data row3 col12\" >5.000</td>\n",
       "      <td id=\"T_faefc_row3_col13\" class=\"data row3 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row3_col14\" class=\"data row3 col14\" >422</td>\n",
       "      <td id=\"T_faefc_row3_col15\" class=\"data row3 col15\" >28.100</td>\n",
       "      <td id=\"T_faefc_row3_col16\" class=\"data row3 col16\" >7.000</td>\n",
       "      <td id=\"T_faefc_row3_col17\" class=\"data row3 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row3_col18\" class=\"data row3 col18\" >2</td>\n",
       "      <td id=\"T_faefc_row3_col19\" class=\"data row3 col19\" >PC2</td>\n",
       "      <td id=\"T_faefc_row3_col20\" class=\"data row3 col20\" >1</td>\n",
       "      <td id=\"T_faefc_row3_col21\" class=\"data row3 col21\" >1</td>\n",
       "      <td id=\"T_faefc_row3_col22\" class=\"data row3 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row3_col23\" class=\"data row3 col23\" >5</td>\n",
       "      <td id=\"T_faefc_row3_col24\" class=\"data row3 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_faefc_row4_col0\" class=\"data row4 col0\" >1</td>\n",
       "      <td id=\"T_faefc_row4_col1\" class=\"data row4 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_faefc_row4_col2\" class=\"data row4 col2\" >50000.000</td>\n",
       "      <td id=\"T_faefc_row4_col3\" class=\"data row4 col3\" >not verified</td>\n",
       "      <td id=\"T_faefc_row4_col4\" class=\"data row4 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row4_col5\" class=\"data row4 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_faefc_row4_col6\" class=\"data row4 col6\" >CT</td>\n",
       "      <td id=\"T_faefc_row4_col7\" class=\"data row4 col7\" >6.720</td>\n",
       "      <td id=\"T_faefc_row4_col8\" class=\"data row4 col8\" >1.000</td>\n",
       "      <td id=\"T_faefc_row4_col9\" class=\"data row4 col9\" >1.000</td>\n",
       "      <td id=\"T_faefc_row4_col10\" class=\"data row4 col10\" >22.000</td>\n",
       "      <td id=\"T_faefc_row4_col11\" class=\"data row4 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row4_col12\" class=\"data row4 col12\" >7.000</td>\n",
       "      <td id=\"T_faefc_row4_col13\" class=\"data row4 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row4_col14\" class=\"data row4 col14\" >11992</td>\n",
       "      <td id=\"T_faefc_row4_col15\" class=\"data row4 col15\" >48.900</td>\n",
       "      <td id=\"T_faefc_row4_col16\" class=\"data row4 col16\" >28.000</td>\n",
       "      <td id=\"T_faefc_row4_col17\" class=\"data row4 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row4_col18\" class=\"data row4 col18\" >3</td>\n",
       "      <td id=\"T_faefc_row4_col19\" class=\"data row4 col19\" >PC2</td>\n",
       "      <td id=\"T_faefc_row4_col20\" class=\"data row4 col20\" >0</td>\n",
       "      <td id=\"T_faefc_row4_col21\" class=\"data row4 col21\" >1</td>\n",
       "      <td id=\"T_faefc_row4_col22\" class=\"data row4 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row4_col23\" class=\"data row4 col23\" >7</td>\n",
       "      <td id=\"T_faefc_row4_col24\" class=\"data row4 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_faefc_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_faefc_row5_col1\" class=\"data row5 col1\" >RENT</td>\n",
       "      <td id=\"T_faefc_row5_col2\" class=\"data row5 col2\" >41900.000</td>\n",
       "      <td id=\"T_faefc_row5_col3\" class=\"data row5 col3\" >not verified</td>\n",
       "      <td id=\"T_faefc_row5_col4\" class=\"data row5 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row5_col5\" class=\"data row5 col5\" >credit card</td>\n",
       "      <td id=\"T_faefc_row5_col6\" class=\"data row5 col6\" >NY</td>\n",
       "      <td id=\"T_faefc_row5_col7\" class=\"data row5 col7\" >12.260</td>\n",
       "      <td id=\"T_faefc_row5_col8\" class=\"data row5 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row5_col9\" class=\"data row5 col9\" >3.000</td>\n",
       "      <td id=\"T_faefc_row5_col10\" class=\"data row5 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row5_col11\" class=\"data row5 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row5_col12\" class=\"data row5 col12\" >12.000</td>\n",
       "      <td id=\"T_faefc_row5_col13\" class=\"data row5 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row5_col14\" class=\"data row5 col14\" >10044</td>\n",
       "      <td id=\"T_faefc_row5_col15\" class=\"data row5 col15\" >42.600</td>\n",
       "      <td id=\"T_faefc_row5_col16\" class=\"data row5 col16\" >15.000</td>\n",
       "      <td id=\"T_faefc_row5_col17\" class=\"data row5 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row5_col18\" class=\"data row5 col18\" >2</td>\n",
       "      <td id=\"T_faefc_row5_col19\" class=\"data row5 col19\" >PC4</td>\n",
       "      <td id=\"T_faefc_row5_col20\" class=\"data row5 col20\" >1</td>\n",
       "      <td id=\"T_faefc_row5_col21\" class=\"data row5 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row5_col22\" class=\"data row5 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row5_col23\" class=\"data row5 col23\" >2</td>\n",
       "      <td id=\"T_faefc_row5_col24\" class=\"data row5 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_faefc_row6_col0\" class=\"data row6 col0\" >10</td>\n",
       "      <td id=\"T_faefc_row6_col1\" class=\"data row6 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_faefc_row6_col2\" class=\"data row6 col2\" >99996.000</td>\n",
       "      <td id=\"T_faefc_row6_col3\" class=\"data row6 col3\" >not verified</td>\n",
       "      <td id=\"T_faefc_row6_col4\" class=\"data row6 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row6_col5\" class=\"data row6 col5\" >car small business</td>\n",
       "      <td id=\"T_faefc_row6_col6\" class=\"data row6 col6\" >TX</td>\n",
       "      <td id=\"T_faefc_row6_col7\" class=\"data row6 col7\" >12.840</td>\n",
       "      <td id=\"T_faefc_row6_col8\" class=\"data row6 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row6_col9\" class=\"data row6 col9\" >0.000</td>\n",
       "      <td id=\"T_faefc_row6_col10\" class=\"data row6 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row6_col11\" class=\"data row6 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row6_col12\" class=\"data row6 col12\" >7.000</td>\n",
       "      <td id=\"T_faefc_row6_col13\" class=\"data row6 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row6_col14\" class=\"data row6 col14\" >13742</td>\n",
       "      <td id=\"T_faefc_row6_col15\" class=\"data row6 col15\" >96.500</td>\n",
       "      <td id=\"T_faefc_row6_col16\" class=\"data row6 col16\" >15.000</td>\n",
       "      <td id=\"T_faefc_row6_col17\" class=\"data row6 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row6_col18\" class=\"data row6 col18\" >1</td>\n",
       "      <td id=\"T_faefc_row6_col19\" class=\"data row6 col19\" >PC5</td>\n",
       "      <td id=\"T_faefc_row6_col20\" class=\"data row6 col20\" >1</td>\n",
       "      <td id=\"T_faefc_row6_col21\" class=\"data row6 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row6_col22\" class=\"data row6 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row6_col23\" class=\"data row6 col23\" >24</td>\n",
       "      <td id=\"T_faefc_row6_col24\" class=\"data row6 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_faefc_row7_col0\" class=\"data row7 col0\" >5</td>\n",
       "      <td id=\"T_faefc_row7_col1\" class=\"data row7 col1\" >MORTGAGE</td>\n",
       "      <td id=\"T_faefc_row7_col2\" class=\"data row7 col2\" >214992.000</td>\n",
       "      <td id=\"T_faefc_row7_col3\" class=\"data row7 col3\" >VERIFIED - income</td>\n",
       "      <td id=\"T_faefc_row7_col4\" class=\"data row7 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row7_col5\" class=\"data row7 col5\" >debt consolidation small business</td>\n",
       "      <td id=\"T_faefc_row7_col6\" class=\"data row7 col6\" >IL</td>\n",
       "      <td id=\"T_faefc_row7_col7\" class=\"data row7 col7\" >5.740</td>\n",
       "      <td id=\"T_faefc_row7_col8\" class=\"data row7 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row7_col9\" class=\"data row7 col9\" >5.000</td>\n",
       "      <td id=\"T_faefc_row7_col10\" class=\"data row7 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row7_col11\" class=\"data row7 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row7_col12\" class=\"data row7 col12\" >9.000</td>\n",
       "      <td id=\"T_faefc_row7_col13\" class=\"data row7 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row7_col14\" class=\"data row7 col14\" >18880</td>\n",
       "      <td id=\"T_faefc_row7_col15\" class=\"data row7 col15\" >23.200</td>\n",
       "      <td id=\"T_faefc_row7_col16\" class=\"data row7 col16\" >28.000</td>\n",
       "      <td id=\"T_faefc_row7_col17\" class=\"data row7 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row7_col18\" class=\"data row7 col18\" >1</td>\n",
       "      <td id=\"T_faefc_row7_col19\" class=\"data row7 col19\" >PC4</td>\n",
       "      <td id=\"T_faefc_row7_col20\" class=\"data row7 col20\" >1</td>\n",
       "      <td id=\"T_faefc_row7_col21\" class=\"data row7 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row7_col22\" class=\"data row7 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row7_col23\" class=\"data row7 col23\" >15</td>\n",
       "      <td id=\"T_faefc_row7_col24\" class=\"data row7 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_faefc_row8_col0\" class=\"data row8 col0\" >7</td>\n",
       "      <td id=\"T_faefc_row8_col1\" class=\"data row8 col1\" >RENT</td>\n",
       "      <td id=\"T_faefc_row8_col2\" class=\"data row8 col2\" >75000.000</td>\n",
       "      <td id=\"T_faefc_row8_col3\" class=\"data row8 col3\" >not verified</td>\n",
       "      <td id=\"T_faefc_row8_col4\" class=\"data row8 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row8_col5\" class=\"data row8 col5\" >debt consolidation</td>\n",
       "      <td id=\"T_faefc_row8_col6\" class=\"data row8 col6\" >TX</td>\n",
       "      <td id=\"T_faefc_row8_col7\" class=\"data row8 col7\" >17.580</td>\n",
       "      <td id=\"T_faefc_row8_col8\" class=\"data row8 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row8_col9\" class=\"data row8 col9\" >1.000</td>\n",
       "      <td id=\"T_faefc_row8_col10\" class=\"data row8 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row8_col11\" class=\"data row8 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row8_col12\" class=\"data row8 col12\" >10.000</td>\n",
       "      <td id=\"T_faefc_row8_col13\" class=\"data row8 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row8_col14\" class=\"data row8 col14\" >630</td>\n",
       "      <td id=\"T_faefc_row8_col15\" class=\"data row8 col15\" >2.200</td>\n",
       "      <td id=\"T_faefc_row8_col16\" class=\"data row8 col16\" >15.000</td>\n",
       "      <td id=\"T_faefc_row8_col17\" class=\"data row8 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row8_col18\" class=\"data row8 col18\" >2</td>\n",
       "      <td id=\"T_faefc_row8_col19\" class=\"data row8 col19\" >PC1</td>\n",
       "      <td id=\"T_faefc_row8_col20\" class=\"data row8 col20\" >0</td>\n",
       "      <td id=\"T_faefc_row8_col21\" class=\"data row8 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row8_col22\" class=\"data row8 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row8_col23\" class=\"data row8 col23\" >3</td>\n",
       "      <td id=\"T_faefc_row8_col24\" class=\"data row8 col24\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_faefc_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_faefc_row9_col0\" class=\"data row9 col0\" >1</td>\n",
       "      <td id=\"T_faefc_row9_col1\" class=\"data row9 col1\" >RENT</td>\n",
       "      <td id=\"T_faefc_row9_col2\" class=\"data row9 col2\" >32400.000</td>\n",
       "      <td id=\"T_faefc_row9_col3\" class=\"data row9 col3\" >VERIFIED - income source</td>\n",
       "      <td id=\"T_faefc_row9_col4\" class=\"data row9 col4\" >n</td>\n",
       "      <td id=\"T_faefc_row9_col5\" class=\"data row9 col5\" >small business</td>\n",
       "      <td id=\"T_faefc_row9_col6\" class=\"data row9 col6\" >OH</td>\n",
       "      <td id=\"T_faefc_row9_col7\" class=\"data row9 col7\" >13.410</td>\n",
       "      <td id=\"T_faefc_row9_col8\" class=\"data row9 col8\" >0.000</td>\n",
       "      <td id=\"T_faefc_row9_col9\" class=\"data row9 col9\" >3.000</td>\n",
       "      <td id=\"T_faefc_row9_col10\" class=\"data row9 col10\" >0.000</td>\n",
       "      <td id=\"T_faefc_row9_col11\" class=\"data row9 col11\" >0.000</td>\n",
       "      <td id=\"T_faefc_row9_col12\" class=\"data row9 col12\" >6.000</td>\n",
       "      <td id=\"T_faefc_row9_col13\" class=\"data row9 col13\" >0.000</td>\n",
       "      <td id=\"T_faefc_row9_col14\" class=\"data row9 col14\" >6514</td>\n",
       "      <td id=\"T_faefc_row9_col15\" class=\"data row9 col15\" >57.100</td>\n",
       "      <td id=\"T_faefc_row9_col16\" class=\"data row9 col16\" >10.000</td>\n",
       "      <td id=\"T_faefc_row9_col17\" class=\"data row9 col17\" >f</td>\n",
       "      <td id=\"T_faefc_row9_col18\" class=\"data row9 col18\" >3</td>\n",
       "      <td id=\"T_faefc_row9_col19\" class=\"data row9 col19\" >PC5</td>\n",
       "      <td id=\"T_faefc_row9_col20\" class=\"data row9 col20\" >0</td>\n",
       "      <td id=\"T_faefc_row9_col21\" class=\"data row9 col21\" >0</td>\n",
       "      <td id=\"T_faefc_row9_col22\" class=\"data row9 col22\" >0</td>\n",
       "      <td id=\"T_faefc_row9_col23\" class=\"data row9 col23\" >11</td>\n",
       "      <td id=\"T_faefc_row9_col24\" class=\"data row9 col24\" >0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "     emp_length home_ownership  ...  years_since_first_cr pub_rec_cat\n",
       "0             9       MORTGAGE  ...                     9         0.0\n",
       "1             2           RENT  ...                    12         0.0\n",
       "2            10       MORTGAGE  ...                    11         0.0\n",
       "3             3           RENT  ...                     5         0.0\n",
       "4             1       MORTGAGE  ...                     7         0.0\n",
       "...         ...            ...  ...                   ...         ...\n",
       "7995          1           RENT  ...                     6         0.0\n",
       "7996          5       MORTGAGE  ...                    26         0.0\n",
       "7997          5            OWN  ...                     5         0.0\n",
       "7998          5           RENT  ...                    12         0.0\n",
       "7999          6       MORTGAGE  ...                    14         0.0\n",
       "\n",
       "[8000 rows x 25 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421aeab3",
   "metadata": {
    "input_tokens": 9
   },
   "outputs": [],
   "source": [
    "# df['pub_rec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107db90f",
   "metadata": {
    "input_tokens": 403
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"Engineer new features and clean up existing ones\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop high cardinality and less useful columns\n",
    "    cols_to_drop = ['emp_title', 'Notes', 'purpose', 'zip_code', 'APP_ID', 'collections_12_mths_ex_med'] \n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "    \n",
    "    # Convert earliest_cr_line to credit history years\n",
    "    if 'earliest_cr_line' in df.columns:\n",
    "        df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "        reference_year = 2008\n",
    "        df['years_since_first_cr'] = reference_year - df['earliest_cr_line'].dt.year\n",
    "        df = df.drop(columns=['earliest_cr_line'])\n",
    "    \n",
    "    # Handle low cardinality features\n",
    "    # Convert pub_rec to categorical (very skewed distribution, only 4 values)\n",
    "    if 'pub_rec' in df.columns:\n",
    "        df['pub_rec_cat'] = df['pub_rec'].astype('category')\n",
    "    \n",
    "    # We keep delinq_2yrs and inq_last_6mths as continuous since they have more values\n",
    "    # and likely have a somewhat linear relationship with default risk\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c9443",
   "metadata": {
    "input_tokens": 10
   },
   "outputs": [],
   "source": [
    "df = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719f4be",
   "metadata": {
    "input_tokens": 6,
    "output_tokens": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `cont_cat_split` not found.\n"
     ]
    }
   ],
   "source": [
    "cont_cat_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc328cd4",
   "metadata": {
    "input_tokens": 31,
    "output_tokens": 130
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cont_cols,cat_cols = \u001b[43mcont_cat_split\u001b[49m(df, max_card=\u001b[32m20\u001b[39m, dep_var=\u001b[33m'\u001b[39m\u001b[33mTARGET\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cat_split' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cat_split' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-bf861d737523>\", line 1, in <module>\n    cont_cols,cat_cols = cont_cat_split(df, max_card=20, dep_var='TARGET')\n                         ^^^^^^^^^^^^^^\n",
      "NameError: name 'cont_cat_split' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols,cat_cols = cont_cat_split(df, max_card=20, dep_var='TARGET')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f54b3",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcont_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7def3622cedc>\", line 1, in <module>\n    cont_cols\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324ee03",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 99
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43mcont_cols\u001b[49m].nunique()\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7918a45abe66>\", line 1, in <module>\n    df[cont_cols].nunique()\n       ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "df[cont_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc44ae",
   "metadata": {
    "input_tokens": 16,
    "output_tokens": 166,
    "solveit_ai": true
   },
   "source": [
    "remove pub_rec from cont and add to cat cols..\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's update our continuous and categorical column lists to move `pub_rec` from continuous to categorical features:\n",
    "\n",
    "```python\n",
    "# Remove pub_rec from continuous columns\n",
    "cont_cols = [col for col in cont_cols if col != 'pub_rec']\n",
    "\n",
    "# Add pub_rec to categorical columns if not already there\n",
    "if 'pub_rec' not in cat_cols:\n",
    "    cat_cols.append('pub_rec')\n",
    "    \n",
    "# Check the updated lists\n",
    "print(f\"Continuous columns: {len(cont_cols)}\")\n",
    "print(f\"Categorical columns: {len(cat_cols)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb3d3b",
   "metadata": {
    "input_tokens": 118,
    "output_tokens": 174
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cont_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcont_cols\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m col != \u001b[33m'\u001b[39m\u001b[33mpub_rec\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Add pub_rec to categorical columns if not already there\u001b[39;00m\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mpub_rec\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_cols:\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-f910d593e567>\", line 1, in <module>\n    cont_cols = [col for col in cont_cols if col != 'pub_rec']\n                                ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols = [col for col in cont_cols if col != 'pub_rec']\n",
    "\n",
    "# Add pub_rec to categorical columns if not already there\n",
    "if 'pub_rec' not in cat_cols:\n",
    "    cat_cols.append('pub_rec')\n",
    "    \n",
    "# Check the updated lists\n",
    "print(f\"Continuous columns: {len(cont_cols)}\")\n",
    "print(f\"Categorical columns: {len(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd13a8",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcont_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7def3622cedc>\", line 1, in <module>\n    cont_cols\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b18ce",
   "metadata": {
    "input_tokens": 3,
    "output_tokens": 91
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcat_cols\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cat_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-44d80dea175d>\", line 1, in <module>\n    cat_cols\n",
      "NameError: name 'cat_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad08cb",
   "metadata": {
    "input_tokens": 18,
    "output_tokens": 276,
    "solveit_ai": true
   },
   "source": [
    "make this remove ad add into small fucntion...\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's a small function to adjust column categorization:\n",
    "\n",
    "```python\n",
    "def adjust_column_types(cont_cols, cat_cols, move_to_cat=None, move_to_cont=None):\n",
    "    \"Move columns between continuous and categorical lists\"\n",
    "    if move_to_cat:\n",
    "        cont_cols = [col for col in cont_cols if col not in move_to_cat]\n",
    "        for col in move_to_cat:\n",
    "            if col not in cat_cols: cat_cols.append(col)\n",
    "    \n",
    "    if move_to_cont:\n",
    "        cat_cols = [col for col in cat_cols if col not in move_to_cont]\n",
    "        for col in move_to_cont:\n",
    "            if col not in cont_cols: cont_cols.append(col)\n",
    "            \n",
    "    return cont_cols, cat_cols\n",
    "```\n",
    "\n",
    "And here's how to use it:\n",
    "\n",
    "```python\n",
    "# Example usage\n",
    "cont_cols, cat_cols = adjust_column_types(cont_cols, cat_cols, move_to_cat=['pub_rec'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c26c3",
   "metadata": {
    "input_tokens": 196
   },
   "outputs": [],
   "source": [
    "def adjust_column_types(cont_cols, cat_cols, move_to_cat=None, move_to_cont=None):\n",
    "    \"Move columns between continuous and categorical lists\"\n",
    "    if move_to_cat:\n",
    "        cont_cols = [col for col in cont_cols if col not in move_to_cat]\n",
    "        for col in move_to_cat:\n",
    "            if col not in cat_cols: cat_cols.append(col)\n",
    "    \n",
    "    if move_to_cont:\n",
    "        cat_cols = [col for col in cat_cols if col not in move_to_cont]\n",
    "        for col in move_to_cont:\n",
    "            if col not in cont_cols: cont_cols.append(col)\n",
    "            \n",
    "    return cont_cols, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3d8af",
   "metadata": {
    "input_tokens": 33,
    "output_tokens": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cont_cols, cat_cols = adjust_column_types(\u001b[43mcont_cols\u001b[49m, cat_cols, move_to_cat=[\u001b[33m'\u001b[39m\u001b[33mpub_rec\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'cont_cols' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cont_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-f9ddecbd7327>\", line 1, in <module>\n    cont_cols, cat_cols = adjust_column_types(cont_cols, cat_cols, move_to_cat=['pub_rec'])\n                                              ^^^^^^^^^\n",
      "NameError: name 'cont_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "cont_cols, cat_cols = adjust_column_types(cont_cols, cat_cols, move_to_cat=['pub_rec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a4695",
   "metadata": {
    "input_tokens": 6
   },
   "source": [
    "# combined steps.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdc3b7",
   "metadata": {
    "input_tokens": 6
   },
   "outputs": [],
   "source": [
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2e210",
   "metadata": {
    "input_tokens": 100,
    "output_tokens": 141
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mAssessment Modeling Dataset.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m      2\u001b[39m df= preprocess_data(df)\n",
      "\u001b[32m      3\u001b[39m df= feature_engineering(df)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-1cc78c765ffd>\", line 1, in <module>\n    df = pd.read_csv('Assessment Modeling Dataset.csv')\n         ^^\n",
      "NameError: name 'pd' is not defined\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Assessment Modeling Dataset.csv')\n",
    "df= preprocess_data(df)\n",
    "df= feature_engineering(df)\n",
    "cont_cols,cat_cols = cont_cat_split(df, max_card=20, dep_var='TARGET')\n",
    "cont_cols, cat_cols = adjust_column_types(cont_cols, cat_cols, move_to_cat=['pub_rec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cd65e",
   "metadata": {
    "input_tokens": 15,
    "output_tokens": 150
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual_inc                0\n",
       "debt_to_income            0\n",
       "delinq_2yrs               0\n",
       "inq_last_6mths            0\n",
       "mths_since_last_delinq    0\n",
       "mths_since_last_record    0\n",
       "open_acc                  0\n",
       "revol_bal                 0\n",
       "revol_util                0\n",
       "total_acc                 0\n",
       "years_since_first_cr      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cont_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d5ab1",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 156
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual_inc                1590\n",
       "debt_to_income            2471\n",
       "delinq_2yrs                 10\n",
       "inq_last_6mths              18\n",
       "mths_since_last_delinq      91\n",
       "mths_since_last_record      88\n",
       "open_acc                    35\n",
       "revol_bal                 6694\n",
       "revol_util                1020\n",
       "total_acc                   73\n",
       "years_since_first_cr        50\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cont_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543628e",
   "metadata": {
    "input_tokens": 15,
    "output_tokens": 166
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_length                     0\n",
       "home_ownership                 0\n",
       "verification_status            0\n",
       "pymnt_plan                     0\n",
       "purpose_cat                    0\n",
       "addr_state                     0\n",
       "initial_list_status            0\n",
       "mths_since_last_major_derog    0\n",
       "policy_code                    0\n",
       "has_mths_since_last_delinq     0\n",
       "has_mths_since_last_record     0\n",
       "pub_rec_cat                    0\n",
       "pub_rec                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18890d8a",
   "metadata": {
    "input_tokens": 12,
    "output_tokens": 166
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_length                     14\n",
       "home_ownership                  5\n",
       "verification_status             3\n",
       "pymnt_plan                      2\n",
       "purpose_cat                    27\n",
       "addr_state                     49\n",
       "initial_list_status             2\n",
       "mths_since_last_major_derog     3\n",
       "policy_code                     5\n",
       "has_mths_since_last_delinq      2\n",
       "has_mths_since_last_record      2\n",
       "pub_rec_cat                     4\n",
       "pub_rec                         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3536f",
   "metadata": {
    "input_tokens": 102,
    "output_tokens": 517,
    "solveit_ai": true
   },
   "source": [
    "Does this data processing step make sense? Do you agree with the data form and all the steps I performed? Do you disagree somewhere? Should I do something more before I start building my model? Any obvious mistakes that don't make sense? Anything that should be categorical but is continuous, or vice versa? Please share your opinion and think carefully.\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Your data processing looks generally good, but I have a few suggestions for improvement:\n",
    "\n",
    "1. **Redundant columns**:\n",
    "   - You have both `pub_rec` and `pub_rec_cat` in your categorical columns - they're redundant. Keep only one (I'd suggest just `pub_rec`).\n",
    "\n",
    "2. **Additional categorical conversions**:\n",
    "   - `delinq_2yrs` has only 10 unique values with a very skewed distribution (7120 zeros). This should likely be categorical.\n",
    "   - `inq_last_6mths` with 18 unique values is borderline - consider testing both ways.\n",
    "\n",
    "3. **Feature transformations**:\n",
    "   - `revol_bal` looks heavily skewed based on your describe output (mean vs median). Consider log-transforming it.\n",
    "   - `annual_inc` might also benefit from log transformation.\n",
    "\n",
    "4. **Feature binning**:\n",
    "   - `debt_to_income` could be binned into ranges that represent meaningful risk segments\n",
    "   - `years_since_first_cr` could be binned into credit history length categories\n",
    "\n",
    "5. **Additional features**:\n",
    "   - Consider ratio features like `revol_bal / annual_inc` for debt burden\n",
    "   - `delinq_2yrs > 0` as a binary flag might be more predictive than the raw count\n",
    "\n",
    "6. **Feature interactions**:\n",
    "   - Simple interactions between features like `home_ownership` Ã— `debt_to_income` might reveal important patterns\n",
    "\n",
    "7. **Column duplication check**:\n",
    "   - Some columns might be representing the same information (multicollinearity)\n",
    "\n",
    "Overall, your processing pipeline is logical and handles the basics well. These additional steps could further improve your model's discriminatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec33e08",
   "metadata": {
    "input_tokens": 66,
    "output_tokens": 252,
    "solveit_ai": true
   },
   "source": [
    "Does the data look good enough to start building the first model? We can always come back and do more feature engineering, but overall, do you think it makes sense to build an initial model with this data as is?\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, the data is definitely ready for an initial model! You've done solid preprocessing work:\n",
    "\n",
    "- Missing values have been handled appropriately\n",
    "- High-cardinality categorical columns have been managed\n",
    "- The date field has been converted to a more useful numeric feature\n",
    "- Continuous and categorical features have been properly separated\n",
    "\n",
    "Building an initial baseline model with this data makes perfect sense. This will give you:\n",
    "\n",
    "1. A performance benchmark to improve upon\n",
    "2. Feature importance insights to guide further engineering\n",
    "3. A better understanding of which areas need more focus\n",
    "\n",
    "You can always iterate and add more sophisticated feature engineering after evaluating your first model. This iterative approach is actually preferable to spending too much time on feature engineering before seeing how a simple model performs.\n",
    "\n",
    "I'd suggest moving forward with building your first model now, then using what you learn to guide your next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae833322",
   "metadata": {
    "input_tokens": 34,
    "output_tokens": 348,
    "solveit_ai": true
   },
   "source": [
    "Let's build our tabular pandas. I want to build a fast AI model, and we'll go in from there.\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's build the TabularPandas and model with fastai:\n",
    "\n",
    "```python\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# Create train/validation splits\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df))\n",
    "\n",
    "# Create TabularPandas\n",
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "                  cat_names=cat_cols,\n",
    "                  cont_names=cont_cols,\n",
    "                  y_names='TARGET',\n",
    "                  splits=splits)\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = to.dataloaders(bs=64)\n",
    "\n",
    "# Create tabular learner\n",
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary()])\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(5, 1e-2)\n",
    "```\n",
    "\n",
    "This will give us a solid baseline model. We're using:\n",
    "- A 80/20 train/validation split\n",
    "- Standard preprocessing (categorification, missing value handling, normalization)\n",
    "- Binary classification metrics (accuracy and ROC AUC)\n",
    "- The standard 1cycle training policy\n",
    "\n",
    "After this runs, we can evaluate performance and decide on next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4ff96",
   "metadata": {
    "input_tokens": 198,
    "output_tokens": 52
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.tabular.learner.TabularLearner at 0x7a6809554d90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "\n",
    "# Create train/validation splits\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(df))\n",
    "\n",
    "# Create TabularPandas\n",
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "                  cat_names=cat_cols,\n",
    "                  cont_names=cont_cols,\n",
    "                  y_names='TARGET',\n",
    "                  splits=splits)\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = to.dataloaders(bs=64)\n",
    "\n",
    "# Create tabular learner\n",
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary()])\n",
    "\n",
    "# Train the model\n",
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433a539",
   "metadata": {
    "input_tokens": 1,
    "output_tokens": 88
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlearn\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'learn' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-851add19358a>\", line 1, in <module>\n    learn\n",
      "NameError: name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee15fa",
   "metadata": {
    "collapsed": true,
    "input_tokens": 28,
    "output_tokens": 5532
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–ˆ\r",
      "epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    \n",
      "â–ˆ\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.00% [1/100 00:00<00:03]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 2.00% [2/100 00:00<00:02 0.7730]\r",
      "\r",
      "Epoch 1/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:02 0.6307]\r",
      "\r",
      "Epoch 1/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:01 0.5347]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:01 0.4737]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [16/100 00:00<00:01 0.2924]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------| 31.00% [31/100 00:00<00:00 0.2387]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 47.00% [47/100 00:00<00:00 0.2015]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---------------| 64.00% [64/100 00:00<00:00 0.1730]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------| 82.00% [82/100 00:00<00:00 0.1571]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:01<00:00 0.1437]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.1430]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.1430]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.1430]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.1430]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.1430]\r",
      "\r",
      "Epoch 1/5 :                                                                              \r",
      "\r",
      "Epoch 1/5 :                                                                              \r",
      "0         0.143037    0.124170    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 2.00% [2/100 00:00<00:01 0.1435]\r",
      "\r",
      "Epoch 2/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.1427]\r",
      "\r",
      "Epoch 2/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.1416]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.1411]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 25.00% [25/100 00:00<00:00 0.1282]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 46.00% [46/100 00:00<00:00 0.1227]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------| 67.00% [67/100 00:00<00:00 0.1185]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 88.00% [88/100 00:00<00:00 0.1144]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.1119]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.1123]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.1123]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.1123]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.1123]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.1123]\r",
      "\r",
      "Epoch 2/5 :                                                                              \r",
      "\r",
      "Epoch 2/5 :                                                                              \r",
      "1         0.112310    0.135443    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 2.00% [2/100 00:00<00:00 0.1116]\r",
      "\r",
      "Epoch 3/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.1113]\r",
      "\r",
      "Epoch 3/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.1113]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.1107]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 26.00% [26/100 00:00<00:00 0.1062]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 47.00% [47/100 00:00<00:00 0.1075]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------------| 68.00% [68/100 00:00<00:00 0.1027]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 89.00% [89/100 00:00<00:00 0.0989]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.1010]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.1011]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.1011]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.1011]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.1011]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.1011]\r",
      "\r",
      "Epoch 3/5 :                                                                              \r",
      "\r",
      "Epoch 3/5 :                                                                              \r",
      "2         0.101141    0.102670    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 2.00% [2/100 00:00<00:00 0.1007]\r",
      "\r",
      "Epoch 4/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.1008]\r",
      "\r",
      "Epoch 4/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.1001]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.1009]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 26.00% [26/100 00:00<00:00 0.1029]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 47.00% [47/100 00:00<00:00 0.0959]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------------| 68.00% [68/100 00:00<00:00 0.0944]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 89.00% [89/100 00:00<00:00 0.0923]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.0901]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.0901]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.0901]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.0901]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.0901]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.0901]\r",
      "\r",
      "Epoch 4/5 :                                                                              \r",
      "\r",
      "Epoch 4/5 :                                                                              \r",
      "3         0.090061    0.096437    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 2.00% [2/100 00:00<00:00 0.0896]\r",
      "\r",
      "Epoch 5/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.0893]\r",
      "\r",
      "Epoch 5/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.0889]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.0887]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 26.00% [26/100 00:00<00:00 0.0904]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 47.00% [47/100 00:00<00:00 0.0943]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------------| 68.00% [68/100 00:00<00:00 0.0941]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 89.00% [89/100 00:00<00:00 0.0882]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.0860]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.0855]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.0855]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.0855]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.0855]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.0855]\r",
      "\r",
      "Epoch 5/5 :                                                                              \r",
      "\r",
      "Epoch 5/5 :                                                                              \r",
      "4         0.085454    0.096734    0.875000  0.500000       00:01     \n"
     ]
    }
   ],
   "source": [
    "# fit the Learner\n",
    "learn.fit_one_cycle(5, 1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893bc71",
   "metadata": {
    "input_tokens": 18,
    "output_tokens": 235,
    "solveit_ai": true
   },
   "source": [
    "lets add class weight to handle the unbalanced target class.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's add class weights to handle the imbalanced target class:\n",
    "\n",
    "```python\n",
    "# Calculate class weights based on the target distribution\n",
    "target_counts = df['TARGET'].value_counts()\n",
    "total = len(df)\n",
    "weights = torch.FloatTensor([total/target_counts[0], total/target_counts[1]])\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Create the learner with class weights\n",
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary()])\n",
    "learn.loss_func = CrossEntropyLossFlat(weight=weights)\n",
    "\n",
    "# Train the model with class weights\n",
    "learn.fit_one_cycle(5, 1e-2)\n",
    "```\n",
    "\n",
    "This will adjust the loss function to give more importance to the minority class (defaults), helping the model learn better from the imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03f750",
   "metadata": {
    "input_tokens": 63
   },
   "outputs": [],
   "source": [
    "target_counts = df['TARGET'].value_counts()\n",
    "total = len(df)\n",
    "weights = torch.FloatTensor([total/target_counts[0], total/target_counts[1]])\n",
    "weights = weights / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5877d86",
   "metadata": {
    "input_tokens": 1,
    "output_tokens": 34
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1277, 0.8723])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f2e22",
   "metadata": {
    "collapsed": true,
    "input_tokens": 78,
    "output_tokens": 4299
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–ˆ\r",
      "epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    \n",
      "â–ˆ\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n",
      "\u001b[32m      2\u001b[39m learn.loss_func = CrossEntropyLossFlat(weight=weights)\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Train the model with class weights\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mlearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/callback/schedule.py:121\u001b[39m, in \u001b[36mfit_one_cycle\u001b[39m\u001b[34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[39m\n",
      "\u001b[32m    118\u001b[39m lr_max = np.array([h[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.opt.hypers])\n",
      "\u001b[32m    119\u001b[39m scheds = {\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n",
      "\u001b[32m    120\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mmom\u001b[39m\u001b[33m'\u001b[39m: combined_cos(pct_start, *(\u001b[38;5;28mself\u001b[39m.moms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n",
      "\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m+\u001b[49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:272\u001b[39m, in \u001b[36mLearner.fit\u001b[39m\u001b[34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[39m\n",
      "\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.opt.set_hypers(lr=\u001b[38;5;28mself\u001b[39m.lr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n",
      "\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m.n_epoch = n_epoch\n",
      "\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:207\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n",
      "\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final=noop):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:261\u001b[39m, in \u001b[36mLearner._do_fit\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    259\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_epoch):\n",
      "\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.epoch=epoch\n",
      "\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:207\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n",
      "\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final=noop):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:255\u001b[39m, in \u001b[36mLearner._do_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_epoch_validate()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:247\u001b[39m, in \u001b[36mLearner._do_epoch_train\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    246\u001b[39m     \u001b[38;5;28mself\u001b[39m.dl = \u001b[38;5;28mself\u001b[39m.dls.train\n",
      "\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:207\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n",
      "\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final=noop):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:213\u001b[39m, in \u001b[36mLearner.all_batches\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    212\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_iter = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dl)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.dl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:243\u001b[39m, in \u001b[36mLearner.one_batch\u001b[39m\u001b[34m(self, i, b)\u001b[39m\n",
      "\u001b[32m    241\u001b[39m b = \u001b[38;5;28mself\u001b[39m._set_device(b)\n",
      "\u001b[32m    242\u001b[39m \u001b[38;5;28mself\u001b[39m._split(b)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:207\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n",
      "\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final=noop):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/learner.py:227\u001b[39m, in \u001b[36mLearner._do_one_batch\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    225\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mafter_pred\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.yb):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28mself\u001b[39m.loss_grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m.loss = \u001b[38;5;28mself\u001b[39m.loss_grad.clone()\n",
      "\u001b[32m    229\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mafter_loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/losses.py:57\u001b[39m, in \u001b[36mBaseLoss.__call__\u001b[39m\u001b[34m(self, inp, targ, **kwargs)\u001b[39m\n",
      "\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m targ.dtype \u001b[38;5;129;01min\u001b[39;00m [torch.int8, torch.int16, torch.int32]: targ = targ.long()\n",
      "\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.flatten: inp = inp.view(-\u001b[32m1\u001b[39m,inp.shape[-\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_2d \u001b[38;5;28;01melse\u001b[39;00m inp.view(-\u001b[32m1\u001b[39m)\n",
      "\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n",
      "\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/loss.py:1295\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n",
      "\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/functional.py:3480\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n",
      "\u001b[32m   3414\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Compute the cross entropy loss between input logits and target.\u001b[39;00m\n",
      "\u001b[32m   3415\u001b[39m \n",
      "\u001b[32m   3416\u001b[39m \u001b[33;03mSee :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   3477\u001b[39m \u001b[33;03m    >>> loss.backward()\u001b[39;00m\n",
      "\u001b[32m   3478\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m   3479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   3481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3482\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3483\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3486\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/overrides.py:1742\u001b[39m, in \u001b[36mhandle_torch_function\u001b[39m\u001b[34m(public_api, relevant_args, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m   1734\u001b[39m     warnings.warn(\n",
      "\u001b[32m   1735\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m   1736\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m   1737\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n",
      "\u001b[32m   1738\u001b[39m     )\n",
      "\u001b[32m   1740\u001b[39m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n",
      "\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m result = \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/fastai/torch_core.py:384\u001b[39m, in \u001b[36mTensorBase.__torch_function__\u001b[39m\u001b[34m(cls, func, types, args, kwargs)\u001b[39m\n",
      "\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.debug \u001b[38;5;129;01mand\u001b[39;00m func.\u001b[34m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33m__str__\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n",
      "\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m._opt, func): types = (torch.Tensor,)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m res = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    385\u001b[39m dict_objs = _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs.values()))\n",
      "\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res.set_meta(dict_objs[\u001b[32m0\u001b[39m],as_copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/_tensor.py:1648\u001b[39m, in \u001b[36mTensor.__torch_function__\u001b[39m\u001b[34m(cls, func, types, args, kwargs)\u001b[39m\n",
      "\u001b[32m   1645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[32m   1647\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _C.DisableTorchFunctionSubclass():\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1648\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n",
      "\u001b[32m   1650\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n",
      "\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[31mRuntimeError\u001b[39m: weight tensor should be defined either for all 1 classes or no classes but got weight tensor of shape: [2]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 1 classes or no classes but got weight tensor of shape: [2]",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ba1215941a5d>\", line 5, in <module>\n    learn.fit_one_cycle(5, 1e-2)\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/callback/schedule.py\", line 121, in fit_one_cycle\n    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 272, in fit\n    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 207, in _with_events\n    try: self(f'before_{event_type}');  f()\n                                        ^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 261, in _do_fit\n    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 207, in _with_events\n    try: self(f'before_{event_type}');  f()\n                                        ^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 255, in _do_epoch\n    self._do_epoch_train()\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 247, in _do_epoch_train\n    self._with_events(self.all_batches, 'train', CancelTrainException)\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 207, in _with_events\n    try: self(f'before_{event_type}');  f()\n                                        ^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 213, in all_batches\n    for o in enumerate(self.dl): self.one_batch(*o)\n                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 243, in one_batch\n    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 207, in _with_events\n    try: self(f'before_{event_type}');  f()\n                                        ^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/learner.py\", line 227, in _do_one_batch\n    self.loss_grad = self.loss_func(self.pred, *self.yb)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/losses.py\", line 57, in __call__\n    return self.func.__call__(inp, targ.view(-1) if self.flatten else targ, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/loss.py\", line 1295, in forward\n    return F.cross_entropy(\n           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/functional.py\", line 3480, in cross_entropy\n    return handle_torch_function(\n           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/overrides.py\", line 1742, in handle_torch_function\n    result = torch_func_method(public_api, types, args, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/data/.local/lib/python3.11/site-packages/fastai/torch_core.py\", line 384, in __torch_function__\n    res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/_tensor.py\", line 1648, in __torch_function__\n    ret = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/functional.py\", line 3494, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: weight tensor should be defined either for all 1 classes or no classes but got weight tensor of shape: [2]\n"
     ]
    }
   ],
   "source": [
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary()])\n",
    "learn.loss_func = CrossEntropyLossFlat(weight=weights)\n",
    "\n",
    "# Train the model with class weights\n",
    "learn.fit_one_cycle(5, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569f75e",
   "metadata": {
    "input_tokens": 55,
    "output_tokens": 540,
    "solveit_ai": true
   },
   "source": [
    "refer Loss_Functions_fastai_docs docs for context and first tell me intuitively what wrong here why we using this loss fucntion and why it failing with simple example please..\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the error and the fastai Loss Functions documentation, I can see the issue with our approach.\n",
    "\n",
    "The error message says: `weight tensor should be defined either for all 1 classes or no classes but got weight tensor of shape: [2]`\n",
    "\n",
    "The problem is that we're using `CrossEntropyLossFlat` incorrectly. Let me explain:\n",
    "\n",
    "In fastai, for binary classification tasks like ours (default vs. no default), the model typically outputs a single value which is then passed through a sigmoid function. The target is either 0 or 1. This is fundamentally different from multi-class classification where the model outputs multiple logits (one for each class).\n",
    "\n",
    "When we look at the Loss_Functions_fastai_docs, we can see that:\n",
    "\n",
    "1. `CrossEntropyLossFlat` is designed for multi-class classification\n",
    "2. For binary classification, we should use `BCEWithLogitsLossFlat` instead\n",
    "\n",
    "Here's a simple example:\n",
    "\n",
    "```\n",
    "# Wrong approach (what we did):\n",
    "# For binary classification with TARGET values of 0 and 1\n",
    "weights = torch.FloatTensor([0.1277, 0.8723])\n",
    "loss_func = CrossEntropyLossFlat(weight=weights)  # Error! Expects n_classes logits\n",
    "\n",
    "# Correct approach:\n",
    "# For binary classification, we use BCEWithLogitsLossFlat\n",
    "pos_weight = torch.FloatTensor([0.8723/0.1277])  # Weight for positive class (ratio of neg:pos)\n",
    "loss_func = BCEWithLogitsLossFlat(pos_weight=pos_weight)\n",
    "```\n",
    "\n",
    "The issue is that our model is outputting a single value for each sample (for binary classification), but CrossEntropyLoss expects logits for each class. Let's fix this by using the appropriate loss function for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fea028",
   "metadata": {
    "collapsed": true,
    "input_tokens": 127,
    "output_tokens": 5524
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–ˆ\r",
      "epoch     train_loss  valid_loss  accuracy  roc_auc_score  time    \n",
      "â–ˆ\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 1.00% [1/100 00:00<00:02]\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 2.00% [2/100 00:00<00:01 0.5510]\r",
      "\r",
      "Epoch 1/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:01 0.4284]\r",
      "\r",
      "Epoch 1/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:01 0.4007]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:01 0.3790]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 17.00% [17/100 00:00<00:01 0.2794]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------| 32.00% [32/100 00:00<00:00 0.2350]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---------------------| 48.00% [48/100 00:00<00:00 0.1969]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------| 65.00% [65/100 00:00<00:00 0.1785]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------| 83.00% [83/100 00:00<00:00 0.1614]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:01<00:00 0.1463]\r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "\r",
      "Epoch 1/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 1/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 1/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.1451]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.1451]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.1451]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.1451]\r",
      "\r",
      "Epoch 1/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.1451]\r",
      "\r",
      "Epoch 1/5 :                                                                              \r",
      "\r",
      "Epoch 1/5 :                                                                              \r",
      "0         0.145086    0.121886    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 2.00% [2/100 00:00<00:01 0.1438]\r",
      "\r",
      "Epoch 2/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:01 0.1440]\r",
      "\r",
      "Epoch 2/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:01 0.1448]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:01 0.1437]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------------------------------| 23.00% [23/100 00:00<00:00 0.1339]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------| 41.00% [41/100 00:00<00:00 0.1298]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------| 60.00% [60/100 00:00<00:00 0.1194]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------| 80.00% [80/100 00:00<00:00 0.1139]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.1072]\r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "\r",
      "Epoch 2/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 2/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 2/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.1061]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.1061]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.1061]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.1061]\r",
      "\r",
      "Epoch 2/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.1061]\r",
      "\r",
      "Epoch 2/5 :                                                                              \r",
      "\r",
      "Epoch 2/5 :                                                                              \r",
      "1         0.106122    0.111109    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 2.00% [2/100 00:00<00:00 0.1064]\r",
      "\r",
      "Epoch 3/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.1052]\r",
      "\r",
      "Epoch 3/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.1045]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.1047]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 25.00% [25/100 00:00<00:00 0.1061]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 46.00% [46/100 00:00<00:00 0.1077]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------| 67.00% [67/100 00:00<00:00 0.1031]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 88.00% [88/100 00:00<00:00 0.1019]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.0977]\r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "\r",
      "Epoch 3/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 3/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 3/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.0967]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.0967]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.0967]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.0967]\r",
      "\r",
      "Epoch 3/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.0967]\r",
      "\r",
      "Epoch 3/5 :                                                                              \r",
      "\r",
      "Epoch 3/5 :                                                                              \r",
      "2         0.096713    0.101208    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 2.00% [2/100 00:00<00:00 0.0965]\r",
      "\r",
      "Epoch 4/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.0977]\r",
      "\r",
      "Epoch 4/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.0978]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.0974]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 25.00% [25/100 00:00<00:00 0.0984]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 46.00% [46/100 00:00<00:00 0.0967]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------| 67.00% [67/100 00:00<00:00 0.0944]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 88.00% [88/100 00:00<00:00 0.0928]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.0892]\r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "\r",
      "Epoch 4/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 4/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 4/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.0894]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.0894]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.0894]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.0894]\r",
      "\r",
      "Epoch 4/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.0894]\r",
      "\r",
      "Epoch 4/5 :                                                                              \r",
      "\r",
      "Epoch 4/5 :                                                                              \r",
      "3         0.089435    0.096973    0.875000  0.500000       00:01     \n",
      "â–ˆ\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/100 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 1.00% [1/100 00:00<00:01]\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 2.00% [2/100 00:00<00:00 0.0889]\r",
      "\r",
      "Epoch 5/5 : |â–ˆ---------------------------------------| 3.00% [3/100 00:00<00:00 0.0886]\r",
      "\r",
      "Epoch 5/5 : |â–ˆ---------------------------------------| 4.00% [4/100 00:00<00:00 0.0882]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆ--------------------------------------| 5.00% [5/100 00:00<00:00 0.0885]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------------------------| 25.00% [25/100 00:00<00:00 0.0868]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------| 46.00% [46/100 00:00<00:00 0.0889]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------| 67.00% [67/100 00:00<00:00 0.0884]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 88.00% [88/100 00:00<00:00 0.0875]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [100/100 00:00<00:00 0.0873]\r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "\r",
      "Epoch 5/5 :                                                                                \r",
      "â–ˆ\r",
      "\r",
      "Epoch 5/5 : |----------------------------------------| 0.00% [0/25 00:00<?]\r",
      "\r",
      "Epoch 5/5 : |â–ˆ---------------------------------------| 4.00% [1/25 00:00<00:00]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆ-------------------------------------| 8.00% [2/25 00:00<00:00 0.0875]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆ------------------------------------| 12.00% [3/25 00:00<00:00 0.0875]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------------------------------| 16.00% [4/25 00:00<00:00 0.0875]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------------------------------| 20.00% [5/25 00:00<00:00 0.0875]\r",
      "\r",
      "Epoch 5/5 : |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [25/25 00:00<00:00 0.0875]\r",
      "\r",
      "Epoch 5/5 :                                                                              \r",
      "\r",
      "Epoch 5/5 :                                                                              \r",
      "4         0.087512    0.098837    0.875000  0.500000       00:01     \n"
     ]
    }
   ],
   "source": [
    "learn = tabular_learner(dls, metrics=[accuracy, RocAucBinary()])\n",
    "pos_weight = torch.FloatTensor([0.8723/0.1277])  # Weight for positive class (ratio of neg:pos)\n",
    "loss_func = BCEWithLogitsLossFlat(pos_weight=pos_weight)\n",
    "\n",
    "# Train the model with class weights\n",
    "learn.fit_one_cycle(5, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e913a",
   "metadata": {
    "input_tokens": 16,
    "output_tokens": 37,
    "solveit_ai": true
   },
   "source": [
    "let  try the mteric mention in assessment ...\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Please post on Discord that you got this error:\n",
    "Expecting value: line 2 column 1 (char 1)"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
